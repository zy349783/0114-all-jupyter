{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def tickDB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "\n",
    "def dailyDB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    url = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    client = pymongo.MongoClient(url, maxPoolSize=None)\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def read_filter_daily(db, name, start_date=None, end_date=None, skey=None, interval=None, col=None, return_sdi=True):\n",
    "    collection = db[name]\n",
    "    # Build projection\n",
    "    prj = {'_id': 0}\n",
    "    if col is not None:\n",
    "        if return_sdi:\n",
    "            col = ['skey', 'date'] + col\n",
    "        for col_name in col:\n",
    "            prj[col_name] = 1\n",
    "\n",
    "    # Build query\n",
    "    query = {}\n",
    "    if skey is not None:\n",
    "        query['skey'] = {'$in': skey}\n",
    "    if interval is not None:\n",
    "        query['interval'] = {'$in': interval}\n",
    "    if start_date is not None:\n",
    "        if end_date is not None:\n",
    "            query['date'] = {'$gte': start_date, '$lte': end_date}\n",
    "        else:\n",
    "            query['date'] = {'$gte': start_date}\n",
    "    elif end_date is not None:\n",
    "        query['date'] = {'$lte': end_date}\n",
    "\n",
    "    # Load data\n",
    "    cur = collection.find(query, prj)\n",
    "    df = pd.DataFrame.from_records(cur)\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        df = df.sort_values(by=['date','skey'])\n",
    "    return df  \n",
    "\n",
    "def read_memb_daily(db, name, start_date=None, end_date=None, skey=None, index_id=None, interval=None, col=None, return_sdi=True):\n",
    "    collection = db[name]\n",
    "    # Build projection\n",
    "    prj = {'_id': 0}\n",
    "    if col is not None:\n",
    "        if return_sdi:\n",
    "            col = ['skey', 'date', 'index_id'] + col\n",
    "        for col_name in col:\n",
    "            prj[col_name] = 1\n",
    "\n",
    "    # Build query\n",
    "    query = {}\n",
    "    if skey is not None:\n",
    "        query['skey'] = {'$in': skey}\n",
    "    if index_id is not None:\n",
    "        query['index_id'] = {'$in': index_id}\n",
    "    if interval is not None:\n",
    "        query['interval'] = {'$in': interval}\n",
    "    if start_date is not None:\n",
    "        if end_date is not None:\n",
    "            query['date'] = {'$gte': start_date, '$lte': end_date}\n",
    "        else:\n",
    "            query['date'] = {'$gte': start_date}\n",
    "    elif end_date is not None:\n",
    "        query['date'] = {'$lte': end_date}\n",
    "\n",
    "    # Load data\n",
    "    cur = collection.find(query, prj)\n",
    "    df = pd.DataFrame.from_records(cur)\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        df = df.sort_values(by=['date', 'index_id', 'skey'])\n",
    "    return df    \n",
    "\n",
    "\n",
    "def read_stock_daily(db, name, start_date=None, end_date=None, skey=None, index_name=None, interval=None, col=None, return_sdi=True):\n",
    "    collection = db[name]\n",
    "    # Build projection\n",
    "    prj = {'_id': 0}\n",
    "    if col is not None:\n",
    "        if return_sdi:\n",
    "            col = ['skey', 'date'] + col\n",
    "        for col_name in col:\n",
    "            prj[col_name] = 1\n",
    "\n",
    "    # Build query\n",
    "    query = {}\n",
    "    if skey is not None:\n",
    "        query['skey'] = {'$in': skey}\n",
    "    if index_name is not None:\n",
    "        query['index_name'] = {'$in': index_name}\n",
    "    if start_date is not None:\n",
    "        if end_date is not None:\n",
    "            query['date'] = {'$gte': start_date, '$lte': end_date}\n",
    "        else:\n",
    "            query['date'] = {'$gte': start_date}\n",
    "    elif end_date is not None:\n",
    "        query['date'] = {'$lte': end_date}\n",
    "\n",
    "    # Load data\n",
    "    cur = collection.find(query, prj)\n",
    "    df = pd.DataFrame.from_records(cur)\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        df = df.sort_values(by=['date', 'skey'])\n",
    "    return df    \n",
    "\n",
    "\n",
    "def read_beta_daily(db, name, start_date=None, end_date=None, skey=None, interval=None, col=None, return_sdi=True):\n",
    "    collection = db[name]\n",
    "    # Build projection\n",
    "    prj = {'_id': 0}\n",
    "    if col is not None:\n",
    "        if return_sdi:\n",
    "            col = ['skey', 'date'] + col\n",
    "        for col_name in col:\n",
    "            prj[col_name] = 1\n",
    "\n",
    "    # Build query\n",
    "    query = {}\n",
    "    if skey is not None:\n",
    "        query['skey'] = {'$in': skey}\n",
    "    if interval is not None:\n",
    "        query['interval'] = {'$in': interval}\n",
    "    if start_date is not None:\n",
    "        if end_date is not None:\n",
    "            query['date'] = {'$gte': start_date, '$lte': end_date}\n",
    "        else:\n",
    "            query['date'] = {'$gte': start_date}\n",
    "    elif end_date is not None:\n",
    "        query['date'] = {'$lte': end_date}\n",
    "\n",
    "    # Load data\n",
    "    cur = collection.find(query, prj)\n",
    "    df = pd.DataFrame.from_records(cur)\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        df = df.sort_values(by=['date','skey'])\n",
    "    return df  \n",
    "\n",
    "\n",
    "database_name = 'com_md_eq_cn'\n",
    "user = 'zhenyuy'\n",
    "password = 'bnONBrzSMGoE'\n",
    "\n",
    "import sys\n",
    "import zipfile \n",
    "\n",
    "pd.set_option('max_columns', 200)\n",
    "db1 = tickDB(\"192.168.10.178\", database_name, user, password)\n",
    "db = dailyDB(\"192.168.10.178\", database_name, user, password)\n",
    "dateLs = read_memb_daily(db, 'index_memb', index_id=[1000300], start_date=20201228, end_date=20201229)['date'].unique()\n",
    "for date in dateLs:\n",
    "    data1 = read_memb_daily(db, 'index_memb', start_date=int(date), end_date=int(date))\n",
    "    data1 = data1[~data1['index_id'].isin([1000300, 1000852, 1000905, 1000985])]\n",
    "    f = zipfile.ZipFile('E:\\\\AMAC\\\\AMAC_' + str(date) + '.zip', 'r')\n",
    "    data2 = pd.read_excel(f.open(f.namelist()[0]))\n",
    "    data2['index_name'] = data2['指数名称\\nIndex Name'].str[:4] + ' ' + data2['指数名称\\nIndex Name'].str[4:]\n",
    "    re2 = data2.groupby('index_name')['权重(%)\\nWeight(%)'].sum().reset_index()\n",
    "    re1 = data1.groupby('index_name')['weight'].sum().reset_index()\n",
    "    re2['权重(%)\\nWeight(%)'] = re2['权重(%)\\nWeight(%)'].round(2)\n",
    "    re1['weight'] = re1['weight'].round(2)\n",
    "    re = pd.merge(re1, re2, on='index_name', how='outer')\n",
    "    if re[re['weight'] != re['权重(%)\\nWeight(%)']].shape[0] != 0:\n",
    "        print(date)\n",
    "        display(re[re['weight'] != re['权重(%)\\nWeight(%)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "len(data1[data1['index_name'] == 'AMAC 地产']['成分券代码\\nConstituent Code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{558}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data2[data2['index_name'] == 'AMAC 地产']['成分券代码\\nConstituent Code'].unique()) - set(data1[(data1['index_name'] == 'AMAC 地产') & (data1['weight'] != 0)]['成分券代码\\nConstituent Code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>日期\\nDate</th>\n",
       "      <th>指数代码\\nIndex Code</th>\n",
       "      <th>指数名称\\nIndex Name</th>\n",
       "      <th>指数英文名称\\nIndex Name(Eng.)</th>\n",
       "      <th>成分券代码\\nConstituent Code</th>\n",
       "      <th>成分券名称\\nConstituent Name</th>\n",
       "      <th>成分券英文名称\\nConstituent Name(Eng.)</th>\n",
       "      <th>交易所\\nExchange</th>\n",
       "      <th>权重(%)\\nWeight(%)</th>\n",
       "      <th>交易货币\\nTrading Currency</th>\n",
       "      <th>index_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>958</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>H11047</td>\n",
       "      <td>AMAC地产</td>\n",
       "      <td>AMAC Real Estate Index</td>\n",
       "      <td>558</td>\n",
       "      <td>莱茵体育</td>\n",
       "      <td>LANDER SPORTS DEVELOPMENT CO.,LTD.</td>\n",
       "      <td>Shenzhen</td>\n",
       "      <td>0.2</td>\n",
       "      <td>CNY</td>\n",
       "      <td>AMAC 地产</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       日期\\nDate 指数代码\\nIndex Code 指数名称\\nIndex Name 指数英文名称\\nIndex Name(Eng.)  \\\n",
       "958  2020-12-15           H11047           AMAC地产   AMAC Real Estate Index   \n",
       "\n",
       "     成分券代码\\nConstituent Code 成分券名称\\nConstituent Name  \\\n",
       "958                      558                    莱茵体育   \n",
       "\n",
       "        成分券英文名称\\nConstituent Name(Eng.) 交易所\\nExchange  权重(%)\\nWeight(%)  \\\n",
       "958  LANDER SPORTS DEVELOPMENT CO.,LTD.      Shenzhen               0.2   \n",
       "\n",
       "    交易货币\\nTrading Currency index_name  \n",
       "958                    CNY    AMAC 地产  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[data2['成分券代码\\nConstituent Code'] == 558]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  import sys\n",
      "C:\\Users\\win\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20200813,\n",
       " 20200820,\n",
       " 20200827,\n",
       " 20200903,\n",
       " 20200910,\n",
       " 20200917,\n",
       " 20200924,\n",
       " 20201015,\n",
       " 20201022,\n",
       " 20201029]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "pd.set_option('max_columns', 200)\n",
    "db1 = tickDB(\"192.168.10.178\", database_name, user, password)\n",
    "db = dailyDB(\"192.168.10.178\", database_name, user, password)\n",
    "dateLs = read_memb_daily(db, 'index_memb', index_id=[1000300], start_date=20200813, end_date=20201101)['date'].astype(str).\\\n",
    "apply(lambda x: datetime.datetime.strptime(x,\"%Y%m%d\")).unique()\n",
    "dateLs1 = [datetime.datetime.fromtimestamp((i-np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')).weekday() for i in dateLs]\n",
    "dateLs = np.array(dateLs)[np.array(dateLs1) == 3]\n",
    "dateLs = [int(datetime.datetime.fromtimestamp((i-np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')).strftime('%Y%m%d')) for i in dateLs]\n",
    "dateLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('E:\\\\AMAC\\\\AMAC_20201218.zip', <http.client.HTTPMessage at 0x1d1e5654a08>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "updateDate = (datetime.date.today()).strftime('%Y%m%d')\n",
    "savePath = 'E:\\\\AMAC'\n",
    "from urllib.request import urlretrieve\n",
    "url = 'http://www.csindex.com.cn/uploads/indices/amac/files/csrccwf.zip'\n",
    "fileName = savePath + '\\\\AMAC_' + updateDate + '.zip'\n",
    "urlretrieve(url, fileName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
