{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "20200813\n",
      "0:00:35.034240\n",
      "0:02:59.152680\n",
      "----------------------------------------------------------------\n",
      "SH lv2 data:\n",
      "1674\n",
      "1667\n",
      "11\n",
      "{688065, 605066, 688556, 605100, 688338, 688339, 605366, 688313, 688155, 688286, 688185}\n",
      "6823282\n",
      "6823282\n",
      "6823282\n",
      "-----------------------------------------------\n",
      "0:01:59.426880\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '0.0]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-aefe188bad96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ask\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"q\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"OfferQty\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m             \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bid\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"p\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"BidPrice\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ask\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"p\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"OfferPrice\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bid\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"q\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"BidOrderQty\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4040\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4041\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4042\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4044\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-aefe188bad96>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ask\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"q\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"OfferQty\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m             \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bid\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"p\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"BidPrice\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ask\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"p\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"OfferPrice\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bid\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"q\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogSH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"BidOrderQty\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '0.0]'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from matplotlib.ticker import Formatter\n",
    "import collections\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "\n",
    "\n",
    "for y in ['20200813', '20200814', '20200817']:\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(y)\n",
    "    \n",
    "    re = {}\n",
    "    for col in ['date', 'data', 'baseline', 'test', 'merge', 'time', 'stock_list']:\n",
    "        re[col] = []\n",
    "            \n",
    "    readPath = 'F:\\\\data\\\\' + y + '\\\\***_zt_88_03_day_88data\\\\mdLog_SH_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    startTm = datetime.datetime.now()\n",
    "    logSH1 = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    logSH1 = logSH1[[\"sequenceNo\", \"StockID\", \"source\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                     \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\", \"bid3q\", \n",
    "                     \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \n",
    "                     \"ask2q\", \"ask3q\", \"ask4q\", \"ask5q\", \"openPrice\", \"numTrades\"]]\n",
    "    logSH1[\"time\"] = logSH1[\"time\"].apply(lambda x: int(x.replace(':', \"\").replace('.', \"\")))\n",
    "        \n",
    "    readPath = 'A:\\\\KR_daily_data\\\\' + y + '\\\\SH\\\\snapshot\\\\Level2\\\\***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[(dateLs >= 600000) & (dateLs <= 700000)]\n",
    "    logSH2 = []\n",
    "    ll = []\n",
    "    startTm = datetime.datetime.now()\n",
    "    for i in dataPathLs:\n",
    "        try:\n",
    "            df = pd.read_csv(i)\n",
    "        except:\n",
    "            print(\"empty data\")\n",
    "            print(i)\n",
    "            ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "            continue\n",
    "        df[\"StockID\"] = int(os.path.basename(i).split('.')[0])\n",
    "        logSH2 += [df]\n",
    "    del df\n",
    "    logSH2 = pd.concat(logSH2).reset_index(drop=True)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    for i in range(1, 6):\n",
    "        if i == 1:\n",
    "            logSH2[\"bid\" + str(i) + \"p\"] = logSH2[\"BidPrice\"].apply(lambda x: float(x.split(',')[0][1:]))\n",
    "            logSH2[\"ask\" + str(i) + \"p\"] = logSH2[\"OfferPrice\"].apply(lambda x: float(x.split(',')[0][1:]))\n",
    "            logSH2[\"bid\" + str(i) + \"q\"] = logSH2[\"BidOrderQty\"].apply(lambda x: int(x.split(',')[0][1:]))\n",
    "            logSH2[\"ask\" + str(i) + \"q\"] = logSH2[\"OfferOrderQty\"].apply(lambda x: int(x.split(',')[0][1:]))\n",
    "        else:\n",
    "            logSH2[\"bid\" + str(i) + \"p\"] = logSH2[\"BidPrice\"].apply(lambda x: float(x.split(',')[i-1]))\n",
    "            logSH2[\"ask\" + str(i) + \"p\"] = logSH2[\"OfferPrice\"].apply(lambda x: float(x.split(',')[i-1]))\n",
    "            logSH2[\"bid\" + str(i) + \"q\"] = logSH2[\"BidOrderQty\"].apply(lambda x: int(x.split(',')[i-1]))\n",
    "            logSH2[\"ask\" + str(i) + \"q\"] = logSH2[\"OfferOrderQty\"].apply(lambda x: int(x.split(',')[i-1]))\n",
    "    logSH2 = logSH2.rename(columns={\"Volume\":\"cum_volume\", \"Amount\":\"cum_amount\", \"LastPx\":\"close\", \"OpenPx\":\"openPrice\",\n",
    "                                   \"NumTrades\":\"numTrades\"})\n",
    "    logSH2[\"time\"] = (logSH2[\"QuotTime\"] - int(y)*1000000000).astype(np.int64)\n",
    "    \n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SH lv2 data:')\n",
    "    in_dex = [16, 300, 852, 905]\n",
    "    data1 = logSH2[~logSH2[\"StockID\"].isin(in_dex) & (logSH2[\"time\"] >= 91500000) & (logSH2[\"time\"] <= 150000000)]\n",
    "    data2 = logSH1[~logSH1[\"StockID\"].isin(in_dex) & (logSH1[\"time\"] >= 91500000) & (logSH1[\"time\"] <= 150000000) & (logSH1['source'] == 23)]\n",
    "    columns = [\"StockID\", \"cum_volume\", \"cum_amount\", \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "           \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "           \"ask4q\", \"ask5q\", \"openPrice\", \"time\", \"numTrades\"]\n",
    "    data1_1 = data1.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    data2_1 = data2.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "\n",
    "    n1 = len(data1_1[\"StockID\"].unique())\n",
    "    n2 = len(data2_1[\"StockID\"].unique())\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique())))\n",
    "    print(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique()))\n",
    "    \n",
    "    if n1 != n2:\n",
    "        sl = list(set(data1_1[\"StockID\"].unique()) & set(data2_1[\"StockID\"].unique()))\n",
    "        data1_1 = data1_1[data1_1[\"StockID\"].isin(sl)]\n",
    "        data2_1 = data2_1[data2_1[\"StockID\"].isin(sl)]\n",
    "    \n",
    "    data1_1['cum_amount'] = data1_1['cum_amount'].round(2)\n",
    "    data2_1['cum_amount'] = data2_1['cum_amount'].round(2)\n",
    "    data1_1['openPrice'] = data1_1.groupby('StockID')['openPrice'].transform('max')\n",
    "    data2_1['openPrice'] = data2_1.groupby('StockID')['openPrice'].transform('max')\n",
    "    \n",
    "    test = pd.merge(data1_1, data2_1, left_on=columns, right_on=columns, how=\"outer\")\n",
    "    n1 = test[\"IOPV\"].count()\n",
    "    n2 = test[\"sequenceNo\"].count()\n",
    "    len1 = len(test)\n",
    "    re['date'].append(y)\n",
    "    re['data'].append('SH lv2 data')\n",
    "    re['baseline'].append(n1)\n",
    "    re['test'].append(n2)\n",
    "    re['merge'].append(len1)\n",
    "    if (n1 == len1) & (n2 == len1):\n",
    "        re['time'].append(0)\n",
    "        re['stock_list'].append(0)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        display(\"test is not complete:\")\n",
    "        display(test[np.isnan(test[\"sequenceNo\"])])\n",
    "        display(len(test[np.isnan(test[\"sequenceNo\"])])/n1)\n",
    "        display(len(test[np.isnan(test[\"sequenceNo\"])][\"time\"].unique()))\n",
    "        display(test[np.isnan(test[\"sequenceNo\"])][\"time\"].unique())\n",
    "        display(len(test[np.isnan(test[\"sequenceNo\"])][\"StockID\"].unique()))\n",
    "        display(test[np.isnan(test[\"sequenceNo\"])][\"StockID\"].unique())\n",
    "        re['time'].append(np.sort(test[np.isnan(test[\"sequenceNo\"])][\"time\"].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test[\"sequenceNo\"])][\"StockID\"].unique()))\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        display(\"baseline is not complete:\")\n",
    "        display(test[np.isnan(test[\"IOPV\"])])\n",
    "        display(n2-n1)\n",
    "        re['time'].append(np.sort(test[np.isnan(test[\"IOPV\"])][\"time\"].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test[\"IOPV\"])][\"StockID\"].unique()))\n",
    "        print((n2-n1)/n1)\n",
    "    del logSH2\n",
    "    del data1\n",
    "    del data2\n",
    "    del test\n",
    "    del data1_1\n",
    "    del data2_1\n",
    "\n",
    "\n",
    "    readPath = 'F:\\\\data\\\\' + y + '\\\\***_zs_92_01_day_data\\\\mdLog_SH_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    startTm = datetime.datetime.now()\n",
    "    logSH2 = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    logSH2 = logSH2[[\"sequenceNo\", \"StockID\", \"source\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                     \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\", \"bid3q\", \n",
    "                     \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \n",
    "                     \"ask2q\", \"ask3q\", \"ask4q\", \"ask5q\", \"openPrice\", \"numTrades\"]]\n",
    "    logSH2[\"time\"] = logSH2[\"time\"].apply(lambda x: int(x.replace(':', \"\").replace('.', \"\")))\n",
    "    \n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SH lv1 data:')\n",
    "    in_dex = [16, 300, 852, 905]\n",
    "    data1 = logSH2[~logSH2[\"StockID\"].isin(in_dex) & (logSH2[\"time\"] >= 91500000) & (logSH2[\"time\"] <= 150000000) & (logSH2['source'] == 3)]\n",
    "    data2 = logSH1[~logSH1[\"StockID\"].isin(in_dex) & (logSH1[\"time\"] >= 91500000) & (logSH1[\"time\"] <= 150000000) & (logSH1['source'] == 22)]\n",
    "    columns = [\"StockID\", \"cum_volume\", \"cum_amount\", \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "           \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "           \"ask4q\", \"ask5q\", \"openPrice\", \"time\", \"numTrades\"]\n",
    "    data1_1 = data1.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    data2_1 = data2.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "\n",
    "    n1 = len(data1_1[\"StockID\"].unique())\n",
    "    n2 = len(data2_1[\"StockID\"].unique())\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique())))\n",
    "    print(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique()))\n",
    "    \n",
    "    if n1 != n2:\n",
    "        sl = list(set(data1_1[\"StockID\"].unique()) & set(data2_1[\"StockID\"].unique()))\n",
    "        data1_1 = data1_1[data1_1[\"StockID\"].isin(sl)]\n",
    "        data2_1 = data2_1[data2_1[\"StockID\"].isin(sl)]\n",
    "    data1_1['cum_amount'] = data1_1['cum_amount'].round(2)\n",
    "    data2_1['cum_amount'] = data2_1['cum_amount'].round(2)\n",
    "    data1_1['openPrice'] = data1_1.groupby('StockID')['openPrice'].transform('max')\n",
    "    data2_1['openPrice'] = data2_1.groupby('StockID')['openPrice'].transform('max')\n",
    "    \n",
    "    test = pd.merge(data1_1, data2_1, left_on=columns, right_on=columns, how=\"outer\")\n",
    "    n1 = test[\"IOPV\"].count()\n",
    "    n2 = test[\"sequenceNo\"].count()\n",
    "    len1 = len(test)\n",
    "    re['date'].append(y)\n",
    "    re['data'].append('SH lv1 data')\n",
    "    re['baseline'].append(n1)\n",
    "    re['test'].append(n2)\n",
    "    re['merge'].append(len1)\n",
    "    if (n1 == len1) & (n2 == len1):\n",
    "        re['time'].append(0)\n",
    "        re['stock_list'].append(0)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        display(\"test is not complete:\")\n",
    "        display(test[np.isnan(test[\"sequenceNo\"])])\n",
    "        display(len(test[np.isnan(test[\"sequenceNo\"])])/n1)\n",
    "        display(len(test[np.isnan(test[\"sequenceNo\"])][\"time\"].unique()))\n",
    "        display(test[np.isnan(test[\"sequenceNo\"])][\"time\"].unique())\n",
    "        display(len(test[np.isnan(test[\"sequenceNo\"])][\"StockID\"].unique()))\n",
    "        display(test[np.isnan(test[\"sequenceNo\"])][\"StockID\"].unique())\n",
    "        re['time'].append(np.sort(test[np.isnan(test[\"sequenceNo\"])][\"time\"].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test[\"sequenceNo\"])][\"StockID\"].unique()))\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        display(\"baseline is not complete:\")\n",
    "        display(test[np.isnan(test[\"IOPV\"])])\n",
    "        display(n2-n1)\n",
    "        re['time'].append(np.sort(test[np.isnan(test[\"IOPV\"])][\"time\"].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test[\"IOPV\"])][\"StockID\"].unique()))\n",
    "        print((n2-n1)/n1)\n",
    "    del logSH1\n",
    "    del logSH2\n",
    "    del data1\n",
    "    del data2\n",
    "    del test\n",
    "    del data1_1\n",
    "    del data2_1\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SH index data:')\n",
    "    \n",
    "    readPath = 'F:\\\\data\\\\' + y + '\\\\***_zt_88_03_day_88data\\\\mdLog_SH_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    startTm = datetime.datetime.now()\n",
    "    index = pd.read_csv(dataPathLs[0])\n",
    "    index[\"time\"] = index[\"time\"].apply(lambda x: int(x.replace(':', \"\").replace('.', \"\")))\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "    readPath = 'A:\\\\KR_daily_data\\\\' + y + '\\\\SH\\\\snapshot\\\\Level2\\\\***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[(dateLs == 16) | (dateLs == 300) | (dateLs == 852) | (dateLs == 905)]\n",
    "    logSH = []\n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    for i in dataPathLs:\n",
    "        df = pd.read_csv(i)\n",
    "        df[\"StockID\"] = int(os.path.basename(i).split('.')[0])\n",
    "        logSH += [df]\n",
    "    logSH = pd.concat(logSH).reset_index(drop=True)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    for i in range(1, 6):\n",
    "        if i == 1:\n",
    "            logSH[\"bid\" + str(i) + \"p\"] = logSH[\"BidPrice\"].apply(lambda x: float(x.split(',')[0][1:]))\n",
    "            logSH[\"ask\" + str(i) + \"p\"] = logSH[\"OfferPrice\"].apply(lambda x: float(x.split(',')[0][1:]))\n",
    "            logSH[\"bid\" + str(i) + \"q\"] = logSH[\"BidOrderQty\"].apply(lambda x: int(x.split(',')[0][1:]))\n",
    "            logSH[\"ask\" + str(i) + \"q\"] = logSH[\"OfferOrderQty\"].apply(lambda x: int(x.split(',')[0][1:]))\n",
    "        else:\n",
    "            logSH[\"bid\" + str(i) + \"p\"] = logSH[\"BidPrice\"].apply(lambda x: float(x.split(',')[i-1]))\n",
    "            logSH[\"ask\" + str(i) + \"p\"] = logSH[\"OfferPrice\"].apply(lambda x: float(x.split(',')[i-1]))\n",
    "            logSH[\"bid\" + str(i) + \"q\"] = logSH[\"BidOrderQty\"].apply(lambda x: int(x.split(',')[i-1]))\n",
    "            logSH[\"ask\" + str(i) + \"q\"] = logSH[\"OfferOrderQty\"].apply(lambda x: int(x.split(',')[i-1]))\n",
    "    logSH = logSH.rename(columns={\"Volume\":\"cum_volume\", \"Amount\":\"cum_amount\", \"LastPx\":\"close\", \"OpenPx\":\"openPrice\",\n",
    "                                   \"NumTrades\":\"numTrades\"})\n",
    "    logSH[\"time\"] = (logSH[\"SendingTime\"] - int(y)*1000000000).astype(np.int64)\n",
    "    \n",
    "    in_dex = [16, 300, 852, 905]\n",
    "    index = index[index[\"StockID\"].isin(in_dex)]\n",
    "    print(index[\"StockID\"].unique())\n",
    "    \n",
    "    data1 = logSH[(logSH[\"StockID\"].isin(in_dex)) & (logSH[\"time\"] >= 91500000) & (logSH[\"time\"] <= 150000000)]\n",
    "    data2 = index[(index[\"time\"] >= 91500000) & (index[\"time\"] <= 150000000)]\n",
    "\n",
    "    columns = [\"StockID\", \"cum_volume\", \"cum_amount\", \"close\", \"openPrice\"]\n",
    "    data1_1 = data1.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    data2_1 = data2.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    \n",
    "    for cols in ['close', 'openPrice']:\n",
    "        data1_1[cols] = data1_1[cols].round(4)\n",
    "        data2_1[cols] = data2_1[cols].round(4)\n",
    "    for cols in ['cum_amount']:\n",
    "        data1_1[cols] = data1_1[cols].round(1)\n",
    "        data2_1[cols] = data2_1[cols].round(1)\n",
    "        \n",
    "    test = pd.merge(data1_1, data2_1, left_on=columns, right_on=columns, how=\"outer\")\n",
    "    n1 = test[\"IOPV\"].count()\n",
    "    n2 = test[\"sequenceNo\"].count()\n",
    "    len1 = len(test)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    re['date'].append(y)\n",
    "    re['data'].append('SH index data without time column')\n",
    "    re['baseline'].append(n1)\n",
    "    re['test'].append(n2)\n",
    "    re['merge'].append(len1)\n",
    "    if (n1 == len1) & (n2 == len1):\n",
    "        re['time'].append(0)\n",
    "        re['stock_list'].append(0)\n",
    "    if n2 < len1:\n",
    "        display(\"test is not complete:\")\n",
    "        display(test[np.isnan(test[\"sequenceNo\"])])\n",
    "        re['time'].append(np.sort(test[np.isnan(test['sequenceNo'])]['time_x'].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test['sequenceNo'])]['StockID'].unique()))\n",
    "    if (n2 == len1) & (n1 < len1):\n",
    "        display(\"baseline is not complete::\")\n",
    "        display(test[np.isnan(test[\"IOPV\"])])\n",
    "        re['time'].append(np.sort(test[np.isnan(test[\"IOPV\"])]['time_y'].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test['IOPV'])]['StockID'].unique()))\n",
    "    \n",
    "    del index\n",
    "    del logSH\n",
    "    del data1\n",
    "    del data2\n",
    "    del test\n",
    "    del data1_1\n",
    "    del data2_1\n",
    "\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SZ lv2 data:')\n",
    "    \n",
    "    readPath = 'F:\\\\data\\\\' + y + '\\\\***_zt_88_03_day_88data\\\\mdLog_SZ_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    startTm = datetime.datetime.now()\n",
    "    logSZ1 = pd.read_csv(dataPathLs[0])\n",
    "    logSZ1[\"time\"] = logSZ1[\"time\"].apply(lambda x: int(x.replace(':', \"\").replace('.', \"\")))\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    logSZ1 = logSZ1.loc[:, [\"clockAtArrival\", \"sequenceNo\", \"StockID\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                                              \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\",\n",
    "                                              \"bid2q\", \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\",\n",
    "                                              \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "                                              \"ask4q\", \"ask5q\", \"openPrice\", \"numTrades\"]]\n",
    "\n",
    "\n",
    "    readPath = 'A:\\\\KR_daily_data\\\\' + y + '\\\\SZ\\\\snapshot\\\\Level2\\\\***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[(dateLs < 4000) | ((dateLs > 300000) & (dateLs < 310000))]\n",
    "    logSZ = []\n",
    "    ll = []\n",
    "    startTm = datetime.datetime.now()\n",
    "    for i in dataPathLs:\n",
    "        try:\n",
    "            df = pd.read_csv(i)\n",
    "        except:\n",
    "            print(\"empty data\")\n",
    "            print(i)\n",
    "            ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "            continue\n",
    "        df[\"StockID\"] = int(os.path.basename(i).split('.')[0])\n",
    "        logSZ += [df]\n",
    "    del df\n",
    "    logSZ = pd.concat(logSZ).reset_index(drop=True)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    for i in range(1, 6):\n",
    "        if i == 1:\n",
    "            logSZ[\"bid\" + str(i) + \"p\"] = logSZ[\"BidPrice\"].apply(lambda x: float(x.split(',')[0][1:]))\n",
    "            logSZ[\"ask\" + str(i) + \"p\"] = logSZ[\"OfferPrice\"].apply(lambda x: float(x.split(',')[0][1:]))\n",
    "            logSZ[\"bid\" + str(i) + \"q\"] = logSZ[\"BidOrderQty\"].apply(lambda x: int(x.split(',')[0][1:]))\n",
    "            logSZ[\"ask\" + str(i) + \"q\"] = logSZ[\"OfferOrderQty\"].apply(lambda x: int(x.split(',')[0][1:]))\n",
    "        else:\n",
    "            logSZ[\"bid\" + str(i) + \"p\"] = logSZ[\"BidPrice\"].apply(lambda x: float(x.split(',')[i-1]))\n",
    "            logSZ[\"ask\" + str(i) + \"p\"] = logSZ[\"OfferPrice\"].apply(lambda x: float(x.split(',')[i-1]))\n",
    "            logSZ[\"bid\" + str(i) + \"q\"] = logSZ[\"BidOrderQty\"].apply(lambda x: int(x.split(',')[i-1]))\n",
    "            logSZ[\"ask\" + str(i) + \"q\"] = logSZ[\"OfferOrderQty\"].apply(lambda x: int(x.split(',')[i-1]))\n",
    "    logSZ = logSZ.rename(columns={\"Volume\":\"cum_volume\", \"Amount\":\"cum_amount\", \"LastPx\":\"close\", \"OpenPx\":\"openPrice\",\n",
    "                                   \"NumTrades\":\"numTrades\"})\n",
    "    logSZ[\"time\"] = (logSZ[\"QuotTime\"] - int(y)*1000000000).astype(np.int64)\n",
    "    print(datetime.datetime.now() - startTm)    \n",
    "    \n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    data1 = logSZ[(logSZ[\"time\"] >= 91500000) & (logSZ[\"time\"] < 150000000)]\n",
    "    data2 = logSZ1[(logSZ1[\"time\"] >= 91500000) & (logSZ1[\"time\"] < 150000000)]\n",
    "\n",
    "    columns = [\"StockID\", \"cum_volume\", \"cum_amount\", \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "           \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "           \"ask4q\", \"ask5q\", \"openPrice\", \"numTrades\", \"time\"]\n",
    "    data1_1 = data1.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    data2_1 = data2.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "\n",
    "    n1 = len(data1_1[\"StockID\"].unique())\n",
    "    n2 = len(data2_1[\"StockID\"].unique())\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique())))\n",
    "    print(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique()))\n",
    "    if n1 != n2:\n",
    "        sl = list(set(data1_1[\"StockID\"].unique()) & set(data2_1[\"StockID\"].unique()))\n",
    "        data1_1 = data1_1[data1_1[\"StockID\"].isin(sl)]\n",
    "        data2_1 = data2_1[data2_1[\"StockID\"].isin(sl)]\n",
    "    for cols in ['close', 'cum_amount']:\n",
    "        data1_1[cols] = data1_1[cols].round(2)\n",
    "        data2_1[cols] = data2_1[cols].round(2)\n",
    "    test = pd.merge(data1_1, data2_1, left_on=columns, right_on=columns, how=\"outer\")\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    n1 = test[\"ImageStatus\"].count()\n",
    "    n2 = test[\"sequenceNo\"].count()\n",
    "    len1 = len(test)\n",
    "    re['date'].append(y)\n",
    "    re['data'].append('SZ lv2 data')\n",
    "    re['baseline'].append(n1)\n",
    "    re['test'].append(n2)\n",
    "    re['merge'].append(len1)\n",
    "    if (n1 == len1) & (n2 == len1):\n",
    "        re['time'].append(0)\n",
    "        re['stock_list'].append(0)    \n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        display(\"test is not complete:\")\n",
    "        display(test[np.isnan(test[\"sequenceNo\"])])\n",
    "        print(len(test[np.isnan(test[\"sequenceNo\"])])/n1)\n",
    "        print(np.sort(test[np.isnan(test[\"sequenceNo\"])][\"time\"].unique()))\n",
    "        print(len(np.sort(test[np.isnan(test[\"sequenceNo\"])][\"StockID\"].unique())))\n",
    "        print(np.sort(test[np.isnan(test[\"sequenceNo\"])][\"StockID\"].unique()))\n",
    "        re['time'].append(np.sort(test[np.isnan(test[\"sequenceNo\"])][\"time\"].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test[\"sequenceNo\"])][\"StockID\"].unique()))   \n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        display(\"baseline is not complete:\")\n",
    "        display(test[np.isnan(test[\"ImageStatus\"])])\n",
    "        display(n2-n1)\n",
    "        re['time'].append(np.sort(test[np.isnan(test[\"ImageStatus\"])][\"time\"].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test[\"ImageStatus\"])][\"StockID\"].unique()))\n",
    "    del logSZ\n",
    "    del logSZ1\n",
    "    del data1\n",
    "    del data2\n",
    "    del test\n",
    "    del data1_1\n",
    "    del data2_1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    readPath = 'F:\\\\data\\\\' + y + '\\\\***_zt_88_03_day_88data\\\\mdOrderLog_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    startTm = datetime.datetime.now()\n",
    "    OrderLogSZ1 = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "\n",
    "    readPath = 'A:\\\\KR_daily_data\\\\' + y + '\\\\SZ\\\\order\\\\***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[(dateLs < 4000) | ((dateLs > 300000) & (dateLs < 310000))]\n",
    "    OrderLogSZ = []\n",
    "    ll = []\n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    for i in dataPathLs:\n",
    "        try:\n",
    "            df = pd.read_csv(i, encoding='GBK')\n",
    "        except:\n",
    "            print(\"empty data\")\n",
    "            print(i)\n",
    "            ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "            continue\n",
    "        df[\"SecurityID\"] = int(os.path.basename(i).split('.')[0])\n",
    "        OrderLogSZ += [df]\n",
    "    OrderLogSZ = pd.concat(OrderLogSZ).reset_index(drop=True)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    OrderLogSZ = OrderLogSZ.rename(columns={\"OrdType\": \"OrderType\"})\n",
    "    OrderLogSZ[\"TransactTime\"] = (OrderLogSZ[\"TransactTime\"] - int(y) * 1000000000).astype(np.int64)\n",
    "#     OrderLogSZ1 = OrderLogSZ1[OrderLogSZ1[\"Side\"] != 'F']\n",
    "    display(OrderLogSZ[\"Side\"].unique())\n",
    "    display(OrderLogSZ[\"ChannelNo\"].unique())\n",
    "    OrderLogSZ[\"Side\"] = np.where(OrderLogSZ[\"Side\"] == '1', 1, np.where(\n",
    "    OrderLogSZ[\"Side\"] == '2', 2, OrderLogSZ[\"Side\"]))\n",
    "    display(OrderLogSZ[((OrderLogSZ[\"Side\"] != 1) & (OrderLogSZ[\"Side\"] != 2)) | (OrderLogSZ[\"OrderType\"].isnull())])\n",
    "    OrderLogSZ[\"OrderType\"] = np.where(OrderLogSZ[\"OrderType\"] == 2, '2', np.where(\n",
    "        OrderLogSZ[\"OrderType\"] == 1, '1', OrderLogSZ['OrderType']))\n",
    "    \n",
    "    OrderLogSZ1[\"OrderType\"] = np.where(OrderLogSZ1[\"OrderType\"] == 2, '2', np.where(\n",
    "        OrderLogSZ1[\"OrderType\"] == 1, '1', OrderLogSZ1['OrderType']))\n",
    "    \n",
    "    OrderLogSZ = OrderLogSZ[OrderLogSZ[\"ChannelNo\"] != 4001]\n",
    "    display(len(OrderLogSZ[\"SecurityID\"].unique()))\n",
    "    display(len(OrderLogSZ1[\"SecurityID\"].unique()))\n",
    "    display(len(set(OrderLogSZ[\"SecurityID\"].unique()) - set(OrderLogSZ1[\"SecurityID\"].unique())))\n",
    "    display(set(OrderLogSZ[\"SecurityID\"].unique()) - set(OrderLogSZ1[\"SecurityID\"].unique()))\n",
    "\n",
    "\n",
    "    sl = list(set(OrderLogSZ[\"SecurityID\"].unique()) & set(OrderLogSZ1['SecurityID'].unique()))\n",
    "    OrderLogSZ = OrderLogSZ[OrderLogSZ[\"SecurityID\"].isin(sl)]\n",
    "    OrderLogSZ1 = OrderLogSZ1[OrderLogSZ1[\"SecurityID\"].isin(sl)]\n",
    "    print(len(OrderLogSZ[\"SecurityID\"].unique()))\n",
    "    print(len(OrderLogSZ1[\"SecurityID\"].unique()))\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SZ order data:')\n",
    "    \n",
    "    columns = [\"ApplSeqNum\", \"TransactTime\", \"Side\", 'OrderType', 'Price', 'OrderQty', \"SecurityID\"]\n",
    "    ree = pd.merge(OrderLogSZ, OrderLogSZ1, on=columns, how=\"outer\", validate='one_to_one')\n",
    "    n1 = ree[\"SendingTime\"].count()\n",
    "    n2 = ree[\"sequenceNo\"].count()\n",
    "    len1 = len(ree)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    re['date'].append(y)\n",
    "    re['data'].append('SZ order data')\n",
    "    re['baseline'].append(n1)\n",
    "    re['test'].append(n2)\n",
    "    re['merge'].append(len1) \n",
    "    if (n1 == len1) & (n2 == len1):\n",
    "        re['time'].append(0)\n",
    "        re['stock_list'].append(0)    \n",
    "    \n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        display(\"test is not complete:\")\n",
    "        display(ree[np.isnan(ree[\"sequenceNo\"])])\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo\"])]))\n",
    "        print(np.sort(ree[np.isnan(ree[\"sequenceNo\"])][\"TransactTime\"].unique()))\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo\"])][\"SecurityID\"].unique()))\n",
    "        print(ree[np.isnan(ree[\"sequenceNo\"])][\"SecurityID\"].unique())\n",
    "        re['time'].append(np.sort(ree[np.isnan(ree[\"sequenceNo\"]) & (~ree[\"OrderType\"].isnull())][\"TransactTime\"].unique()))\n",
    "        re['stock_list'].append(np.sort(ree[np.isnan(ree[\"sequenceNo\"]) & (~ree[\"OrderType\"].isnull())][\"SecurityID\"].unique()))\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        display(\"test is complete, baseline is not complete:\")\n",
    "        display(ree[np.isnan(ree[\"SendingTime\"])])\n",
    "        print(np.sort(ree[np.isnan(ree[\"SendingTime\"])][\"TransactTime\"].unique()))\n",
    "        print(len(ree[np.isnan(ree[\"SendingTime\"])][\"SecurityID\"].unique()))\n",
    "        print(ree[np.isnan(ree[\"SendingTime\"])][\"SecurityID\"].unique())\n",
    "        display(n2-n1)\n",
    "        re['time'].append(np.sort(ree[np.isnan(ree[\"SendingTime\"])][\"TransactTime\"].unique()))\n",
    "        re['stock_list'].append(np.sort(ree[np.isnan(ree[\"SendingTime\"])][\"SecurityID\"].unique()))\n",
    "    del OrderLogSZ\n",
    "    del OrderLogSZ1\n",
    "    del ree\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    readPath = 'F:\\\\data\\\\' + y + '\\\\***_zt_88_03_day_88data\\\\mdTradeLog_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    SH1 = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "\n",
    "    readPath = 'A:\\\\KR_daily_data\\\\' + y + '\\\\SH\\\\tick\\\\***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[(dateLs >= 600000) & (dateLs <= 700000)]\n",
    "    SH = []\n",
    "    ll = []\n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    for i in dataPathLs:\n",
    "        try:\n",
    "            df = pd.read_csv(i)\n",
    "        except:\n",
    "            print(\"empty data\")\n",
    "            print(i)\n",
    "            ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "            continue\n",
    "        df[\"SecurityID\"] = int(os.path.basename(i).split('.')[0])\n",
    "        SH += [df]\n",
    "    SH = pd.concat(SH).reset_index(drop=True)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    SH[\"TransactTime\"] = (SH[\"TradeTime\"] - int(y) * 1000000000).astype(np.int64)\n",
    "    SH[\"ExecType\"] = 'F'\n",
    "    SH = SH.rename(columns={\"TradeIndex\":\"ApplSeqNum\", \"BuyNo\":\"BidApplSeqNum\", \"SellNo\":\"OfferApplSeqNum\"})\n",
    "    \n",
    "    display(len(SH[\"SecurityID\"].unique()))\n",
    "    display(len(SH1[\"SecurityID\"].unique()))\n",
    "    display(len(set(SH[\"SecurityID\"].unique()) - set(SH1[\"SecurityID\"].unique())))\n",
    "    display(set(SH[\"SecurityID\"].unique()) - set(SH1[\"SecurityID\"].unique()))\n",
    "\n",
    "    \n",
    "    sl = list(set(SH[\"SecurityID\"].unique()) & set(SH1['SecurityID'].unique()))\n",
    "    SH = SH[SH[\"SecurityID\"].isin(sl)]\n",
    "    SH1 = SH1[SH1[\"SecurityID\"].isin(sl)]\n",
    "    print(len(SH[\"SecurityID\"].unique()))\n",
    "    print(len(SH1[\"SecurityID\"].unique()))\n",
    "\n",
    "    print(SH1.columns)\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SH trade data:')\n",
    "    \n",
    "    SH[\"ExecType\"] = SH[\"ExecType\"].apply(lambda x: str(x))\n",
    "    SH1[\"ExecType\"] = 'F'\n",
    "    columns = [\"TransactTime\", \"ApplSeqNum\", \"SecurityID\", \"TradePrice\", \"TradeQty\", \"TradeMoney\", \"TradeBSFlag\",\"ExecType\",\n",
    "           \"BidApplSeqNum\", \"OfferApplSeqNum\"]\n",
    "    ree = pd.merge(SH, SH1, left_on=columns, right_on=columns, how=\"outer\", validate='one_to_one')\n",
    "    n1 = ree[\"TradeTime\"].count()\n",
    "    n2 = ree[\"sequenceNo\"].count()\n",
    "    len1 = len(ree)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    re['date'].append(y)\n",
    "    re['data'].append('SH trade data')\n",
    "    re['baseline'].append(n1)\n",
    "    re['test'].append(n2)\n",
    "    re['merge'].append(len1) \n",
    "    if (n1 == len1) & (n2 == len1):\n",
    "        re['time'].append(0)\n",
    "        re['stock_list'].append(0)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        display(\"test is not complete:\")\n",
    "        display(ree[np.isnan(ree[\"sequenceNo\"])])\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo\"])]))\n",
    "        print(np.sort(ree[np.isnan(ree[\"sequenceNo\"])][\"TransactTime\"].unique()))\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo\"])][\"SecurityID\"].unique()))\n",
    "        print(ree[np.isnan(ree[\"sequenceNo\"])][\"SecurityID\"].unique())\n",
    "        re['time'].append(np.sort(ree[np.isnan(ree[\"sequenceNo\"])][\"TransactTime\"].unique()))\n",
    "        re['stock_list'].append(np.sort(ree[np.isnan(ree[\"sequenceNo\"])][\"SecurityID\"].unique()))\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        display(\"baseline is not complete:\")\n",
    "        display(ree[np.isnan(ree[\"TradeTime\"])])\n",
    "        print(np.sort(ree[np.isnan(ree[\"TradeTime\"])][\"TransactTime\"].unique()))\n",
    "        print(len(ree[np.isnan(ree[\"TradeTime\"])][\"SecurityID\"].unique()))\n",
    "        print(ree[np.isnan(ree[\"TradeTime\"])][\"SecurityID\"].unique())\n",
    "        display(n2-n1)\n",
    "        re['time'].append(np.sort(ree[np.isnan(ree[\"TradeTime\"])][\"TransactTime\"].unique()))\n",
    "        re['stock_list'].append(np.sort(ree[np.isnan(ree[\"TradeTime\"])][\"SecurityID\"].unique()))\n",
    "    del SH\n",
    "    del SH1\n",
    "    del ree\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    readPath = 'F:\\\\data\\\\' + y + '\\\\***_zt_88_03_day_88data\\\\mdTradeLog_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    TradeLogSZ1 = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    TradeLogSZ1[\"TradeBSFlag\"] = 'N'\n",
    "    \n",
    "    readPath = 'A:\\\\KR_daily_data\\\\' + y + '\\\\SZ\\\\tick\\\\***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[(dateLs < 4000) | ((dateLs > 300000) & (dateLs < 310000))]\n",
    "    TradeLogSZ = []\n",
    "    ll = []\n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    for i in dataPathLs:\n",
    "        try:\n",
    "            df = pd.read_csv(i)\n",
    "        except:\n",
    "            print(\"empty data\")\n",
    "            print(i)\n",
    "            ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "            continue\n",
    "        df[\"SecurityID\"] = int(os.path.basename(i).split('.')[0])\n",
    "        TradeLogSZ += [df]\n",
    "    TradeLogSZ = pd.concat(TradeLogSZ).reset_index(drop=True)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    TradeLogSZ[\"TransactTime\"] = (TradeLogSZ[\"TransactTime\"] - int(y) * 1000000000).astype(np.int64)\n",
    "    TradeLogSZ = TradeLogSZ.rename(columns={\"Qty\":\"TradeQty\"})\n",
    "    TradeLogSZ[\"TradeMoney\"] = (TradeLogSZ[\"TradePrice\"] * TradeLogSZ[\"TradeQty\"]).round(2)\n",
    "    TradeLogSZ1[\"TradeMoney\"] = TradeLogSZ1[\"TradeMoney\"].round(2)\n",
    "    TradeLogSZ[\"TradeBSFlag\"] = 'N'\n",
    "    \n",
    "    TradeLogSZ = TradeLogSZ[TradeLogSZ['ChannelNo'] != 4001]\n",
    "    display(len(TradeLogSZ[\"SecurityID\"].unique()))\n",
    "    display(len(TradeLogSZ1[\"SecurityID\"].unique()))\n",
    "    display(len(set(TradeLogSZ[\"SecurityID\"].unique()) - set(TradeLogSZ1[\"SecurityID\"].unique())))\n",
    "    display(set(TradeLogSZ[\"SecurityID\"].unique()) - set(TradeLogSZ1[\"SecurityID\"].unique()))\n",
    "\n",
    "\n",
    "    sl = list(set(TradeLogSZ[\"SecurityID\"].unique()) & set(TradeLogSZ1['SecurityID'].unique()))\n",
    "    TradeLogSZ = TradeLogSZ[TradeLogSZ[\"SecurityID\"].isin(sl)]\n",
    "    TradeLogSZ1 = TradeLogSZ1[TradeLogSZ1[\"SecurityID\"].isin(sl)]\n",
    "    print(len(TradeLogSZ[\"SecurityID\"].unique()))\n",
    "    print(len(TradeLogSZ1[\"SecurityID\"].unique()))\n",
    "    \n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SZ trade data:')\n",
    "    \n",
    "    TradeLogSZ[\"ExecType\"] = TradeLogSZ[\"ExecType\"].apply(lambda x: str(x))\n",
    "    TradeLogSZ1[\"ExecType\"] = TradeLogSZ1[\"ExecType\"].apply(lambda x: str(x))\n",
    "\n",
    "    columns = [\"TransactTime\",\"ApplSeqNum\", \"SecurityID\", \"ExecType\", \"TradeBSFlag\",\"TradePrice\", \"TradeQty\", \"TradeMoney\", \"BidApplSeqNum\",\"OfferApplSeqNum\"]\n",
    "    ree = pd.merge(TradeLogSZ, TradeLogSZ1, left_on=columns, right_on=columns, how=\"outer\", validate='one_to_one')\n",
    "    n1 = ree[\"Price\"].count()\n",
    "    n2 = ree[\"sequenceNo\"].count()\n",
    "    len1 = len(ree)\n",
    "    re['date'].append(y)\n",
    "    re['data'].append('SZ trade data')\n",
    "    re['baseline'].append(n1)\n",
    "    re['test'].append(n2)\n",
    "    re['merge'].append(len1)\n",
    "    if (n1 == len1) & (n2 == len1):\n",
    "        re['time'].append(0)\n",
    "        re['stock_list'].append(0)    \n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        display(\"test is not complete:\")\n",
    "        display(ree[np.isnan(ree[\"sequenceNo\"])])\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo\"])]))\n",
    "        print(np.sort(ree[np.isnan(ree[\"sequenceNo\"])][\"TransactTime\"].unique()))\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo\"])][\"SecurityID\"].unique()))\n",
    "        print(ree[np.isnan(ree[\"sequenceNo\"])][\"SecurityID\"].unique())\n",
    "        re['time'].append(np.sort(ree[np.isnan(ree[\"sequenceNo\"])][\"TransactTime\"].unique()))\n",
    "        re['stock_list'].append(ree[np.isnan(ree[\"sequenceNo\"])][\"SecurityID\"].unique())\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        display(\"baseline is not complete:\")\n",
    "        display(ree[np.isnan(ree[\"Price\"])])\n",
    "        print(np.sort(ree[np.isnan(ree[\"Price\"])][\"TransactTime\"].unique()))\n",
    "        print(len(ree[np.isnan(ree[\"Price\"])][\"SecurityID\"].unique()))\n",
    "        print(ree[np.isnan(ree[\"Price\"])][\"SecurityID\"].unique())\n",
    "        display(n2-n1)\n",
    "        re['time'].append(np.sort(ree[np.isnan(ree[\"sequenceNo\"])][\"TransactTime\"].unique()))\n",
    "        re['stock_list'].append(ree[np.isnan(ree[\"sequenceNo\"])][\"SecurityID\"].unique())\n",
    "    del TradeLogSZ\n",
    "    del TradeLogSZ1\n",
    "    del ree\n",
    "\n",
    "    \n",
    "    re = pd.DataFrame(re) \n",
    "    re.to_csv('D:\\\\work\\\\project 7 snapshot data\\\\zt_88_03\\\\' + y + '.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumTrades</th>\n",
       "      <th>LastPx</th>\n",
       "      <th>ImageStatus</th>\n",
       "      <th>Amount</th>\n",
       "      <th>AveragePx</th>\n",
       "      <th>TotalLongPosition</th>\n",
       "      <th>MsgSeqNum</th>\n",
       "      <th>OfferPrice</th>\n",
       "      <th>BidPrice</th>\n",
       "      <th>OfferQty</th>\n",
       "      <th>PeRatio2</th>\n",
       "      <th>SendingTime</th>\n",
       "      <th>Volume</th>\n",
       "      <th>PeRatio1</th>\n",
       "      <th>BidOrderQty</th>\n",
       "      <th>TradingPhaseCode</th>\n",
       "      <th>QuotTime</th>\n",
       "      <th>OpenPx</th>\n",
       "      <th>PreWeightedAvgPx</th>\n",
       "      <th>HighPx</th>\n",
       "      <th>ClosePx</th>\n",
       "      <th>WeightedAvgPxChg</th>\n",
       "      <th>PreClosePx</th>\n",
       "      <th>LowPx</th>\n",
       "      <th>StockID</th>\n",
       "      <th>bid1p</th>\n",
       "      <th>ask1p</th>\n",
       "      <th>bid1q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16693</td>\n",
       "      <td>[0.0,0.0,0.0,0.0,0.0]</td>\n",
       "      <td>[0.0,0.0,0.0,0.0,0.0]</td>\n",
       "      <td>[0,0,0,0,0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20200813084029000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0,0,0,0,0]</td>\n",
       "      <td>S 10</td>\n",
       "      <td>20200813084029210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>603676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NumTrades  LastPx  ImageStatus  Amount  AveragePx  TotalLongPosition  \\\n",
       "0          0     0.0            1     0.0        0.0                  0   \n",
       "\n",
       "   MsgSeqNum             OfferPrice               BidPrice     OfferQty  \\\n",
       "0      16693  [0.0,0.0,0.0,0.0,0.0]  [0.0,0.0,0.0,0.0,0.0]  [0,0,0,0,0]   \n",
       "\n",
       "   PeRatio2        SendingTime  Volume  PeRatio1  BidOrderQty  \\\n",
       "0       0.0  20200813084029000       0       0.0  [0,0,0,0,0]   \n",
       "\n",
       "  TradingPhaseCode           QuotTime  OpenPx  PreWeightedAvgPx  HighPx  \\\n",
       "0             S 10  20200813084029210     0.0               0.0     0.0   \n",
       "\n",
       "   ClosePx  WeightedAvgPxChg  PreClosePx  LowPx  StockID  bid1p  ask1p  bid1q  \n",
       "0      0.0               0.0       11.66    0.0   603676    0.0    0.0      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logSH2.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
