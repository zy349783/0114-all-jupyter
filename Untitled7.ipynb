{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "import numpy as np\n",
    "import TSLPy3\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def read_daily(self, table_name, start_date=None, end_date=None, index_id=None, skey=None, interval=None, col=None,\n",
    "                   return_sdi=True):\n",
    "        collection = self.db[table_name]\n",
    "        # Build projection\n",
    "        prj = {'_id': 0}\n",
    "        if col is not None:\n",
    "            if return_sdi:\n",
    "                col = ['skey', 'date', 'interval'] + col\n",
    "            for col_name in col:\n",
    "                prj[col_name] = 1\n",
    "\n",
    "        # Build query\n",
    "        query = {}\n",
    "        if skey is not None:\n",
    "            query['skey'] = {'$in': skey}\n",
    "        if index_id is not None:\n",
    "            query['index_id'] = {'$in': index_id}\n",
    "        if interval is not None:\n",
    "            query['interval'] = {'$in': interval}\n",
    "        if start_date is not None:\n",
    "            if end_date is not None:\n",
    "                query['date'] = {'$gte': start_date, '$lte': end_date}\n",
    "            else:\n",
    "                query['date'] = {'$gte': start_date}\n",
    "        elif end_date is not None:\n",
    "            query['date'] = {'$lte': end_date}\n",
    "\n",
    "        # Load data\n",
    "        cur = collection.find(query, prj)\n",
    "        df = pd.DataFrame.from_records(cur)\n",
    "        if df.empty:\n",
    "            df = pd.DataFrame()\n",
    "        else:\n",
    "            df = df.sort_values(by=['date', 'index_id', 'skey'])\n",
    "        return df\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "\n",
    "\n",
    "patch_pandas_pickle()\n",
    "\n",
    "def DB1(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    url = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    client = pymongo.MongoClient(url, maxPoolSize=None)\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "\n",
    "def write_filter_data(db, name, df):\n",
    "    collection = db[name]\n",
    "    df1 = []\n",
    "    for symbol in df['skey'].unique():\n",
    "        if symbol in collection.distinct('skey'):\n",
    "            symbol = int(symbol)\n",
    "            m_ax = pd.DataFrame.from_records(collection.find({'skey':{'$in':[symbol]}}).sort([('date',-1)]).skip(0).limit(1))['date'].values[0]\n",
    "#             df2 = df[(df['skey'] == symbol) & (df['date'] > m_ax)]\n",
    "            df2 = df[(df['skey'] == symbol)]\n",
    "            print(df2)\n",
    "            df1 += [df2]\n",
    "        else:\n",
    "            print(symbol)\n",
    "            df2 = df[(df['skey'] == symbol)]\n",
    "            print(df2)\n",
    "            df1 += [df2]\n",
    "    df1 = pd.concat(df1).reset_index(drop=True)\n",
    "    df1 = df1.to_dict('records')\n",
    "    collection.insert_many(df1) \n",
    "\n",
    "def build_filter_query(start_date=None, end_date=None, skey=None):\n",
    "    query = {}\n",
    "    def parse_date(x):\n",
    "        if type(x) == int:\n",
    "            return x\n",
    "        elif type(x) == str:\n",
    "            if len(x) != 8:\n",
    "                raise Exception(\"date must be YYYYMMDD format\")\n",
    "            return int(x)\n",
    "        elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "            return x.strftime(\"%Y%m%d\").astype(int)\n",
    "        else:\n",
    "            raise Exception(\"invalid date type: \" + str(type(x)))\n",
    "    if start_date is not None or end_date is not None:\n",
    "        query['date'] = {}\n",
    "        if start_date is not None:\n",
    "            query['date']['$gte'] = parse_date(start_date)\n",
    "        if end_date is not None:\n",
    "            query['date']['$lte'] = parse_date(end_date)\n",
    "    def parse_symbol(x):\n",
    "        if type(x) == int:\n",
    "            return x\n",
    "        else:\n",
    "            return int(x)\n",
    "    if skey:\n",
    "        if type(skey) == list or type(skey) == tuple:\n",
    "            query['skey'] = {'$in': [parse_symbol(x) for x in skey]}\n",
    "        else:\n",
    "            query['skey'] = parse_symbol(skey)\n",
    "    return query\n",
    "\n",
    "def delete_filter_data(db, name, start_date=None, end_date=None, skey=None):\n",
    "    collection = db[name]\n",
    "    query = build_filter_query(start_date, end_date, skey)\n",
    "    if not query:\n",
    "        print('cannot delete the whole table')\n",
    "        return None\n",
    "    collection.delete_many(query)    \n",
    "\n",
    "def read_filter_daily(db, name, start_date=None, end_date=None, skey=None, interval=None, col=None, return_sdi=True):\n",
    "    collection = db[name]\n",
    "    # Build projection\n",
    "    prj = {'_id': 0}\n",
    "    if col is not None:\n",
    "        if return_sdi:\n",
    "            col = ['skey', 'date', 'interval'] + col\n",
    "        for col_name in col:\n",
    "            prj[col_name] = 1\n",
    "\n",
    "    # Build query\n",
    "    query = {}\n",
    "    if skey is not None:\n",
    "        query['skey'] = {'$in': skey}\n",
    "    if interval is not None:\n",
    "        query['interval'] = {'$in': interval}\n",
    "    if start_date is not None:\n",
    "        if end_date is not None:\n",
    "            query['date'] = {'$gte': start_date, '$lte': end_date}\n",
    "        else:\n",
    "            query['date'] = {'$gte': start_date}\n",
    "    elif end_date is not None:\n",
    "        query['date'] = {'$lte': end_date}\n",
    "\n",
    "    # Load data\n",
    "    cur = collection.find(query, prj)\n",
    "    df = pd.DataFrame.from_records(cur)\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        df = df.sort_values(by=['date','skey'])\n",
    "    return df  \n",
    "\n",
    "\n",
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "\n",
    "pd.set_option('max_columns', 200)\n",
    "db1 = DB1(\"192.168.10.178\", database_name, user, password)\n",
    "\n",
    "def getTradeDate(begT, endT):\n",
    "    tsstr = \"\"\"    begt := %s;\n",
    "                   endt := %s;\n",
    "                   begt_:=datetoint(begt);\n",
    "                   endt_:=datetoint(endt);\n",
    "                   dayArr:=sselect inttodate(['截止日']) from infotable 753 of 'SH000001'\n",
    "                               where ['截止日']>=begt_\n",
    "                                     and ['截止日']<=endt_\n",
    "                                     and ['是否交易日']=1\n",
    "                                     order by ['截止日'] end;\n",
    "                   if not istable(dayArr) then endt1:=endt;\n",
    "                   else endt1:=dayArr[0];\n",
    "                   hisArr:=MarketTradeDayQk(begt,endt1);\n",
    "                   dateDf := hisArr union2 dayArr;\n",
    "                   dateDf := select [0] as 'date' from `dateDf end;\n",
    "                   dateDf[:]['date'] := datetostr(dateDf[:]['date']);\n",
    "                   return dateDf; \"\"\" % (begT + 'T', endT + 'T')\n",
    "    dateDf = pd.DataFrame(TSLPy3.RemoteExecute(tsstr, {})[1])\n",
    "    dateDf.columns = list(pd.Series(dateDf.columns).str.decode('GBK'))\n",
    "    dateDf['date'] = dateDf['date'].str.decode('GBK')\n",
    "\n",
    "    return dateDf\n",
    "\n",
    "# ## Version one\n",
    "# def sta_sizeFilter(stockID, startDate, endDate, regWindowSize=20, weekInterval=1):\n",
    "#     database_name = 'com_md_eq_cn'\n",
    "#     user = \"zhenyuy\"\n",
    "#     password = \"bnONBrzSMGoE\"\n",
    "\n",
    "#     pd.set_option('max_columns', 200)\n",
    "#     db = DB(\"192.168.10.178\", database_name, user, password)\n",
    "\n",
    "#     print(' ...... Now Calculating SizeFilter for  ', stockID)\n",
    "#     #    startTm = datetime.datetime.now()\n",
    "#     stockData = db.read('md_snapshot_l2', start_date=startDate, end_date=endDate, symbol=[stockID])\n",
    "#     stockData = stockData.loc[((stockData.bid1p != 0) | (stockData.ask1p != 0)), \\\n",
    "#                               ['skey', 'date', 'time', 'clockAtArrival', 'datetime', 'ordering',\n",
    "#                                'cum_amount', 'bid1p', 'bid1q', 'bid5q', 'ask5q']].reset_index(drop=True)\n",
    "#     stockData = stockData[((stockData.time >= 93000000000) & (stockData.time <= 113000000000)) | \\\n",
    "#                           ((stockData.time >= 130000000000) & (stockData.time <= 150000000000))].reset_index(drop=True)\n",
    "#     indexDaily = db.read_daily('index_memb', start_date=startDate, end_date=endDate, index_id=[1000905])\n",
    "#     indexDaily['tradeConsDay'] = indexDaily.groupby(['date']).grouper.group_info[0]\n",
    "#     indexDaily = indexDaily.groupby('date')['tradeConsDay'].first().reset_index()\n",
    "#     df_train = stockData.merge(indexDaily[['date', 'tradeConsDay']], how='left', on=['date'], validate='many_to_one')\n",
    "\n",
    "#     df_train = df_train[(df_train['time'] >= 93000000000) & (df_train['time'] < 145655000000)].reset_index(drop=True)\n",
    "#     groupAllData = df_train.groupby(['skey', 'date'])\n",
    "#     df_train['amountThisUpdate'] = df_train.cum_amount - groupAllData['cum_amount'].shift(1)\n",
    "#     df_train['amountThisUpdate'] = np.where(pd.isnull(df_train.amountThisUpdate), df_train.cum_amount,\n",
    "#                                             df_train.amountThisUpdate)\n",
    "\n",
    "#     ### add useful day indicator\n",
    "#     df_train['curNearLimit'] = np.where((df_train.ask5q == 0) | (df_train.bid5q == 0), 1.0, 0.0)\n",
    "#     df_train['curNearLimit_L1'] = groupAllData['curNearLimit'].shift(1)\n",
    "#     df_train['dailyCount'] = groupAllData['time'].transform('count')\n",
    "#     df_train['nearLimitCount'] = groupAllData['curNearLimit'].transform('sum')\n",
    "#     dateInfo = groupAllData['dailyCount', 'nearLimitCount', 'tradeConsDay'].mean().reset_index()\n",
    "#     del groupAllData\n",
    "#     dateInfo['useFlag'] = np.where(dateInfo['nearLimitCount'] * 2 < dateInfo['dailyCount'], 1, 0)\n",
    "#     dateInfo['useConsDay'] = dateInfo['useFlag'].cumsum()\n",
    "#     df_train = pd.merge(df_train, dateInfo[['date', 'tradeConsDay', 'useFlag', 'useConsDay']],\n",
    "#                         how='left', on=['date', 'tradeConsDay'], validate='many_to_one')\n",
    "\n",
    "#     df_train['weekday'] = df_train['datetime'].dt.weekday\n",
    "#     sizeFilterData = df_train.groupby(['date'])['tradeConsDay'].first().reset_index()\n",
    "#     sizeFilterData['amountFilter'] = np.nan\n",
    "#     ## we only update on Thrusday\n",
    "#     regDays = sorted(list(df_train.loc[df_train.weekday == 3, 'tradeConsDay'].unique()))\n",
    "\n",
    "#     weekInterval = 1\n",
    "#     for d in range(int(regWindowSize / 5), len(regDays), weekInterval):\n",
    "#         amountFilter = np.nan\n",
    "#         ## get current Thrusday\n",
    "#         endTradeConsDay = regDays[d]\n",
    "#         endUseConsDay = dateInfo[dateInfo['tradeConsDay'] == endTradeConsDay]['useConsDay'].values[0]\n",
    "#         startUseConsDay = max(endUseConsDay - regWindowSize + 1, 1)\n",
    "\n",
    "#         ## check 60 consecutive days\n",
    "#         if dateInfo['useConsDay'].max() < 1:\n",
    "#             amountFilter = np.nan\n",
    "#             continue\n",
    "#         startTradeConsDay = dateInfo[dateInfo['useConsDay'] == startUseConsDay]['tradeConsDay'].values[0]\n",
    "#         endTradeConsDay = dateInfo[dateInfo['tradeConsDay'] == endTradeConsDay]['tradeConsDay'].values[0]\n",
    "#         if (endTradeConsDay - startTradeConsDay > 59) or (endUseConsDay - startUseConsDay < 9):\n",
    "#             amountFilter = np.nan\n",
    "#             continue\n",
    "#             ## get the Monday right after current Thursday update\n",
    "#         oss_intdate = df_train.loc[df_train.tradeConsDay == endTradeConsDay, 'date'].unique()[0]\n",
    "#         oss_intdate = (datetime.datetime.strptime(str(oss_intdate), '%Y%m%d') - datetime.datetime(1899, 12,\n",
    "#                                                                                                   30)).days + 4\n",
    "#         oss = int((datetime.datetime(1899, 12, 30) + datetime.timedelta(int(oss_intdate))).strftime('%Y%m%d'))\n",
    "#         ## get the Friday right after next Thursday update\n",
    "#         if d >= len(regDays) - weekInterval:\n",
    "#             # we should update the data from this Friday to next Thursday\n",
    "#             try:\n",
    "#                 assert(df_train.loc[df_train['tradeConsDay'] == regDays[d], 'date'].values[0] == df_train.date.max())\n",
    "#                 next_t = (datetime.datetime.strptime(str(df_train.date.max()), '%Y%m%d') - datetime.datetime(1899, 12,\n",
    "#                                                                                                            30)).days + 7\n",
    "#                 next_t = int((datetime.datetime(1899, 12, 30) + datetime.timedelta(int(next_t))).strftime('%Y%m%d'))\n",
    "#                 m = 2\n",
    "#                 n_next_t = getTradeDate(str(df_train.date.max()), str(next_t))['date'].astype(str).apply(lambda x: int(x.replace('-', ''))).max()\n",
    "#                 while n_next_t != next_t:\n",
    "#                     next_t = (datetime.datetime.strptime(str(df_train.date.max()), '%Y%m%d') - datetime.datetime(1899,\n",
    "#                                                                                                                  12,\n",
    "#                                                                                                                  30)).days + 7 * m\n",
    "#                     next_t = int((datetime.datetime(1899, 12, 30) + datetime.timedelta(int(next_t))).strftime('%Y%m%d'))\n",
    "#                     n_next_t = getTradeDate(str(df_train.date.max()), str(next_t))['date'].astype(str).apply(\n",
    "#                         lambda x: int(x.replace('-', ''))).max()\n",
    "#                     print(next_t)\n",
    "#                     print(n_next_t)\n",
    "#                     m = m + 1\n",
    "#                 assert(datetime.datetime.strptime(str(next_t), '%Y%m%d').weekday() == 3)\n",
    "#                 ose = (datetime.datetime.strptime(str(next_t), '%Y%m%d') - datetime.datetime(1899, 12,\n",
    "#                                                                                                            30)).days + 1\n",
    "#                 ose = int((datetime.datetime(1899, 12, 30) + datetime.timedelta(int(ose))).strftime('%Y%m%d'))\n",
    "#                 add = getTradeDate(str(df_train.date.max()), str(ose))['date'].astype(str).apply(\n",
    "#                         lambda x: int(x.replace('-', '')))\n",
    "#                 for i in add:\n",
    "#                     if i in sizeFilterData['date'].values:\n",
    "#                         continue\n",
    "#                     else:\n",
    "#                         if (datetime.datetime.strptime(str(i), '%Y%m%d') - datetime.datetime.strptime(str(df_train.date.max()), '%Y%m%d')).days == 1:\n",
    "#                             sizeFilterData = sizeFilterData.append(\n",
    "#                                 pd.DataFrame([[i, sizeFilterData.tradeConsDay.max() + 1, sizeFilterData.loc[sizeFilterData['date'] == df_train.date.max(), 'amountFilter'].values[0]]],\n",
    "#                                              columns=['date', 'tradeConsDay', 'amountFilter']))\n",
    "#                         else:\n",
    "#                             sizeFilterData = sizeFilterData.append(\n",
    "#                             pd.DataFrame([[i, sizeFilterData.tradeConsDay.max() + 1, np.nan]],\n",
    "#                                          columns=['date', 'tradeConsDay', 'amountFilter']))\n",
    "#             except:\n",
    "#                 ose = df_train.date.max()\n",
    "#         else:\n",
    "#             ose_intdate = df_train.loc[df_train.tradeConsDay == regDays[d + weekInterval], 'date'].unique()[0]\n",
    "#             ose_intdate = (datetime.datetime.strptime(str(ose_intdate), '%Y%m%d') - datetime.datetime(1899, 12,\n",
    "#                                                                                                       30)).days + 1\n",
    "#             ose = int((datetime.datetime(1899, 12, 30) + datetime.timedelta(int(ose_intdate))).strftime('%Y%m%d'))\n",
    "#         inSampleSlice = df_train[(df_train.useConsDay >= startUseConsDay) & \\\n",
    "#                                  (df_train.useConsDay <= endUseConsDay) & \\\n",
    "#                                  (df_train.useFlag == 1)].reset_index(drop=True)\n",
    "#         amountFilter = inSampleSlice[(inSampleSlice['curNearLimit'] == 0) & \\\n",
    "#                                      (inSampleSlice['curNearLimit_L1'] == 0)].amountThisUpdate.quantile(.75)\n",
    "#         if ose < oss:\n",
    "#             print('out of sample end day < start day, skip')\n",
    "#             continue\n",
    "#         sizeFilterData.loc[(sizeFilterData.date >= oss) & (sizeFilterData.date <= ose), 'amountFilter'] = amountFilter\n",
    "#     sizeFilterData['skey'] = int(stockID)\n",
    "#     sizeFilterData = sizeFilterData[['skey', 'date', 'amountFilter']]\n",
    "#     sizeFilterData['amountFilter'] = sizeFilterData['amountFilter'].fillna(0)\n",
    "#     sizeFilterData = sizeFilterData.rename(columns={'amountFilter': 'size_filter'})\n",
    "#     sizeFilterData = sizeFilterData.sort_values(by='date').reset_index(drop=True)\n",
    "# #     if sizeFilterData.empty == False:\n",
    "# #         write_filter_data(db1, 'md_stock_sizefilter', sizeFilterData)\n",
    "#     return sizeFilterData\n",
    "\n",
    "# Version two\n",
    "def sta_sizeFilter(stockID, startDate, endDate, regWindowSize=20, weekInterval=1):\n",
    "    database_name = 'com_md_eq_cn'\n",
    "    user = \"zhenyuy\"\n",
    "    password = \"bnONBrzSMGoE\"\n",
    "\n",
    "    pd.set_option('max_columns', 200)\n",
    "    db = DB(\"192.168.10.178\", database_name, user, password)\n",
    "\n",
    "    print(' ...... Now Calculating SizeFilter for  ', stockID)\n",
    "    #    startTm = datetime.datetime.now()\n",
    "    stockData = db.read('md_snapshot_l2', start_date=startDate, end_date=endDate, symbol=[stockID])\n",
    "    stockData = stockData.loc[((stockData.bid1p != 0) | (stockData.ask1p != 0)), \\\n",
    "                              ['skey', 'date', 'time', 'clockAtArrival', 'datetime', 'ordering',\n",
    "                               'cum_amount', 'bid1p', 'bid1q', 'bid5q', 'ask5q']].reset_index(drop=True)\n",
    "    stockData = stockData[((stockData.time >= 93000000000) & (stockData.time <= 113000000000)) | \\\n",
    "                          ((stockData.time >= 130000000000) & (stockData.time <= 150000000000))].reset_index(drop=True)\n",
    "    indexDaily = db.read_daily('index_memb', start_date=startDate, end_date=endDate, index_id=[1000905])\n",
    "    indexDaily['tradeConsDay'] = indexDaily.groupby(['date']).grouper.group_info[0]\n",
    "    indexDaily = indexDaily.groupby('date')['tradeConsDay'].first().reset_index()\n",
    "    df_train = stockData.merge(indexDaily[['date', 'tradeConsDay']], how='left', on=['date'], validate='many_to_one')\n",
    "\n",
    "    df_train = df_train[(df_train['time'] >= 93000000000) & (df_train['time'] < 145655000000)].reset_index(drop=True)\n",
    "    groupAllData = df_train.groupby(['skey', 'date'])\n",
    "    df_train['amountThisUpdate'] = df_train.cum_amount - groupAllData['cum_amount'].shift(1)\n",
    "    df_train['amountThisUpdate'] = np.where(pd.isnull(df_train.amountThisUpdate), df_train.cum_amount,\n",
    "                                            df_train.amountThisUpdate)\n",
    "\n",
    "    ### add useful day indicator\n",
    "    df_train['curNearLimit'] = np.where((df_train.ask5q == 0) | (df_train.bid5q == 0), 1.0, 0.0)\n",
    "    df_train['curNearLimit_L1'] = groupAllData['curNearLimit'].shift(1)\n",
    "    df_train['dailyCount'] = groupAllData['time'].transform('count')\n",
    "    df_train['nearLimitCount'] = groupAllData['curNearLimit'].transform('sum')\n",
    "    dateInfo = groupAllData['dailyCount', 'nearLimitCount', 'tradeConsDay'].mean().reset_index()\n",
    "    del groupAllData\n",
    "    dateInfo['useFlag'] = np.where(dateInfo['nearLimitCount'] * 2 < dateInfo['dailyCount'], 1, 0)\n",
    "    dateInfo['useConsDay'] = dateInfo['useFlag'].cumsum()\n",
    "    df_train = pd.merge(df_train, dateInfo[['date', 'tradeConsDay', 'useFlag', 'useConsDay']],\n",
    "                        how='left', on=['date', 'tradeConsDay'], validate='many_to_one')\n",
    "\n",
    "    df_train['weekday'] = df_train['datetime'].dt.weekday\n",
    "    sizeFilterData = df_train.groupby(['date'])['tradeConsDay'].first().reset_index()\n",
    "    sizeFilterData['amountFilter'] = np.nan\n",
    "    \n",
    "    regDays = sorted(list(df_train.loc[df_train.weekday == 3, 'tradeConsDay'].unique()))\n",
    "    \n",
    "    assert(datetime.datetime.strptime(str(endDate), \"%Y%m%d\").weekday() == 3)\n",
    "    if sizeFilterData.empty == False:\n",
    "        try:\n",
    "            endTradeConsDay = regDays[-1]\n",
    "            endUseConsDay = dateInfo[dateInfo['tradeConsDay'] == endTradeConsDay]['useConsDay'].values[0]\n",
    "            startUseConsDay = max(endUseConsDay - regWindowSize + 1, 1)\n",
    "\n",
    "            startTradeConsDay = dateInfo[dateInfo['useConsDay'] == startUseConsDay]['tradeConsDay'].values[0]\n",
    "            endTradeConsDay = dateInfo[dateInfo['tradeConsDay'] == endTradeConsDay]['tradeConsDay'].values[0]\n",
    "\n",
    "            ## check 60 consecutive days\n",
    "            if (dateInfo['useConsDay'].max() < 1) | (endTradeConsDay - startTradeConsDay > 59) | (endUseConsDay - startUseConsDay < 9):\n",
    "                amountFilter = np.nan\n",
    "            else:\n",
    "                inSampleSlice = df_train[(df_train.useConsDay >= startUseConsDay) & \\\n",
    "                                         (df_train.useConsDay <= endUseConsDay) & \\\n",
    "                                         (df_train.useFlag == 1)].reset_index(drop=True)\n",
    "                amountFilter = inSampleSlice[(inSampleSlice['curNearLimit'] == 0) & \\\n",
    "                                             (inSampleSlice['curNearLimit_L1'] == 0)].amountThisUpdate.quantile(.75)\n",
    "        except:\n",
    "            amountFilter = np.nan\n",
    "\n",
    "        oss_intdate = endDate\n",
    "        oss_intdate = (datetime.datetime.strptime(str(oss_intdate), '%Y%m%d') - datetime.datetime(1899, 12, 30)).days + 4\n",
    "        oss = int((datetime.datetime(1899, 12, 30) + datetime.timedelta(int(oss_intdate))).strftime('%Y%m%d'))\n",
    "\n",
    "        next_t = (datetime.datetime.strptime(str(endDate), '%Y%m%d') - datetime.datetime(1899, 12, 30)).days + 7\n",
    "        next_t = int((datetime.datetime(1899, 12, 30) + datetime.timedelta(int(next_t))).strftime('%Y%m%d'))\n",
    "        m = 2\n",
    "        n_next_t = getTradeDate(str(df_train.date.max()), str(next_t))['date'].astype(str).apply(lambda x: int(x.replace('-', ''))).max()\n",
    "        while n_next_t != next_t:\n",
    "            next_t = (datetime.datetime.strptime(str(endDate), '%Y%m%d') - datetime.datetime(1899, 12, 30)).days + 7 * m\n",
    "            next_t = int((datetime.datetime(1899, 12, 30) + datetime.timedelta(int(next_t))).strftime('%Y%m%d'))\n",
    "            n_next_t = getTradeDate(str(endDate), str(next_t))['date'].astype(str).apply(\n",
    "                lambda x: int(x.replace('-', ''))).max()\n",
    "            m = m + 1\n",
    "        assert(datetime.datetime.strptime(str(next_t), '%Y%m%d').weekday() == 3)\n",
    "        ose = (datetime.datetime.strptime(str(next_t), '%Y%m%d') - datetime.datetime(1899, 12, 30)).days + 1\n",
    "        ose = int((datetime.datetime(1899, 12, 30) + datetime.timedelta(int(ose))).strftime('%Y%m%d'))\n",
    "        add = getTradeDate(str(oss), str(ose))['date'].astype(str).apply(\n",
    "                lambda x: int(x.replace('-', '')))\n",
    "        re = pd.DataFrame()\n",
    "        m = 1\n",
    "        for i in add:\n",
    "            re = pd.concat([re, pd.DataFrame([[i, sizeFilterData.tradeConsDay.max() + m, np.nan]],\n",
    "                             columns=['date', 'tradeConsDay', 'amountFilter'])])\n",
    "            m = m + 1\n",
    "\n",
    "        re.loc[(re.date >= oss) & (re.date <= ose), 'amountFilter'] = amountFilter\n",
    "        re['skey'] = int(stockID)\n",
    "        re = re[['skey', 'date', 'amountFilter']]\n",
    "        re['amountFilter'] = re['amountFilter'].fillna(0)\n",
    "        re = re.rename(columns={'amountFilter': 'size_filter'})\n",
    "        re = re.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "        write_filter_data(db1, 'md_stock_sizefilter', re)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# # Version three 0501-1016?? (0501-1015, 1016用之前预测的 Version 2 0501-0924 fill up, \n",
    "# # 是否会出现停牌时间特别长的情况，和当前database数据最大值的差值是多少？？？)\n",
    "# def sta_sizeFilter(stockID, startDate, endDate, regWindowSize = 20, weekInterval = 1): \n",
    "#     database_name = 'com_md_eq_cn'\n",
    "#     user = \"zhenyuy\"\n",
    "#     password = \"bnONBrzSMGoE\"\n",
    "\n",
    "#     pd.set_option('max_columns', 200)\n",
    "#     db = DB(\"192.168.10.178\", database_name, user, password)\n",
    "\n",
    "#     print(' ...... Now Calculating SizeFilter for  ', stockID)\n",
    "#     #    startTm = datetime.datetime.now()\n",
    "#     stockData = db.read('md_snapshot_l2', start_date=startDate, end_date=endDate, symbol=[stockID])\n",
    "#     stockData = stockData.loc[((stockData.bid1p != 0) | (stockData.ask1p != 0)), \\\n",
    "#                               ['skey','date','time','clockAtArrival','datetime','ordering',\n",
    "#                                'cum_amount','bid1p','bid1q','bid5q','ask5q']].reset_index(drop=True)\n",
    "#     stockData = stockData[((stockData.time >= 93000000000) & (stockData.time <= 113000000000)) | \\\n",
    "#                           ((stockData.time >= 130000000000) & (stockData.time <= 150000000000))].reset_index(drop=True)\n",
    "#     indexDaily = db.read_daily('index_memb', start_date=startDate, end_date=endDate, index_id=[1000905])\n",
    "#     indexDaily['tradeConsDay'] = indexDaily.groupby(['date']).grouper.group_info[0]\n",
    "#     indexDaily = indexDaily.groupby('date')['tradeConsDay'].first().reset_index()\n",
    "#     df_train = stockData.merge(indexDaily[['date','tradeConsDay']], how='left', on=['date'], validate='many_to_one')\n",
    "    \n",
    "#     df_train = df_train[(df_train['time'] >= 93000000000) & (df_train['time'] < 145655000000)].reset_index(drop=True)\n",
    "#     groupAllData = df_train.groupby(['skey','date'])\n",
    "#     df_train['amountThisUpdate'] = df_train.cum_amount - groupAllData['cum_amount'].shift(1)\n",
    "#     df_train['amountThisUpdate'] = np.where(pd.isnull(df_train.amountThisUpdate), df_train.cum_amount, df_train.amountThisUpdate)\n",
    "\n",
    "#     ### add useful day indicator\n",
    "#     df_train['curNearLimit'] = np.where((df_train.ask5q == 0) | (df_train.bid5q == 0), 1.0, 0.0)\n",
    "#     df_train['curNearLimit_L1'] = groupAllData['curNearLimit'].shift(1)\n",
    "#     df_train['dailyCount'] = groupAllData['time'].transform('count')\n",
    "#     df_train['nearLimitCount'] = groupAllData['curNearLimit'].transform('sum')\n",
    "#     dateInfo = groupAllData['dailyCount', 'nearLimitCount', 'tradeConsDay'].mean().reset_index()\n",
    "#     del groupAllData\n",
    "#     dateInfo['useFlag'] = np.where(dateInfo['nearLimitCount']*2 < dateInfo['dailyCount'], 1, 0)\n",
    "#     dateInfo['useConsDay'] = dateInfo['useFlag'].cumsum()\n",
    "#     df_train = pd.merge(df_train, dateInfo[['date', 'tradeConsDay', 'useFlag', 'useConsDay']],\n",
    "#                         how='left', on=['date', 'tradeConsDay'], validate='many_to_one') \n",
    "    \n",
    "#     df_train['weekday'] = df_train['datetime'].dt.weekday\n",
    "#     sizeFilterData = df_train.groupby(['date'])['tradeConsDay'].first().reset_index()\n",
    "#     sizeFilterData['amountFilter'] = np.nan\n",
    "#     ## we only update on Thrusday\n",
    "#     regDays = sorted(list(df_train.loc[df_train.weekday == 3, 'tradeConsDay'].unique()))      \n",
    "#     weekInterval = 1    \n",
    "#     for d in range(int(regWindowSize/5), len(regDays), weekInterval):\n",
    "#         amountFilter = np.nan\n",
    "#         ## get current Thrusday\n",
    "#         endTradeConsDay = regDays[d]\n",
    "#         endUseConsDay = dateInfo[dateInfo['tradeConsDay'] == endTradeConsDay]['useConsDay'].values[0]\n",
    "#         startUseConsDay = max(endUseConsDay - regWindowSize + 1, 1)\n",
    "        \n",
    "#         ## check 60 consecutive days\n",
    "#         if dateInfo['useConsDay'].max() < 1: \n",
    "#             amountFilter = np.nan\n",
    "#             continue\n",
    "#         startTradeConsDay = dateInfo[dateInfo['useConsDay'] == startUseConsDay]['tradeConsDay'].values[0]\n",
    "#         endTradeConsDay = dateInfo[dateInfo['tradeConsDay'] == endTradeConsDay]['tradeConsDay'].values[0]\n",
    "#         if (endTradeConsDay - startTradeConsDay > 59) or (endUseConsDay - startUseConsDay < 9):\n",
    "#             amountFilter = np.nan\n",
    "#             continue      \n",
    "#         ## get the Monday right after current Thursday update\n",
    "#         oss_intdate = df_train.loc[df_train.tradeConsDay == endTradeConsDay, 'date'].unique()[0]\n",
    "#         oss_intdate = (datetime.datetime.strptime(str(oss_intdate), '%Y%m%d') - datetime.datetime(1899,12,30)).days + 4\n",
    "#         oss = int((datetime.datetime(1899,12,30) + datetime.timedelta(int(oss_intdate))).strftime('%Y%m%d'))\n",
    "#         ## get the Friday right after next Thursday update\n",
    "#         if d >= len(regDays) - weekInterval:\n",
    "#             ose = df_train.date.max()\n",
    "#         else:\n",
    "#             ose_intdate = df_train.loc[df_train.tradeConsDay == regDays[d+weekInterval], 'date'].unique()[0]\n",
    "#             ose_intdate = (datetime.datetime.strptime(str(ose_intdate), '%Y%m%d') - datetime.datetime(1899,12,30)).days + 1\n",
    "#             ose =  int((datetime.datetime(1899,12,30) + datetime.timedelta(int(ose_intdate))).strftime('%Y%m%d'))         \n",
    "#         inSampleSlice = df_train[(df_train.useConsDay >= startUseConsDay) &\\\n",
    "#                                (df_train.useConsDay <= endUseConsDay) &\\\n",
    "#                                (df_train.useFlag == 1)].reset_index(drop=True)\n",
    "#         amountFilter = inSampleSlice[(inSampleSlice['curNearLimit'] == 0) &\\\n",
    "#                                      (inSampleSlice['curNearLimit_L1'] == 0)].amountThisUpdate.quantile(.75)\n",
    "#         print(oss)\n",
    "#         print(ose)\n",
    "#         if ose < oss:\n",
    "#             print('out of sample end day < start day, skip')\n",
    "#             continue \n",
    "#         sizeFilterData.loc[(sizeFilterData.date >= oss)&(sizeFilterData.date <= ose), 'amountFilter'] = amountFilter\n",
    "#     sizeFilterData['skey'] = int(stockID)\n",
    "#     sizeFilterData = sizeFilterData[['skey', 'date', 'amountFilter']]\n",
    "#     sizeFilterData['amountFilter'] = sizeFilterData['amountFilter'].fillna(0)\n",
    "#     sizeFilterData = sizeFilterData.rename(columns={'amountFilter': 'size_filter'})\n",
    "#     sizeFilterData = sizeFilterData.sort_values(by='date').reset_index(drop=True)\n",
    "#     if sizeFilterData.empty == False:\n",
    "#         write_filter_data(db1, 'md_stock_sizefilter', sizeFilterData)\n",
    "#     return sizeFilterData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ...... Now Calculating SizeFilter for   2002299\n",
      "      skey      date  size_filter\n",
      "0  2002299  20201026     35329.25\n",
      "1  2002299  20201027     35329.25\n",
      "2  2002299  20201028     35329.25\n",
      "3  2002299  20201029     35329.25\n",
      "4  2002299  20201030     35329.25\n"
     ]
    }
   ],
   "source": [
    "sta_sizeFilter(2002297,startDate=20200601, endDate=20201022, \n",
    "                     regWindowSize = 20, weekInterval = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "\n",
    "def unzip_data():\n",
    "    y = '20201106'\n",
    "    y1 = '202011'\n",
    "    exe_path = 'G:\\\\7z1900-extra\\\\7za.exe'\n",
    "    rar_path = 'L:\\\\KR\\\\data\\\\quant360_data\\\\2020\\\\' + y1 + '\\\\' + y + '\\\\SH\\\\snapshot.7z'\n",
    "    path = '\\\\\\\\192.168.10.34\\\\random_backup\\\\Kevin_zhenyu\\\\KR_daily_data\\\\' +  y\n",
    "    os.mkdir(path)\n",
    "    path1 = path + '\\\\SH'\n",
    "    un_path = path1\n",
    "    cmd = '{} x {} -o{} -aos -r'.format(exe_path, rar_path, un_path)\n",
    "    os.system(cmd)\n",
    "    rar_path = 'L:\\\\KR\\\\data\\\\quant360_data\\\\2020\\\\' + y1 + '\\\\' + y + '\\\\SH\\\\tick.7z'\n",
    "    cmd = '{} x {} -o{} -aos -r'.format(exe_path, rar_path, un_path)\n",
    "    os.system(cmd)\n",
    "    rar_path = 'L:\\\\KR\\\\data\\\\quant360_data\\\\2020\\\\' + y1 + '\\\\' + y + '\\\\SZ\\\\snapshot.7z'\n",
    "    path1 = path + '\\\\SZ'\n",
    "    un_path = path1\n",
    "    cmd = '{} x {} -o{} -aos -r'.format(exe_path, rar_path, un_path)\n",
    "    os.system(cmd)\n",
    "    rar_path = 'L:\\\\KR\\\\data\\\\quant360_data\\\\2020\\\\' + y1 + '\\\\' + y + '\\\\SZ\\\\order.7z'\n",
    "    cmd = '{} x {} -o{} -aos -r'.format(exe_path, rar_path, un_path)\n",
    "    os.system(cmd)\n",
    "    rar_path = 'L:\\\\KR\\\\data\\\\quant360_data\\\\2020\\\\' + y1 + '\\\\' + y + '\\\\SZ\\\\tick.7z'\n",
    "    cmd = '{} x {} -o{} -aos -r'.format(exe_path, rar_path, un_path)\n",
    "    os.system(cmd)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unzip_data()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
