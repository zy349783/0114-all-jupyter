{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2002977, 2300819, 2300821, 2300822, 2300823, 2300825}\n",
      "20200327\n",
      "order finished\n",
      "0:09:00.531404\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>BidApplSeqNum</th>\n",
       "      <th>OfferApplSeqNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [skey, BidApplSeqNum, OfferApplSeqNum]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>BidApplSeqNum</th>\n",
       "      <th>OfferApplSeqNum</th>\n",
       "      <th>union</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1398</td>\n",
       "      <td>2002977</td>\n",
       "      <td>[694, 1092, 54381, 16564, 0, 93550, 105808, 11...</td>\n",
       "      <td>[0, 55123, 57506, 134503, 131765, 46842, 5960,...</td>\n",
       "      <td>[0, 393216, 2, 3, 786436, 5, 6, 7, 8, 9, 78643...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2192</td>\n",
       "      <td>2300819</td>\n",
       "      <td>[22161, 95881, 0, 134998, 143208, 151795, 1168...</td>\n",
       "      <td>[0, 21933, 51189, 135659, 117144, 150273, 1539...</td>\n",
       "      <td>[0, 12189696, 917504, 13959168, 2686982, 59637...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2194</td>\n",
       "      <td>2300821</td>\n",
       "      <td>[0, 82924, 85511, 72015, 141174, 81984, 148629...</td>\n",
       "      <td>[108453, 76094, 0, 34335, 140114, 145657, 1365...</td>\n",
       "      <td>[0, 6815744, 12189698, 13762561, 2621443, 6160...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2195</td>\n",
       "      <td>2300822</td>\n",
       "      <td>[10589, 0, 49813, 129419, 130898, 131353, 1375...</td>\n",
       "      <td>[0, 26772, 62504, 71638, 135411, 133882, 13582...</td>\n",
       "      <td>[0, 16908288, 4587529, 4587530, 11403276, 1310...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2196</td>\n",
       "      <td>2300823</td>\n",
       "      <td>[5882, 5883, 5884, 5903, 5902, 5904, 11665, 13...</td>\n",
       "      <td>[0, 90705, 101163, 99091, 134440, 50522, 14015...</td>\n",
       "      <td>[0, 1, 2, 4, 5, 12976134, 4194311, 13762567, 9...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2197</td>\n",
       "      <td>2300825</td>\n",
       "      <td>[248, 37340, 42273, 45625, 60095, 60017, 61741...</td>\n",
       "      <td>[0, 142805, 165160, 207855, 217078, 179760, 18...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 196613, 6, 8, 10, 11, 12, 13, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         skey                                      BidApplSeqNum  \\\n",
       "1398  2002977  [694, 1092, 54381, 16564, 0, 93550, 105808, 11...   \n",
       "2192  2300819  [22161, 95881, 0, 134998, 143208, 151795, 1168...   \n",
       "2194  2300821  [0, 82924, 85511, 72015, 141174, 81984, 148629...   \n",
       "2195  2300822  [10589, 0, 49813, 129419, 130898, 131353, 1375...   \n",
       "2196  2300823  [5882, 5883, 5884, 5903, 5902, 5904, 11665, 13...   \n",
       "2197  2300825  [248, 37340, 42273, 45625, 60095, 60017, 61741...   \n",
       "\n",
       "                                        OfferApplSeqNum  \\\n",
       "1398  [0, 55123, 57506, 134503, 131765, 46842, 5960,...   \n",
       "2192  [0, 21933, 51189, 135659, 117144, 150273, 1539...   \n",
       "2194  [108453, 76094, 0, 34335, 140114, 145657, 1365...   \n",
       "2195  [0, 26772, 62504, 71638, 135411, 133882, 13582...   \n",
       "2196  [0, 90705, 101163, 99091, 134440, 50522, 14015...   \n",
       "2197  [0, 142805, 165160, 207855, 217078, 179760, 18...   \n",
       "\n",
       "                                                  union ApplSeqNum  \n",
       "1398  [0, 393216, 2, 3, 786436, 5, 6, 7, 8, 9, 78643...        NaN  \n",
       "2192  [0, 12189696, 917504, 13959168, 2686982, 59637...        NaN  \n",
       "2194  [0, 6815744, 12189698, 13762561, 2621443, 6160...        NaN  \n",
       "2195  [0, 16908288, 4587529, 4587530, 11403276, 1310...        NaN  \n",
       "2196  [0, 1, 2, 4, 5, 12976134, 4194311, 13762567, 9...        NaN  \n",
       "2197  [0, 1, 2, 3, 4, 196613, 6, 8, 10, 11, 12, 13, ...        NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-43480bf790de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'skey'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BidApplSeqNum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'OfferApplSeqNum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ApplSeqNum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'less'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mApplSeqNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'less1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mApplSeqNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'less1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-43480bf790de>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'skey'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BidApplSeqNum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'OfferApplSeqNum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ApplSeqNum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'less'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mApplSeqNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'less1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mApplSeqNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'less1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "# 2020 version\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from unrar import rarfile\n",
    "import py7zr\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "columns1 = [\"Date\",\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",\"PreClosePx\",\n",
    "                   \"PxChnage1\",\"PXChange2\",\"openPrice\",\"HighPx\",\"LowPx\",\"close\",\"NumTrades\",\"cum_volume\",\"cum_amount\",\"PE1\",\"PE2\",\"TradingPhase\",\n",
    "                   \"totalofferqty\", \"wa_offerPrice\", \"totalbidqty\", \"wa_bidPrice\", \"PreNAV\", \"RealTimeNAV\", \"WarrantPremiumRate\", \"UpLimitPx\",\n",
    "                   \"DownLimitPx\", \"TotalLongPosition\", \"unknown1\", \"unknown2\", \"unknown3\"]\n",
    "columns2 = ['Date',\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",'ask1p','bid1p',\n",
    "                   \"ask1q\",\"bid1q\", 'ask2p','bid2p',\"ask2q\",\"bid2q\",'ask3p','bid3p',\"ask3q\",\"bid3q\",'ask4p','bid4p',\"ask4q\",\"bid4q\",'ask5p',\n",
    "                    'bid5p',\"ask5q\",\"bid5q\",'ask6p','bid6p',\"ask6q\",\"bid6q\",'ask7p','bid7p',\"ask7q\",\"bid7q\",'ask8p','bid8p',\"ask8q\",\"bid8q\",\n",
    "                   'ask9p','bid9p',\"ask9q\",\"bid9q\",'ask10p','bid10p',\"ask10q\",\"bid10q\",\"NUMORDERS_B1\",\"NOORDERS_B1\",\"ORDERQTY_B1\",\n",
    "                    \"NUMORDERS_S1\",\"NOORDERS_S1\",\"ORDERQTY_S1\"]\n",
    "columns3 =  [\"Date\",\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",\"PreClosePx\",\n",
    "                   \"PxChnage1\",\"PXChange2\",\"openPrice\",\"HighPx\",\"LowPx\",\"close\",\"NumTrades\",\"cum_volume\",\"cum_amount\",\"PE1\",\"PE2\",\"TradingPhase\",\n",
    "                   \"totalofferqty\", \"wa_offerPrice\", \"totalbidqty\", \"wa_bidPrice\", \"PreNAV\", \"RealTimeNAV\", \"WarrantPremiumRate\", \"UpLimitPx\",\n",
    "                   \"DownLimitPx\", \"TotalLongPosition\"]\n",
    "\n",
    "# startTm = datetime.datetime.now()\n",
    "# readPath = r'\\\\192.168.10.30\\Kevin_zhenyu\\day_stock\\***'\n",
    "# dataPathLs = np.array(glob.glob(readPath))\n",
    "# dataPathLs = dataPathLs[[np.array([os.path.basename(i).split('.')[0][:2] == 'SZ' for i in dataPathLs])]]\n",
    "# db = pd.DataFrame()\n",
    "# for p in dataPathLs:\n",
    "#     dayData = pd.read_csv(p, compression='gzip')\n",
    "#     db = pd.concat([db, dayData])\n",
    "# print(datetime.datetime.now() - startTm)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "startDate = \"20200327\"\n",
    "endDate = \"20200327\"\n",
    "df = []\n",
    "bad = []\n",
    "readPath = 'A:\\\\rawData\\\\logs_***_zs_92_01_day_data'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i).split('_')[1] for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "\n",
    "for data in dataPathLs:\n",
    "    readPath = data + '\\\\mdOrderLog***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    OrderLog1 = pd.read_csv(dataPathLs[0], encoding=\"utf-8\").loc[:, [\"clockAtArrival\", \"sequenceNo\", \"exchId\", \"TransactTime\",\n",
    "                                                 \"ApplSeqNum\", \"SecurityID\", \"Side\", \"OrderType\", \"Price\",\n",
    "                                                 \"OrderQty\"]]\n",
    "    OrderLog1 = OrderLog1[(OrderLog1[\"SecurityID\"] < 4000) | (OrderLog1[\"SecurityID\"] > 300000)]\n",
    "    OrderLog1 = OrderLog1.rename(columns={\"Side\":\"order_side\", \"OrderType\":\"order_type\", \"Price\":\"order_price\",\n",
    "                                             \"OrderQty\":'order_qty'})\n",
    "    OrderLog1['date'] = int(os.path.basename(dataPathLs[0]).split('_')[1])\n",
    "    OrderLog1[\"skey\"] = OrderLog1[\"SecurityID\"] + 2000000\n",
    "    OrderLog1[\"time\"] = OrderLog1['TransactTime'].astype(np.int64)*1000\n",
    "    OrderLog1['TransactTime'] = OrderLog1['date'] * 1000000000 + OrderLog1['TransactTime']\n",
    "    OrderLog1[\"clockAtArrival\"] = OrderLog1[\"TransactTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    OrderLog1['datetime'] = OrderLog1[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    OrderLog1[\"order_type\"] =np.where(OrderLog1[\"order_type\"] == 'U', 3, OrderLog1[\"order_type\"])\n",
    "    for col in [\"skey\", \"date\", \"ApplSeqNum\", \"order_qty\", \"order_side\", \"order_type\"]:\n",
    "        OrderLog1[col] = OrderLog1[col].astype('int32')\n",
    "    OrderLog1['order_price'] = OrderLog1['order_price']/10000\n",
    "    display(OrderLog1[\"order_price\"].astype(str).apply(lambda x: len(x.split('.')[1])).unique())\n",
    "    \n",
    "    assert(OrderLog1[((OrderLog1[\"order_side\"] != 1) & (OrderLog1[\"order_side\"] != 2)) | (OrderLog1[\"order_type\"].isnull())].shape[0] == 0)\n",
    "    da_te = str(OrderLog1[\"date\"].iloc[0]) \n",
    "    da_te = da_te[:4] + '-' + da_te[4:6] + '-' + da_te[6:8]\n",
    "    db1 = db[db[\"date\"] == da_te]\n",
    "    sl = (db1[\"ID\"].str[2:].astype(int) + 2000000).unique()\n",
    "    del db1\n",
    "    try:\n",
    "        assert(len(set(sl) - set(OrderLog1[\"skey\"].unique())) == 0)\n",
    "    except:\n",
    "        print(set(sl) - set(OrderLog1[\"skey\"].unique()))\n",
    "    \n",
    "    OrderLog1 = OrderLog1[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ApplSeqNum\", \"order_side\", \"order_type\", \"order_price\",\n",
    "                                                 \"order_qty\"]]\n",
    "    \n",
    "    print(OrderLog1[\"date\"].iloc[0])\n",
    "    print(\"order finished\")\n",
    "    \n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "startDate = 20200327\n",
    "endDate = 20200327\n",
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "db1 = DB(\"192.168.10.223\", database_name, user, password)\n",
    "trade = db1.read('md_trade', start_date=startDate, end_date=endDate)\n",
    "trade = trade[trade['skey'] > 2000000]\n",
    "t1 = trade.groupby('skey')['BidApplSeqNum'].unique().reset_index()\n",
    "t2 = trade.groupby('skey')['OfferApplSeqNum'].unique().reset_index()\n",
    "t3 = OrderLog1.groupby('skey')['ApplSeqNum'].unique().reset_index()\n",
    "t = pd.merge(t1, t2, on='skey', how='outer')\n",
    "display(t[(t['BidApplSeqNum'].isnull()) | (t['OfferApplSeqNum'].isnull())])\n",
    "t['union'] = [list(set(a) | set(b)) for a, b in zip(t.BidApplSeqNum, t.OfferApplSeqNum)]\n",
    "t = pd.merge(t, t3, on='skey', how='outer')\n",
    "display(t[(t['BidApplSeqNum'].isnull()) | (t['OfferApplSeqNum'].isnull()) | (t['ApplSeqNum'].isnull())])\n",
    "t['less'] = [len(set(a) - set(b)) for a, b in zip(t.union, t.ApplSeqNum)]\n",
    "t['less1'] = [list(set(a) - set(b))[0] for a, b in zip(t.union, t.ApplSeqNum)]\n",
    "display(t['less1'].unique())\n",
    "t[t['less'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>BidApplSeqNum</th>\n",
       "      <th>OfferApplSeqNum</th>\n",
       "      <th>union</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "      <th>less</th>\n",
       "      <th>less1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2000016</td>\n",
       "      <td>[0, 84818, 36514, 138993, 139668, 139126, 1440...</td>\n",
       "      <td>[5031, 64213, 73250, 0, 93332, 21514, 126063, ...</td>\n",
       "      <td>[0, 12582913, 2621449, 12582924, 17825807, 104...</td>\n",
       "      <td>[436, 709, 992, 995, 1568, 1596, 1835, 1838, 1...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>2000651</td>\n",
       "      <td>[27137, 27136, 37406, 44478, 0, 73088, 81731, ...</td>\n",
       "      <td>[0, 65212, 65435, 55626, 47667, 47668, 95164, ...</td>\n",
       "      <td>[0, 1572867, 2883589, 2097160, 5767178, 262161...</td>\n",
       "      <td>[125, 130, 131, 140, 149, 201, 269, 270, 272, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>2000725</td>\n",
       "      <td>[48, 19557, 30114, 0, 38845, 38854, 46441, 497...</td>\n",
       "      <td>[0, 13512, 42058, 9914, 67107, 37566, 76448, 8...</td>\n",
       "      <td>[0, 1572865, 3670022, 12582918, 14155782, 1048...</td>\n",
       "      <td>[18, 48, 53, 65, 85, 111, 120, 121, 122, 123, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>2000789</td>\n",
       "      <td>[0, 46957, 127386, 128405, 146109, 128396, 467...</td>\n",
       "      <td>[37428, 107711, 0, 106598, 104751, 86892, 1935...</td>\n",
       "      <td>[0, 8192002, 2949124, 10420229, 10289158, 6094...</td>\n",
       "      <td>[511, 984, 1076, 1156, 1494, 1783, 1983, 2678,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>2000790</td>\n",
       "      <td>[0, 42444, 95209, 130793, 122137, 142155, 2097...</td>\n",
       "      <td>[112615, 0, 86160, 97131, 103406, 138810, 1402...</td>\n",
       "      <td>[0, 131072, 13369346, 2359300, 13598725, 56361...</td>\n",
       "      <td>[2810, 3091, 3099, 4221, 4222, 4223, 4397, 494...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2000961</td>\n",
       "      <td>[40952, 33796, 33795, 102154, 47901, 128036, 0...</td>\n",
       "      <td>[0, 152713, 127053, 127055, 127069, 258175, 20...</td>\n",
       "      <td>[0, 11403273, 13238289, 8650769, 9502739, 1638...</td>\n",
       "      <td>[1356, 1455, 2452, 3012, 3044, 3190, 3191, 348...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>2000988</td>\n",
       "      <td>[0, 75928, 93528, 94756, 103219, 117321, 53167...</td>\n",
       "      <td>[35425, 35426, 0, 109262, 125310, 125539, 1259...</td>\n",
       "      <td>[0, 16580608, 14876673, 16646147, 7733252, 347...</td>\n",
       "      <td>[1544, 1668, 2501, 2603, 2704, 2984, 3071, 313...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>478</td>\n",
       "      <td>2002024</td>\n",
       "      <td>[1912, 0, 108015, 48653, 132291, 85992, 47299,...</td>\n",
       "      <td>[0, 67918, 100170, 37175, 7619, 54471, 11873, ...</td>\n",
       "      <td>[0, 12320773, 851977, 9306123, 589838, 1369704...</td>\n",
       "      <td>[1462, 1543, 1636, 1840, 1846, 1912, 2252, 334...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>2002030</td>\n",
       "      <td>[0, 62637, 86610, 120606, 126463, 130471, 5150...</td>\n",
       "      <td>[60657, 0, 71947, 72085, 78606, 88562, 40162, ...</td>\n",
       "      <td>[0, 3801088, 11403265, 13238272, 2752518, 9306...</td>\n",
       "      <td>[851, 1090, 1209, 1348, 1370, 1371, 1374, 1375...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>2002043</td>\n",
       "      <td>[64386, 47599, 119054, 0, 146388, 148647, 1986...</td>\n",
       "      <td>[0, 130950, 293461, 147382, 226666, 299730, 27...</td>\n",
       "      <td>[0, 8585216, 17806254, 786443, 18808844, 16285...</td>\n",
       "      <td>[2043, 2185, 3193, 4031, 5791, 5792, 5807, 905...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>623</td>\n",
       "      <td>2002171</td>\n",
       "      <td>[0, 95741, 55589, 132025, 20726, 20725, 30319,...</td>\n",
       "      <td>[56022, 0, 144383, 125659, 145983, 121755, 159...</td>\n",
       "      <td>[0, 3538945, 3768324, 6553604, 10059782, 15761...</td>\n",
       "      <td>[861, 3661, 4451, 4805, 6653, 8373, 10239, 106...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>757</td>\n",
       "      <td>2002307</td>\n",
       "      <td>[64313, 0, 145215, 144155, 40699, 159680, 2117...</td>\n",
       "      <td>[0, 139124, 10886, 147056, 143498, 144415, 111...</td>\n",
       "      <td>[0, 5701643, 3538956, 1638430, 1114142, 184156...</td>\n",
       "      <td>[1505, 3128, 3129, 4134, 4272, 4416, 4704, 507...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>858</td>\n",
       "      <td>2002408</td>\n",
       "      <td>[62761, 40653, 0, 285117, 145118, 42718, 11135...</td>\n",
       "      <td>[0, 10542, 48010, 267954, 285072, 268171, 1761...</td>\n",
       "      <td>[0, 16908291, 16351239, 8650760, 14581779, 163...</td>\n",
       "      <td>[2590, 2676, 2730, 2831, 2846, 4121, 4234, 426...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>863</td>\n",
       "      <td>2002413</td>\n",
       "      <td>[0, 64476, 140543, 92939, 84947, 72202, 163523...</td>\n",
       "      <td>[4951, 0, 91429, 105331, 104706, 254660, 27273...</td>\n",
       "      <td>[0, 15728641, 16449536, 12845059, 12582920, 30...</td>\n",
       "      <td>[1510, 1763, 3605, 4951, 5101, 5264, 5270, 553...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>909</td>\n",
       "      <td>2002460</td>\n",
       "      <td>[0, 75900, 92855, 69134, 92262, 115348, 130017...</td>\n",
       "      <td>[71813, 0, 86522, 143099, 39624, 131250, 86846...</td>\n",
       "      <td>[0, 1572871, 1572877, 5767182, 12058637, 55050...</td>\n",
       "      <td>[1252, 2298, 2620, 2621, 2749, 2951, 3142, 316...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>994</td>\n",
       "      <td>2002547</td>\n",
       "      <td>[44698, 45703, 102184, 0, 107721, 94245, 63861...</td>\n",
       "      <td>[0, 104341, 45481, 45480, 127702, 135532, 8434...</td>\n",
       "      <td>[0, 16908295, 16121865, 7340044, 3407886, 1022...</td>\n",
       "      <td>[1450, 1568, 1844, 1850, 2503, 2550, 2665, 308...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2002603</td>\n",
       "      <td>[0, 49704, 60942, 61811, 66952, 79377, 50803, ...</td>\n",
       "      <td>[23074, 0, 41919, 36136, 79942, 80000, 82023, ...</td>\n",
       "      <td>[0, 1572865, 7340034, 16777218, 13107202, 2097...</td>\n",
       "      <td>[484, 485, 486, 525, 544, 664, 665, 666, 1355,...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1061</td>\n",
       "      <td>2002615</td>\n",
       "      <td>[0, 12863, 127740, 87281, 132473, 110485, 1096...</td>\n",
       "      <td>[77682, 10044, 0, 123571, 135227, 100291, 1287...</td>\n",
       "      <td>[0, 3080192, 6815746, 14581764, 8257541, 11468...</td>\n",
       "      <td>[3140, 3628, 5088, 5250, 5373, 5596, 5597, 562...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>2002644</td>\n",
       "      <td>[0, 17761, 121912, 73861, 137718, 148041, 1516...</td>\n",
       "      <td>[23480, 54776, 0, 65249, 91205, 80628, 123554,...</td>\n",
       "      <td>[0, 11862016, 2424837, 131078, 5832710, 110755...</td>\n",
       "      <td>[892, 1654, 2129, 2694, 3133, 4557, 4684, 4685...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1173</td>\n",
       "      <td>2002731</td>\n",
       "      <td>[8463, 34004, 1200, 82758, 0, 51620, 64657, 70...</td>\n",
       "      <td>[0, 60004, 120532, 125568, 48446, 107382, 1322...</td>\n",
       "      <td>[0, 6160387, 5, 6, 2097158, 4063237, 393224, 5...</td>\n",
       "      <td>[5, 6, 19, 20, 26, 31, 33, 37, 40, 55, 86, 92,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>2002879</td>\n",
       "      <td>[0, 79218, 61215, 79835, 61217, 159999, 166377...</td>\n",
       "      <td>[11158, 0, 33124, 101456, 224622, 299646, 2364...</td>\n",
       "      <td>[0, 12025858, 10551308, 15302673, 10911763, 85...</td>\n",
       "      <td>[636, 2443, 4096, 4304, 5621, 5686, 7242, 7636...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1353</td>\n",
       "      <td>2002927</td>\n",
       "      <td>[83821, 0, 152798, 149004, 156072, 158054, 619...</td>\n",
       "      <td>[0, 126380, 119146, 156082, 173079, 197914, 25...</td>\n",
       "      <td>[0, 17760259, 15237123, 1671172, 15368197, 855...</td>\n",
       "      <td>[763, 4394, 4732, 4788, 7558, 7616, 9086, 9087...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1389</td>\n",
       "      <td>2002967</td>\n",
       "      <td>[13475, 75266, 95237, 102380, 0, 97899, 136422...</td>\n",
       "      <td>[0, 35833, 123440, 140421, 149932, 139175, 379...</td>\n",
       "      <td>[0, 360448, 1638402, 3932164, 3899397, 1756365...</td>\n",
       "      <td>[3164, 6145, 9405, 13475, 13807, 17886, 18121,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1424</td>\n",
       "      <td>2300026</td>\n",
       "      <td>[10506, 0, 91344, 118914, 123067, 63051, 63046...</td>\n",
       "      <td>[0, 80795, 79703, 102175, 113008, 45095, 7112,...</td>\n",
       "      <td>[0, 17039360, 3014658, 2883584, 3932165, 17170...</td>\n",
       "      <td>[1099, 1468, 1622, 1665, 1899, 1924, 1932, 206...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1443</td>\n",
       "      <td>2300046</td>\n",
       "      <td>[0, 96480, 125754, 133302, 97196, 10337, 12001...</td>\n",
       "      <td>[19192, 0, 28035, 141949, 19457, 26935, 157183...</td>\n",
       "      <td>[0, 2752513, 4718594, 6291460, 4325381, 165150...</td>\n",
       "      <td>[34, 116, 465, 519, 582, 657, 1496, 1498, 1750...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1466</td>\n",
       "      <td>2300070</td>\n",
       "      <td>[0, 118849, 129350, 131768, 113067, 142379, 11...</td>\n",
       "      <td>[64616, 110107, 0, 3512, 129475, 157257, 12814...</td>\n",
       "      <td>[0, 13041668, 5832709, 10027015, 9895944, 9895...</td>\n",
       "      <td>[1110, 1687, 2820, 3512, 3524, 4150, 5502, 557...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1484</td>\n",
       "      <td>2300088</td>\n",
       "      <td>[133301, 50455, 0, 154177, 160097, 162448, 148...</td>\n",
       "      <td>[0, 143119, 60002, 139521, 160206, 147518, 150...</td>\n",
       "      <td>[0, 16777216, 2752521, 4718607, 8912917, 70779...</td>\n",
       "      <td>[223, 742, 1014, 1092, 1744, 1787, 1790, 1791,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>2300130</td>\n",
       "      <td>[0, 123972, 118992, 288473, 288909, 224202, 25...</td>\n",
       "      <td>[64874, 0, 3034, 176931, 234345, 291458, 29389...</td>\n",
       "      <td>[0, 12025857, 819201, 13697030, 10649608, 1369...</td>\n",
       "      <td>[2290, 2395, 3034, 3708, 3712, 3713, 3714, 371...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1581</td>\n",
       "      <td>2300187</td>\n",
       "      <td>[128526, 88190, 0, 29886, 308873, 234941, 3080...</td>\n",
       "      <td>[0, 88109, 238494, 255745, 258391, 288311, 295...</td>\n",
       "      <td>[0, 5636096, 491525, 2785289, 13467660, 102236...</td>\n",
       "      <td>[4496, 4761, 4766, 4907, 6482, 6801, 7586, 758...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1684</td>\n",
       "      <td>2300292</td>\n",
       "      <td>[69456, 0, 130158, 93035, 141951, 147360, 1193...</td>\n",
       "      <td>[0, 56965, 92872, 134486, 31634, 115061, 10275...</td>\n",
       "      <td>[0, 15400961, 8519683, 6160388, 10616835, 1310...</td>\n",
       "      <td>[1519, 2666, 2667, 2668, 2954, 3052, 4208, 430...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1978</td>\n",
       "      <td>2300592</td>\n",
       "      <td>[0, 97718, 110369, 147866, 204319, 84459, 2694...</td>\n",
       "      <td>[83105, 0, 83102, 61954, 212432, 233860, 25336...</td>\n",
       "      <td>[0, 17399812, 4390918, 622600, 13991945, 12812...</td>\n",
       "      <td>[1311, 1314, 1830, 6932, 7918, 7919, 7927, 799...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2011</td>\n",
       "      <td>2300626</td>\n",
       "      <td>[0, 144822, 136794, 39279, 169799, 171657, 197...</td>\n",
       "      <td>[16663, 12627, 0, 150346, 200768, 252789, 2528...</td>\n",
       "      <td>[0, 12976129, 311300, 7880709, 5193733, 191037...</td>\n",
       "      <td>[1539, 1635, 3872, 3888, 6861, 8371, 9283, 126...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013</td>\n",
       "      <td>2300628</td>\n",
       "      <td>[0, 117800, 128368, 133507, 167387, 149801, 20...</td>\n",
       "      <td>[117898, 117899, 117900, 0, 110931, 110932, 31...</td>\n",
       "      <td>[0, 15204353, 720908, 14221326, 8847374, 16646...</td>\n",
       "      <td>[2316, 2317, 3114, 3287, 3488, 3489, 4223, 445...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2067</td>\n",
       "      <td>2300683</td>\n",
       "      <td>[3578, 0, 126476, 139362, 131907, 142582, 1456...</td>\n",
       "      <td>[0, 23179, 136003, 84520, 140789, 11972, 10672...</td>\n",
       "      <td>[0, 4849666, 8257542, 5963783, 2424841, 118620...</td>\n",
       "      <td>[2859, 3578, 4055, 4111, 4175, 4176, 4177, 486...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2110</td>\n",
       "      <td>2300729</td>\n",
       "      <td>[289786, 309831, 310592, 310900, 299857, 29993...</td>\n",
       "      <td>[284969, 205394, 263437, 380052, 0, 402223, 40...</td>\n",
       "      <td>[0, 10256385, 6340617, 10993677, 8495118, 6742...</td>\n",
       "      <td>[1263, 3284, 3286, 13483, 20633, 20634, 20635,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2189</td>\n",
       "      <td>2300817</td>\n",
       "      <td>[0, 46809, 130396, 130397, 104156, 41887, 1405...</td>\n",
       "      <td>[70389, 0, 133750, 103159, 141099, 141955, 137...</td>\n",
       "      <td>[0, 7323653, 16023562, 12353547, 9519120, 9469...</td>\n",
       "      <td>[1928, 1933, 2362, 3908, 4116, 4495, 4544, 503...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         skey                                      BidApplSeqNum  \\\n",
       "12    2000016  [0, 84818, 36514, 138993, 139668, 139126, 1440...   \n",
       "208   2000651  [27137, 27136, 37406, 44478, 0, 73088, 81731, ...   \n",
       "264   2000725  [48, 19557, 30114, 0, 38845, 38854, 46441, 497...   \n",
       "302   2000789  [0, 46957, 127386, 128405, 146109, 128396, 467...   \n",
       "303   2000790  [0, 42444, 95209, 130793, 122137, 142155, 2097...   \n",
       "420   2000961  [40952, 33796, 33795, 102154, 47901, 128036, 0...   \n",
       "442   2000988  [0, 75928, 93528, 94756, 103219, 117321, 53167...   \n",
       "478   2002024  [1912, 0, 108015, 48653, 132291, 85992, 47299,...   \n",
       "484   2002030  [0, 62637, 86610, 120606, 126463, 130471, 5150...   \n",
       "497   2002043  [64386, 47599, 119054, 0, 146388, 148647, 1986...   \n",
       "623   2002171  [0, 95741, 55589, 132025, 20726, 20725, 30319,...   \n",
       "757   2002307  [64313, 0, 145215, 144155, 40699, 159680, 2117...   \n",
       "858   2002408  [62761, 40653, 0, 285117, 145118, 42718, 11135...   \n",
       "863   2002413  [0, 64476, 140543, 92939, 84947, 72202, 163523...   \n",
       "909   2002460  [0, 75900, 92855, 69134, 92262, 115348, 130017...   \n",
       "994   2002547  [44698, 45703, 102184, 0, 107721, 94245, 63861...   \n",
       "1050  2002603  [0, 49704, 60942, 61811, 66952, 79377, 50803, ...   \n",
       "1061  2002615  [0, 12863, 127740, 87281, 132473, 110485, 1096...   \n",
       "1090  2002644  [0, 17761, 121912, 73861, 137718, 148041, 1516...   \n",
       "1173  2002731  [8463, 34004, 1200, 82758, 0, 51620, 64657, 70...   \n",
       "1310  2002879  [0, 79218, 61215, 79835, 61217, 159999, 166377...   \n",
       "1353  2002927  [83821, 0, 152798, 149004, 156072, 158054, 619...   \n",
       "1389  2002967  [13475, 75266, 95237, 102380, 0, 97899, 136422...   \n",
       "1424  2300026  [10506, 0, 91344, 118914, 123067, 63051, 63046...   \n",
       "1443  2300046  [0, 96480, 125754, 133302, 97196, 10337, 12001...   \n",
       "1466  2300070  [0, 118849, 129350, 131768, 113067, 142379, 11...   \n",
       "1484  2300088  [133301, 50455, 0, 154177, 160097, 162448, 148...   \n",
       "1525  2300130  [0, 123972, 118992, 288473, 288909, 224202, 25...   \n",
       "1581  2300187  [128526, 88190, 0, 29886, 308873, 234941, 3080...   \n",
       "1684  2300292  [69456, 0, 130158, 93035, 141951, 147360, 1193...   \n",
       "1978  2300592  [0, 97718, 110369, 147866, 204319, 84459, 2694...   \n",
       "2011  2300626  [0, 144822, 136794, 39279, 169799, 171657, 197...   \n",
       "2013  2300628  [0, 117800, 128368, 133507, 167387, 149801, 20...   \n",
       "2067  2300683  [3578, 0, 126476, 139362, 131907, 142582, 1456...   \n",
       "2110  2300729  [289786, 309831, 310592, 310900, 299857, 29993...   \n",
       "2189  2300817  [0, 46809, 130396, 130397, 104156, 41887, 1405...   \n",
       "\n",
       "                                        OfferApplSeqNum  \\\n",
       "12    [5031, 64213, 73250, 0, 93332, 21514, 126063, ...   \n",
       "208   [0, 65212, 65435, 55626, 47667, 47668, 95164, ...   \n",
       "264   [0, 13512, 42058, 9914, 67107, 37566, 76448, 8...   \n",
       "302   [37428, 107711, 0, 106598, 104751, 86892, 1935...   \n",
       "303   [112615, 0, 86160, 97131, 103406, 138810, 1402...   \n",
       "420   [0, 152713, 127053, 127055, 127069, 258175, 20...   \n",
       "442   [35425, 35426, 0, 109262, 125310, 125539, 1259...   \n",
       "478   [0, 67918, 100170, 37175, 7619, 54471, 11873, ...   \n",
       "484   [60657, 0, 71947, 72085, 78606, 88562, 40162, ...   \n",
       "497   [0, 130950, 293461, 147382, 226666, 299730, 27...   \n",
       "623   [56022, 0, 144383, 125659, 145983, 121755, 159...   \n",
       "757   [0, 139124, 10886, 147056, 143498, 144415, 111...   \n",
       "858   [0, 10542, 48010, 267954, 285072, 268171, 1761...   \n",
       "863   [4951, 0, 91429, 105331, 104706, 254660, 27273...   \n",
       "909   [71813, 0, 86522, 143099, 39624, 131250, 86846...   \n",
       "994   [0, 104341, 45481, 45480, 127702, 135532, 8434...   \n",
       "1050  [23074, 0, 41919, 36136, 79942, 80000, 82023, ...   \n",
       "1061  [77682, 10044, 0, 123571, 135227, 100291, 1287...   \n",
       "1090  [23480, 54776, 0, 65249, 91205, 80628, 123554,...   \n",
       "1173  [0, 60004, 120532, 125568, 48446, 107382, 1322...   \n",
       "1310  [11158, 0, 33124, 101456, 224622, 299646, 2364...   \n",
       "1353  [0, 126380, 119146, 156082, 173079, 197914, 25...   \n",
       "1389  [0, 35833, 123440, 140421, 149932, 139175, 379...   \n",
       "1424  [0, 80795, 79703, 102175, 113008, 45095, 7112,...   \n",
       "1443  [19192, 0, 28035, 141949, 19457, 26935, 157183...   \n",
       "1466  [64616, 110107, 0, 3512, 129475, 157257, 12814...   \n",
       "1484  [0, 143119, 60002, 139521, 160206, 147518, 150...   \n",
       "1525  [64874, 0, 3034, 176931, 234345, 291458, 29389...   \n",
       "1581  [0, 88109, 238494, 255745, 258391, 288311, 295...   \n",
       "1684  [0, 56965, 92872, 134486, 31634, 115061, 10275...   \n",
       "1978  [83105, 0, 83102, 61954, 212432, 233860, 25336...   \n",
       "2011  [16663, 12627, 0, 150346, 200768, 252789, 2528...   \n",
       "2013  [117898, 117899, 117900, 0, 110931, 110932, 31...   \n",
       "2067  [0, 23179, 136003, 84520, 140789, 11972, 10672...   \n",
       "2110  [284969, 205394, 263437, 380052, 0, 402223, 40...   \n",
       "2189  [70389, 0, 133750, 103159, 141099, 141955, 137...   \n",
       "\n",
       "                                                  union  \\\n",
       "12    [0, 12582913, 2621449, 12582924, 17825807, 104...   \n",
       "208   [0, 1572867, 2883589, 2097160, 5767178, 262161...   \n",
       "264   [0, 1572865, 3670022, 12582918, 14155782, 1048...   \n",
       "302   [0, 8192002, 2949124, 10420229, 10289158, 6094...   \n",
       "303   [0, 131072, 13369346, 2359300, 13598725, 56361...   \n",
       "420   [0, 11403273, 13238289, 8650769, 9502739, 1638...   \n",
       "442   [0, 16580608, 14876673, 16646147, 7733252, 347...   \n",
       "478   [0, 12320773, 851977, 9306123, 589838, 1369704...   \n",
       "484   [0, 3801088, 11403265, 13238272, 2752518, 9306...   \n",
       "497   [0, 8585216, 17806254, 786443, 18808844, 16285...   \n",
       "623   [0, 3538945, 3768324, 6553604, 10059782, 15761...   \n",
       "757   [0, 5701643, 3538956, 1638430, 1114142, 184156...   \n",
       "858   [0, 16908291, 16351239, 8650760, 14581779, 163...   \n",
       "863   [0, 15728641, 16449536, 12845059, 12582920, 30...   \n",
       "909   [0, 1572871, 1572877, 5767182, 12058637, 55050...   \n",
       "994   [0, 16908295, 16121865, 7340044, 3407886, 1022...   \n",
       "1050  [0, 1572865, 7340034, 16777218, 13107202, 2097...   \n",
       "1061  [0, 3080192, 6815746, 14581764, 8257541, 11468...   \n",
       "1090  [0, 11862016, 2424837, 131078, 5832710, 110755...   \n",
       "1173  [0, 6160387, 5, 6, 2097158, 4063237, 393224, 5...   \n",
       "1310  [0, 12025858, 10551308, 15302673, 10911763, 85...   \n",
       "1353  [0, 17760259, 15237123, 1671172, 15368197, 855...   \n",
       "1389  [0, 360448, 1638402, 3932164, 3899397, 1756365...   \n",
       "1424  [0, 17039360, 3014658, 2883584, 3932165, 17170...   \n",
       "1443  [0, 2752513, 4718594, 6291460, 4325381, 165150...   \n",
       "1466  [0, 13041668, 5832709, 10027015, 9895944, 9895...   \n",
       "1484  [0, 16777216, 2752521, 4718607, 8912917, 70779...   \n",
       "1525  [0, 12025857, 819201, 13697030, 10649608, 1369...   \n",
       "1581  [0, 5636096, 491525, 2785289, 13467660, 102236...   \n",
       "1684  [0, 15400961, 8519683, 6160388, 10616835, 1310...   \n",
       "1978  [0, 17399812, 4390918, 622600, 13991945, 12812...   \n",
       "2011  [0, 12976129, 311300, 7880709, 5193733, 191037...   \n",
       "2013  [0, 15204353, 720908, 14221326, 8847374, 16646...   \n",
       "2067  [0, 4849666, 8257542, 5963783, 2424841, 118620...   \n",
       "2110  [0, 10256385, 6340617, 10993677, 8495118, 6742...   \n",
       "2189  [0, 7323653, 16023562, 12353547, 9519120, 9469...   \n",
       "\n",
       "                                             ApplSeqNum  less  less1  \n",
       "12    [436, 709, 992, 995, 1568, 1596, 1835, 1838, 1...     2      0  \n",
       "208   [125, 130, 131, 140, 149, 201, 269, 270, 272, ...     2      0  \n",
       "264   [18, 48, 53, 65, 85, 111, 120, 121, 122, 123, ...     2      0  \n",
       "302   [511, 984, 1076, 1156, 1494, 1783, 1983, 2678,...     2      0  \n",
       "303   [2810, 3091, 3099, 4221, 4222, 4223, 4397, 494...     2      0  \n",
       "420   [1356, 1455, 2452, 3012, 3044, 3190, 3191, 348...     2      0  \n",
       "442   [1544, 1668, 2501, 2603, 2704, 2984, 3071, 313...     2      0  \n",
       "478   [1462, 1543, 1636, 1840, 1846, 1912, 2252, 334...     2      0  \n",
       "484   [851, 1090, 1209, 1348, 1370, 1371, 1374, 1375...     2      0  \n",
       "497   [2043, 2185, 3193, 4031, 5791, 5792, 5807, 905...     2      0  \n",
       "623   [861, 3661, 4451, 4805, 6653, 8373, 10239, 106...     2      0  \n",
       "757   [1505, 3128, 3129, 4134, 4272, 4416, 4704, 507...     2      0  \n",
       "858   [2590, 2676, 2730, 2831, 2846, 4121, 4234, 426...     2      0  \n",
       "863   [1510, 1763, 3605, 4951, 5101, 5264, 5270, 553...     2      0  \n",
       "909   [1252, 2298, 2620, 2621, 2749, 2951, 3142, 316...     2      0  \n",
       "994   [1450, 1568, 1844, 1850, 2503, 2550, 2665, 308...     2      0  \n",
       "1050  [484, 485, 486, 525, 544, 664, 665, 666, 1355,...     4      0  \n",
       "1061  [3140, 3628, 5088, 5250, 5373, 5596, 5597, 562...     2      0  \n",
       "1090  [892, 1654, 2129, 2694, 3133, 4557, 4684, 4685...     2      0  \n",
       "1173  [5, 6, 19, 20, 26, 31, 33, 37, 40, 55, 86, 92,...     2      0  \n",
       "1310  [636, 2443, 4096, 4304, 5621, 5686, 7242, 7636...     2      0  \n",
       "1353  [763, 4394, 4732, 4788, 7558, 7616, 9086, 9087...     2      0  \n",
       "1389  [3164, 6145, 9405, 13475, 13807, 17886, 18121,...     2      0  \n",
       "1424  [1099, 1468, 1622, 1665, 1899, 1924, 1932, 206...     2      0  \n",
       "1443  [34, 116, 465, 519, 582, 657, 1496, 1498, 1750...     2      0  \n",
       "1466  [1110, 1687, 2820, 3512, 3524, 4150, 5502, 557...     2      0  \n",
       "1484  [223, 742, 1014, 1092, 1744, 1787, 1790, 1791,...     2      0  \n",
       "1525  [2290, 2395, 3034, 3708, 3712, 3713, 3714, 371...     2      0  \n",
       "1581  [4496, 4761, 4766, 4907, 6482, 6801, 7586, 758...     3      0  \n",
       "1684  [1519, 2666, 2667, 2668, 2954, 3052, 4208, 430...     2      0  \n",
       "1978  [1311, 1314, 1830, 6932, 7918, 7919, 7927, 799...     2      0  \n",
       "2011  [1539, 1635, 3872, 3888, 6861, 8371, 9283, 126...     2      0  \n",
       "2013  [2316, 2317, 3114, 3287, 3488, 3489, 4223, 445...     2      0  \n",
       "2067  [2859, 3578, 4055, 4111, 4175, 4176, 4177, 486...     2      0  \n",
       "2110  [1263, 3284, 3286, 13483, 20633, 20634, 20635,...     2      0  \n",
       "2189  [1928, 1933, 2362, 3908, 4116, 4495, 4544, 503...     2      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.merge(t1, t2, on='skey')\n",
    "t['union'] = [list(set(a) | set(b)) for a, b in zip(t.BidApplSeqNum, t.OfferApplSeqNum)]\n",
    "t = pd.merge(t, t3, on='skey')\n",
    "t['less'] = [len(set(a) - set(b)) for a, b in zip(t.union, t.ApplSeqNum)]\n",
    "t['less1'] = [list(set(a) - set(b))[0] for a, b in zip(t.union, t.ApplSeqNum)]\n",
    "display(t['less1'].unique())\n",
    "t[t['less'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skey                       int32\n",
      "date                       int32\n",
      "time                       int64\n",
      "clockAtArrival             int64\n",
      "datetime          datetime64[ns]\n",
      "ApplSeqNum                 int32\n",
      "order_side                 int32\n",
      "order_type                 int32\n",
      "order_price              float64\n",
      "order_qty                  int32\n",
      "dtype: object\n",
      "20200316\n",
      "order finished\n",
      "0:36:31.944359\n"
     ]
    },
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "192.168.10.223:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-af99d096acf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[0mpassword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"bnONBrzSMGoE\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[0mdb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"192.168.10.223\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatabase_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m \u001b[0mtrade\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'md_trade'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstartDate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mendDate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[0mtrade\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrade\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrade\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'skey'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2000000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skey'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BidApplSeqNum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-af99d096acf4>\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, table_name, start_date, end_date, symbol)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0msegs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ver'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0msegs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_refresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__manipulate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m                 \u001b[0m_db\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\cursor.py\u001b[0m in \u001b[0;36m_refresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__session\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__id\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Query\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_ensure_session\u001b[1;34m(self, session)\u001b[0m\n\u001b[0;32m   1808\u001b[0m             \u001b[1;31m# Don't make implicit sessions causally consistent. Applications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m             \u001b[1;31m# should always opt-in.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1810\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__start_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcausal_consistency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mConfigurationError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInvalidOperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1812\u001b[0m             \u001b[1;31m# Sessions not supported, or multiple users authenticated.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m__start_session\u001b[1;34m(self, implicit, **kwargs)\u001b[0m\n\u001b[0;32m   1761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1762\u001b[0m         \u001b[1;31m# Raises ConfigurationError if sessions are not supported.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1763\u001b[1;33m         \u001b[0mserver_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_server_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1764\u001b[0m         \u001b[0mopts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSessionOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1765\u001b[0m         return client_session.ClientSession(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_get_server_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1794\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_server_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1795\u001b[0m         \u001b[1;34m\"\"\"Internal: start or resume a _ServerSession.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1796\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_topology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_server_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1798\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_return_server_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\topology.py\u001b[0m in \u001b[0;36mget_server_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    483\u001b[0m                             \u001b[0many_server_selector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_selection_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m                             None)\n\u001b[0m\u001b[0;32m    486\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_description\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadable_servers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                     self._select_servers_loop(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\topology.py\u001b[0m in \u001b[0;36m_select_servers_loop\u001b[1;34m(self, selector, timeout, address)\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                 raise ServerSelectionTimeoutError(\n\u001b[1;32m--> 209\u001b[1;33m                     self._error_message(selector))\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_opened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mServerSelectionTimeoutError\u001b[0m: 192.168.10.223:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。"
     ]
    }
   ],
   "source": [
    "# 2020 ftp data version\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from unrar import rarfile\n",
    "import py7zr\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "columns1 = [\"Date\",\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",\"PreClosePx\",\n",
    "                   \"PxChnage1\",\"PXChange2\",\"openPrice\",\"HighPx\",\"LowPx\",\"close\",\"NumTrades\",\"cum_volume\",\"cum_amount\",\"PE1\",\"PE2\",\"TradingPhase\",\n",
    "                   \"totalofferqty\", \"wa_offerPrice\", \"totalbidqty\", \"wa_bidPrice\", \"PreNAV\", \"RealTimeNAV\", \"WarrantPremiumRate\", \"UpLimitPx\",\n",
    "                   \"DownLimitPx\", \"TotalLongPosition\", \"unknown1\", \"unknown2\", \"unknown3\"]\n",
    "columns2 = ['Date',\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",'ask1p','bid1p',\n",
    "                   \"ask1q\",\"bid1q\", 'ask2p','bid2p',\"ask2q\",\"bid2q\",'ask3p','bid3p',\"ask3q\",\"bid3q\",'ask4p','bid4p',\"ask4q\",\"bid4q\",'ask5p',\n",
    "                    'bid5p',\"ask5q\",\"bid5q\",'ask6p','bid6p',\"ask6q\",\"bid6q\",'ask7p','bid7p',\"ask7q\",\"bid7q\",'ask8p','bid8p',\"ask8q\",\"bid8q\",\n",
    "                   'ask9p','bid9p',\"ask9q\",\"bid9q\",'ask10p','bid10p',\"ask10q\",\"bid10q\",\"NUMORDERS_B1\",\"NOORDERS_B1\",\"ORDERQTY_B1\",\n",
    "                    \"NUMORDERS_S1\",\"NOORDERS_S1\",\"ORDERQTY_S1\"]\n",
    "columns3 =  [\"Date\",\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",\"PreClosePx\",\n",
    "                   \"PxChnage1\",\"PXChange2\",\"openPrice\",\"HighPx\",\"LowPx\",\"close\",\"NumTrades\",\"cum_volume\",\"cum_amount\",\"PE1\",\"PE2\",\"TradingPhase\",\n",
    "                   \"totalofferqty\", \"wa_offerPrice\", \"totalbidqty\", \"wa_bidPrice\", \"PreNAV\", \"RealTimeNAV\", \"WarrantPremiumRate\", \"UpLimitPx\",\n",
    "                   \"DownLimitPx\", \"TotalLongPosition\"]\n",
    "\n",
    "# startTm = datetime.datetime.now()\n",
    "# readPath = r'\\\\192.168.10.30\\Kevin_zhenyu\\day_stock\\***'\n",
    "# dataPathLs = np.array(glob.glob(readPath))\n",
    "# dataPathLs = dataPathLs[[np.array([os.path.basename(i).split('.')[0][:2] == 'SZ' for i in dataPathLs])]]\n",
    "# db = pd.DataFrame()\n",
    "# for p in dataPathLs:\n",
    "#     dayData = pd.read_csv(p, compression='gzip')\n",
    "#     db = pd.concat([db, dayData])\n",
    "# print(datetime.datetime.now() - startTm)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "year = \"2020\"\n",
    "startDate = \"0316\"\n",
    "endDate = \"0316\"\n",
    "df = []\n",
    "bad = []\n",
    "readPath = 'L:\\\\backup_data\\\\' + year + '\\\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "\n",
    "for data in dataPathLs:\n",
    "    if len(np.array(glob.glob(data +'\\\\***'))) == 0:\n",
    "        continue\n",
    "    \n",
    "    if len(np.array(glob.glob(data +'\\\\am_hq_order_spot.7z'))) == 1:\n",
    "        date = os.path.basename(data)\n",
    "        path = 'L:\\\\backup_data\\\\' + year \n",
    "        os.chdir(data)\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\am_hq_order_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\am_hq_order_spot.7z')\n",
    "            bad.append(data + '\\\\am_hq_order_spot.7z')\n",
    "            continue\n",
    "        path1 = path + '\\\\' + date\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\pm_hq_order_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\pm_hq_order_spot.7z')\n",
    "            bad.append(data + '\\\\pm_hq_order_spot.7z')\n",
    "            continue\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        \n",
    "        am_order = pd.read_table(path1 + '\\\\am_hq_order_spot.txt',header=None)\n",
    "        am_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "        pm_order = pd.read_table(path1 + '\\\\pm_hq_order_spot.txt',header=None)\n",
    "        pm_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "        OrderLog1 = pd.concat([am_order, pm_order])\n",
    "        del am_order\n",
    "        del pm_order\n",
    "  \n",
    "    \n",
    "    elif len(np.array(glob.glob(data +'\\\\am_hq_order_spot.7z.001'))) == 1:\n",
    "        date = os.path.basename(data)\n",
    "        path = 'L:\\\\backup_data\\\\' + year \n",
    "        os.chdir(data)\n",
    "        os.system(\"copy /b am_hq_order_spot.7z.* am_hq_order_spot.7z\")\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\am_hq_order_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\am_hq_order_spot.7z')\n",
    "            bad.append(data + '\\\\am_hq_order_spot.7z')\n",
    "            continue\n",
    "        path1 = path + '\\\\' + date\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        os.system(\"copy /b pm_hq_order_spot.7z.* pm_hq_order_spot.7z\")\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\pm_hq_order_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\pm_hq_order_spot.7z')\n",
    "            bad.append(data + '\\\\pm_hq_order_spot.7z')\n",
    "            continue\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        \n",
    "        am_order = pd.read_table(path1 + '\\\\am_hq_order_spot.txt',header=None)\n",
    "        am_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "        pm_order = pd.read_table(path1 + '\\\\pm_hq_order_spot.txt',header=None)\n",
    "        pm_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "        OrderLog1 = pd.concat([am_order, pm_order])\n",
    "        del am_order\n",
    "        del pm_order\n",
    "\n",
    "    elif len(np.array(glob.glob(data +'\\\\hq_order.7z'))) == 1:\n",
    "        date = os.path.basename(data)\n",
    "        path = 'L:\\\\backup_data\\\\' + year \n",
    "        os.chdir(data)\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\hq_order.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\hq_order.7z')\n",
    "            bad.append(data + '\\\\hq_order.7z')\n",
    "            continue\n",
    "        path1 = path + '\\\\' + date\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        OrderLog1 = pd.read_table(path1 + '\\\\hq_order.txt',header=None)\n",
    "        OrderLog1.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "    \n",
    "    \n",
    "    OrderLog1 = OrderLog1[(OrderLog1[\"SecurityID\"] < 4000) | (OrderLog1[\"SecurityID\"] > 300000)]\n",
    "    OrderLog1[\"skey\"] = OrderLog1[\"SecurityID\"] + 2000000\n",
    "    OrderLog1[\"clockAtArrival\"] = OrderLog1[\"TransactTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    OrderLog1['datetime'] = OrderLog1[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    OrderLog1[\"time\"] = (OrderLog1['TransactTime'] - int(OrderLog1['TransactTime'].iloc[0]//1000000000*1000000000)).astype(np.int64)*1000\n",
    "    OrderLog1[\"order_type\"] =np.where(OrderLog1[\"order_type\"] == 'U', 3, OrderLog1[\"order_type\"])\n",
    "    for col in [\"skey\", \"date\", \"ApplSeqNum\", \"order_qty\", \"order_side\", \"order_type\"]:\n",
    "        OrderLog1[col] = OrderLog1[col].astype('int32')\n",
    "    display(OrderLog1[\"order_price\"].astype(str).apply(lambda x: len(x.split('.')[1])).unique())\n",
    "    \n",
    "    assert(OrderLog1[((OrderLog1[\"order_side\"] != 1) & (OrderLog1[\"order_side\"] != 2)) | (OrderLog1[\"order_type\"].isnull())].shape[0] == 0)\n",
    "    da_te = str(OrderLog1[\"date\"].iloc[0]) \n",
    "    da_te = da_te[:4] + '-' + da_te[4:6] + '-' + da_te[6:8]\n",
    "    db1 = db[db[\"date\"] == da_te]\n",
    "    sl = (db1[\"ID\"].str[2:].astype(int) + 2000000).unique()\n",
    "    del db1\n",
    "    try:\n",
    "        assert(len(set(sl) - set(OrderLog1[\"skey\"].unique())) == 0)\n",
    "    except:\n",
    "        print(set(sl) - set(OrderLog1[\"skey\"].unique()))\n",
    "    \n",
    "    OrderLog1 = OrderLog1[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ApplSeqNum\", \"order_side\", \"order_type\", \"order_price\",\n",
    "                                                 \"order_qty\"]]\n",
    "    \n",
    "    print(OrderLog1.dtypes)\n",
    "    print(OrderLog1[\"date\"].iloc[0])\n",
    "    print(\"order finished\")\n",
    "    \n",
    "    print(datetime.datetime.now() - startTm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>BidApplSeqNum</th>\n",
       "      <th>OfferApplSeqNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [skey, BidApplSeqNum, OfferApplSeqNum]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>BidApplSeqNum</th>\n",
       "      <th>OfferApplSeqNum</th>\n",
       "      <th>union</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [skey, BidApplSeqNum, OfferApplSeqNum, union, ApplSeqNum]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>BidApplSeqNum</th>\n",
       "      <th>OfferApplSeqNum</th>\n",
       "      <th>union</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "      <th>less</th>\n",
       "      <th>less1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [skey, BidApplSeqNum, OfferApplSeqNum, union, ApplSeqNum, less, less1]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = \"2020\"\n",
    "startDate = '20200316'\n",
    "endDate = '20200316'\n",
    "readPath = 'K:\\\\data\\\\' + year + '\\\\***\\\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "\n",
    "for data in dataPathLs:\n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    \n",
    "    readPath = data + '\\\\SZ\\\\tick\\\\***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[(dateLs < 4000) | ((dateLs > 300000) & (dateLs < 310000))]\n",
    "    trade = []\n",
    "    ll = []\n",
    "    \n",
    "    for i in dataPathLs:\n",
    "        try:\n",
    "            df = pd.read_csv(i)\n",
    "        except:\n",
    "            print(\"empty data\")\n",
    "            print(i)\n",
    "            ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "            continue\n",
    "        df[\"SecurityID\"] = int(os.path.basename(i).split('.')[0])\n",
    "        trade += [df]\n",
    "    trade = pd.concat(trade).reset_index(drop=True)\n",
    "    trade = trade[trade[\"ChannelNo\"] != 4001]\n",
    "\n",
    "    trade[\"skey\"] = trade[\"SecurityID\"] + 2000000\n",
    "\n",
    "t1 = trade.groupby('skey')['BidApplSeqNum'].unique().reset_index()\n",
    "t2 = trade.groupby('skey')['OfferApplSeqNum'].unique().reset_index()\n",
    "t3 = OrderLog1.groupby('skey')['ApplSeqNum'].unique().reset_index()\n",
    "t = pd.merge(t1, t2, on='skey', how='outer')\n",
    "display(t[(t['BidApplSeqNum'].isnull()) | (t['OfferApplSeqNum'].isnull())])\n",
    "t['union'] = [list(set(a) | set(b)) for a, b in zip(t.BidApplSeqNum, t.OfferApplSeqNum)]\n",
    "t = pd.merge(t, t3, on='skey', how='outer')\n",
    "display(t[(t['BidApplSeqNum'].isnull()) | (t['OfferApplSeqNum'].isnull()) | (t['ApplSeqNum'].isnull())])\n",
    "t['less'] = [len(set(a) - set(b)) for a, b in zip(t.union, t.ApplSeqNum)]\n",
    "t['less1'] = [list(set(a) - set(b))[0] for a, b in zip(t.union, t.ApplSeqNum)]\n",
    "display(t['less1'].unique())\n",
    "t[t['less'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = 20200316\n",
    "endDate = 20200316\n",
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "db1 = DB(\"192.168.10.223\", database_name, user, password)\n",
    "trade = db1.read('md_trade', start_date=startDate, end_date=endDate)\n",
    "trade = trade[trade['skey'] > 2000000]\n",
    "t1 = trade.groupby('skey')['BidApplSeqNum'].unique().reset_index()\n",
    "t2 = trade.groupby('skey')['OfferApplSeqNum'].unique().reset_index()\n",
    "t3 = OrderLog1.groupby('skey')['ApplSeqNum'].unique().reset_index()\n",
    "t = pd.merge(t1, t2, on='skey', how='outer')\n",
    "display(t[(t['BidApplSeqNum'].isnull()) | (t['OfferApplSeqNum'].isnull())])\n",
    "t['union'] = [list(set(a) | set(b)) for a, b in zip(t.BidApplSeqNum, t.OfferApplSeqNum)]\n",
    "t = pd.merge(t, t3, on='skey', how='outer')\n",
    "display(t[(t['BidApplSeqNum'].isnull()) | (t['OfferApplSeqNum'].isnull()) | (t['ApplSeqNum'].isnull())])\n",
    "t['less'] = [len(set(a) - set(b)) for a, b in zip(t.union, t.ApplSeqNum)]\n",
    "t['less1'] = [list(set(a) - set(b))[0] for a, b in zip(t.union, t.ApplSeqNum)]\n",
    "display(t['less1'].unique())\n",
    "t[t['less'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:206: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:03:41.638007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2001914}\n",
      "skey                       int32\n",
      "date                       int32\n",
      "time                       int64\n",
      "clockAtArrival             int64\n",
      "datetime          datetime64[ns]\n",
      "ApplSeqNum                 int32\n",
      "order_side                 int32\n",
      "order_type                 int32\n",
      "order_price              float64\n",
      "order_qty                  int32\n",
      "dtype: object\n",
      "20191113\n",
      "order finished\n",
      "0:07:15.950505\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>BidApplSeqNum</th>\n",
       "      <th>OfferApplSeqNum</th>\n",
       "      <th>union</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "      <th>less</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [skey, BidApplSeqNum, OfferApplSeqNum, union, ApplSeqNum, less]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from unrar import rarfile\n",
    "import py7zr\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "columns1 = [\"Date\",\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",\"PreClosePx\",\n",
    "                   \"PxChnage1\",\"PXChange2\",\"openPrice\",\"HighPx\",\"LowPx\",\"close\",\"NumTrades\",\"cum_volume\",\"cum_amount\",\"PE1\",\"PE2\",\"TradingPhase\",\n",
    "                   \"totalofferqty\", \"wa_offerPrice\", \"totalbidqty\", \"wa_bidPrice\", \"PreNAV\", \"RealTimeNAV\", \"WarrantPremiumRate\", \"UpLimitPx\",\n",
    "                   \"DownLimitPx\", \"TotalLongPosition\", \"unknown1\", \"unknown2\", \"unknown3\"]\n",
    "columns2 = ['Date',\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",'ask1p','bid1p',\n",
    "                   \"ask1q\",\"bid1q\", 'ask2p','bid2p',\"ask2q\",\"bid2q\",'ask3p','bid3p',\"ask3q\",\"bid3q\",'ask4p','bid4p',\"ask4q\",\"bid4q\",'ask5p',\n",
    "                    'bid5p',\"ask5q\",\"bid5q\",'ask6p','bid6p',\"ask6q\",\"bid6q\",'ask7p','bid7p',\"ask7q\",\"bid7q\",'ask8p','bid8p',\"ask8q\",\"bid8q\",\n",
    "                   'ask9p','bid9p',\"ask9q\",\"bid9q\",'ask10p','bid10p',\"ask10q\",\"bid10q\",\"NUMORDERS_B1\",\"NOORDERS_B1\",\"ORDERQTY_B1\",\n",
    "                    \"NUMORDERS_S1\",\"NOORDERS_S1\",\"ORDERQTY_S1\"]\n",
    "columns3 =  [\"Date\",\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",\"PreClosePx\",\n",
    "                   \"PxChnage1\",\"PXChange2\",\"openPrice\",\"HighPx\",\"LowPx\",\"close\",\"NumTrades\",\"cum_volume\",\"cum_amount\",\"PE1\",\"PE2\",\"TradingPhase\",\n",
    "                   \"totalofferqty\", \"wa_offerPrice\", \"totalbidqty\", \"wa_bidPrice\", \"PreNAV\", \"RealTimeNAV\", \"WarrantPremiumRate\", \"UpLimitPx\",\n",
    "                   \"DownLimitPx\", \"TotalLongPosition\"]\n",
    "\n",
    "# startTm = datetime.datetime.now()\n",
    "# readPath = r'\\\\192.168.10.30\\Kevin_zhenyu\\day_stock\\***'\n",
    "# dataPathLs = np.array(glob.glob(readPath))\n",
    "# dataPathLs = dataPathLs[[np.array([os.path.basename(i).split('.')[0][:2] == 'SZ' for i in dataPathLs])]]\n",
    "# db = pd.DataFrame()\n",
    "# for p in dataPathLs:\n",
    "#     dayData = pd.read_csv(p, compression='gzip')\n",
    "#     db = pd.concat([db, dayData])\n",
    "# print(datetime.datetime.now() - startTm)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "year = \"2019\"\n",
    "startDate = \"1113\"\n",
    "endDate = \"1113\"\n",
    "df = []\n",
    "bad = []\n",
    "readPath = 'L:\\\\backup_data\\\\' + year + '\\\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "\n",
    "for data in dataPathLs:\n",
    "    am_order = pd.read_table(data + '\\\\am_hq_order_spot.txt',header=None)\n",
    "    am_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "    pm_order = pd.read_table(data + '\\\\pm_hq_order_spot.txt',header=None)\n",
    "    pm_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "    OrderLog1 = pd.concat([am_order, pm_order])\n",
    "    del am_order\n",
    "    del pm_order\n",
    "\n",
    "    OrderLog1 = OrderLog1[(OrderLog1[\"SecurityID\"] < 4000) | (OrderLog1[\"SecurityID\"] > 300000)]\n",
    "    OrderLog1[\"skey\"] = OrderLog1[\"SecurityID\"] + 2000000\n",
    "    OrderLog1[\"clockAtArrival\"] = OrderLog1[\"TransactTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    OrderLog1['datetime'] = OrderLog1[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    OrderLog1[\"time\"] = (OrderLog1['TransactTime'] - int(OrderLog1['TransactTime'].iloc[0]//1000000000*1000000000)).astype(np.int64)*1000\n",
    "    OrderLog1[\"order_type\"] =np.where(OrderLog1[\"order_type\"] == 'U', 3, OrderLog1[\"order_type\"])\n",
    "    for col in [\"skey\", \"date\", \"ApplSeqNum\", \"order_qty\", \"order_side\", \"order_type\"]:\n",
    "        OrderLog1[col] = OrderLog1[col].astype('int32')\n",
    "    display(OrderLog1[\"order_price\"].astype(str).apply(lambda x: len(x.split('.')[1])).unique())\n",
    "    \n",
    "    assert(OrderLog1[((OrderLog1[\"order_side\"] != 1) & (OrderLog1[\"order_side\"] != 2)) | (OrderLog1[\"order_type\"].isnull())].shape[0] == 0)\n",
    "    da_te = str(OrderLog1[\"date\"].iloc[0]) \n",
    "    da_te = da_te[:4] + '-' + da_te[4:6] + '-' + da_te[6:8]\n",
    "    db1 = db[db[\"date\"] == da_te]\n",
    "    sl = (db1[\"ID\"].str[2:].astype(int) + 2000000).unique()\n",
    "    del db1\n",
    "    try:\n",
    "        assert(len(set(sl) - set(OrderLog1[\"skey\"].unique())) == 0)\n",
    "    except:\n",
    "        print(set(sl) - set(OrderLog1[\"skey\"].unique()))\n",
    "    \n",
    "    OrderLog1 = OrderLog1[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ApplSeqNum\", \"order_side\", \"order_type\", \"order_price\",\n",
    "                                                 \"order_qty\"]]\n",
    "    \n",
    "    print(OrderLog1.dtypes)\n",
    "    print(OrderLog1[\"date\"].iloc[0])\n",
    "    print(\"order finished\")\n",
    "    \n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "    \n",
    "startDate = 20191113\n",
    "endDate = 20191113\n",
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "trade = db1.read('md_trade', start_date=startDate, end_date=endDate)\n",
    "trade = trade[trade['skey'] > 2000000]\n",
    "t1 = trade.groupby('skey')['BidApplSeqNum'].unique().reset_index()\n",
    "t2 = trade.groupby('skey')['OfferApplSeqNum'].unique().reset_index()\n",
    "t3 = OrderLog1.groupby('skey')['ApplSeqNum'].unique().reset_index()\n",
    "t = pd.merge(t1, t2, on='skey')\n",
    "t['union'] = [list(set(a) | set(b)) for a, b in zip(t.BidApplSeqNum, t.OfferApplSeqNum)]\n",
    "t = pd.merge(t, t3, on='skey')\n",
    "t['less'] = [len(set(a) - set(b)) for a, b in zip(t.union, t.ApplSeqNum)]\n",
    "t[t['less'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:206: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:04:47.195677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skey                       int32\n",
      "date                       int32\n",
      "time                       int64\n",
      "clockAtArrival             int64\n",
      "datetime          datetime64[ns]\n",
      "ApplSeqNum                 int32\n",
      "order_side                 int32\n",
      "order_type                 int32\n",
      "order_price              float64\n",
      "order_qty                  int32\n",
      "dtype: object\n",
      "20200316\n",
      "order finished\n",
      "0:17:38.436389\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>BidApplSeqNum</th>\n",
       "      <th>OfferApplSeqNum</th>\n",
       "      <th>union</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "      <th>less</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [skey, BidApplSeqNum, OfferApplSeqNum, union, ApplSeqNum, less]\n",
       "Index: []"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from unrar import rarfile\n",
    "import py7zr\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "columns1 = [\"Date\",\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",\"PreClosePx\",\n",
    "                   \"PxChnage1\",\"PXChange2\",\"openPrice\",\"HighPx\",\"LowPx\",\"close\",\"NumTrades\",\"cum_volume\",\"cum_amount\",\"PE1\",\"PE2\",\"TradingPhase\",\n",
    "                   \"totalofferqty\", \"wa_offerPrice\", \"totalbidqty\", \"wa_bidPrice\", \"PreNAV\", \"RealTimeNAV\", \"WarrantPremiumRate\", \"UpLimitPx\",\n",
    "                   \"DownLimitPx\", \"TotalLongPosition\", \"unknown1\", \"unknown2\", \"unknown3\"]\n",
    "columns2 = ['Date',\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",'ask1p','bid1p',\n",
    "                   \"ask1q\",\"bid1q\", 'ask2p','bid2p',\"ask2q\",\"bid2q\",'ask3p','bid3p',\"ask3q\",\"bid3q\",'ask4p','bid4p',\"ask4q\",\"bid4q\",'ask5p',\n",
    "                    'bid5p',\"ask5q\",\"bid5q\",'ask6p','bid6p',\"ask6q\",\"bid6q\",'ask7p','bid7p',\"ask7q\",\"bid7q\",'ask8p','bid8p',\"ask8q\",\"bid8q\",\n",
    "                   'ask9p','bid9p',\"ask9q\",\"bid9q\",'ask10p','bid10p',\"ask10q\",\"bid10q\",\"NUMORDERS_B1\",\"NOORDERS_B1\",\"ORDERQTY_B1\",\n",
    "                    \"NUMORDERS_S1\",\"NOORDERS_S1\",\"ORDERQTY_S1\"]\n",
    "columns3 =  [\"Date\",\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",\"PreClosePx\",\n",
    "                   \"PxChnage1\",\"PXChange2\",\"openPrice\",\"HighPx\",\"LowPx\",\"close\",\"NumTrades\",\"cum_volume\",\"cum_amount\",\"PE1\",\"PE2\",\"TradingPhase\",\n",
    "                   \"totalofferqty\", \"wa_offerPrice\", \"totalbidqty\", \"wa_bidPrice\", \"PreNAV\", \"RealTimeNAV\", \"WarrantPremiumRate\", \"UpLimitPx\",\n",
    "                   \"DownLimitPx\", \"TotalLongPosition\"]\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "readPath = r'\\\\192.168.10.30\\Kevin_zhenyu\\day_stock\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dataPathLs = dataPathLs[[np.array([os.path.basename(i).split('.')[0][:2] == 'SZ' for i in dataPathLs])]]\n",
    "db = pd.DataFrame()\n",
    "for p in dataPathLs:\n",
    "    dayData = pd.read_csv(p, compression='gzip')\n",
    "    db = pd.concat([db, dayData])\n",
    "print(datetime.datetime.now() - startTm)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "year = \"2020\"\n",
    "startDate = \"0316\"\n",
    "endDate = \"0316\"\n",
    "df = []\n",
    "bad = []\n",
    "readPath = 'L:\\\\backup_data\\\\' + year + '\\\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "\n",
    "for data in dataPathLs:\n",
    "    \n",
    "    path1 = data\n",
    "    am_order = pd.read_table(path1 + '\\\\am_hq_order_spot.txt',header=None)\n",
    "    am_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "               \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "    pm_order = pd.read_table(path1 + '\\\\pm_hq_order_spot.txt',header=None)\n",
    "    pm_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "               \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "    OrderLog1 = pd.concat([am_order, pm_order])\n",
    "    del am_order\n",
    "    del pm_order\n",
    "\n",
    "    OrderLog1 = OrderLog1[(OrderLog1[\"SecurityID\"] < 4000) | (OrderLog1[\"SecurityID\"] > 300000)]\n",
    "    OrderLog1[\"skey\"] = OrderLog1[\"SecurityID\"] + 2000000\n",
    "    OrderLog1[\"clockAtArrival\"] = OrderLog1[\"TransactTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    OrderLog1['datetime'] = OrderLog1[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    OrderLog1[\"time\"] = (OrderLog1['TransactTime'] - int(OrderLog1['TransactTime'].iloc[0]//1000000000*1000000000)).astype(np.int64)*1000\n",
    "    OrderLog1[\"order_type\"] =np.where(OrderLog1[\"order_type\"] == 'U', 3, OrderLog1[\"order_type\"])\n",
    "    for col in [\"skey\", \"date\", \"ApplSeqNum\", \"order_qty\", \"order_side\", \"order_type\"]:\n",
    "        OrderLog1[col] = OrderLog1[col].astype('int32')\n",
    "    display(OrderLog1[\"order_price\"].astype(str).apply(lambda x: len(x.split('.')[1])).unique())\n",
    "    \n",
    "    assert(OrderLog1[((OrderLog1[\"order_side\"] != 1) & (OrderLog1[\"order_side\"] != 2)) | (OrderLog1[\"order_type\"].isnull())].shape[0] == 0)\n",
    "    da_te = str(OrderLog1[\"date\"].iloc[0]) \n",
    "    da_te = da_te[:4] + '-' + da_te[4:6] + '-' + da_te[6:8]\n",
    "    db1 = db[db[\"date\"] == da_te]\n",
    "    sl = (db1[\"ID\"].str[2:].astype(int) + 2000000).unique()\n",
    "    del db1\n",
    "    try:\n",
    "        assert(len(set(sl) - set(OrderLog1[\"skey\"].unique())) == 0)\n",
    "    except:\n",
    "        print(set(sl) - set(OrderLog1[\"skey\"].unique()))\n",
    "    \n",
    "    OrderLog1 = OrderLog1[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ApplSeqNum\", \"order_side\", \"order_type\", \"order_price\",\n",
    "                                                 \"order_qty\"]]\n",
    "    \n",
    "    print(OrderLog1.dtypes)\n",
    "    print(OrderLog1[\"date\"].iloc[0])\n",
    "    print(\"order finished\")\n",
    "    \n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "startDate = 20200316\n",
    "endDate = 20200316\n",
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "trade = db1.read('md_trade', start_date=startDate, end_date=endDate)\n",
    "trade = trade[trade['skey'] > 2000000]\n",
    "t1 = trade.groupby('skey')['BidApplSeqNum'].unique().reset_index()\n",
    "t2 = trade.groupby('skey')['OfferApplSeqNum'].unique().reset_index()\n",
    "t3 = OrderLog1.groupby('skey')['ApplSeqNum'].unique().reset_index()\n",
    "t = pd.merge(t1, t2, on='skey')\n",
    "t['union'] = [list(set(a) | set(b)) for a, b in zip(t.BidApplSeqNum, t.OfferApplSeqNum)]\n",
    "t = pd.merge(t, t3, on='skey')\n",
    "t['less'] = [len(set(a) - set(b)) for a, b in zip(t.union, t.ApplSeqNum)]\n",
    "t[t['less'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2001872, 2001914}\n",
      "skey                       int32\n",
      "date                       int32\n",
      "time                       int64\n",
      "clockAtArrival             int64\n",
      "datetime          datetime64[ns]\n",
      "ApplSeqNum                 int32\n",
      "order_side                 int32\n",
      "order_type                 int32\n",
      "order_price              float64\n",
      "order_qty                  int32\n",
      "dtype: object\n",
      "20170804\n",
      "order finished\n",
      "0:13:04.956434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>BidApplSeqNum</th>\n",
       "      <th>OfferApplSeqNum</th>\n",
       "      <th>union</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "      <th>less</th>\n",
       "      <th>less1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [skey, BidApplSeqNum, OfferApplSeqNum, union, ApplSeqNum, less, less1]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2017-2019 version\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from unrar import rarfile\n",
    "import py7zr\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "columns1 = [\"Date\",\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",\"PreClosePx\",\n",
    "                   \"PxChnage1\",\"PXChange2\",\"openPrice\",\"HighPx\",\"LowPx\",\"close\",\"NumTrades\",\"cum_volume\",\"cum_amount\",\"PE1\",\"PE2\",\"TradingPhase\",\n",
    "                   \"totalofferqty\", \"wa_offerPrice\", \"totalbidqty\", \"wa_bidPrice\", \"PreNAV\", \"RealTimeNAV\", \"WarrantPremiumRate\", \"UpLimitPx\",\n",
    "                   \"DownLimitPx\", \"TotalLongPosition\", \"unknown1\", \"unknown2\", \"unknown3\"]\n",
    "columns2 = ['Date',\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",'ask1p','bid1p',\n",
    "                   \"ask1q\",\"bid1q\", 'ask2p','bid2p',\"ask2q\",\"bid2q\",'ask3p','bid3p',\"ask3q\",\"bid3q\",'ask4p','bid4p',\"ask4q\",\"bid4q\",'ask5p',\n",
    "                    'bid5p',\"ask5q\",\"bid5q\",'ask6p','bid6p',\"ask6q\",\"bid6q\",'ask7p','bid7p',\"ask7q\",\"bid7q\",'ask8p','bid8p',\"ask8q\",\"bid8q\",\n",
    "                   'ask9p','bid9p',\"ask9q\",\"bid9q\",'ask10p','bid10p',\"ask10q\",\"bid10q\",\"NUMORDERS_B1\",\"NOORDERS_B1\",\"ORDERQTY_B1\",\n",
    "                    \"NUMORDERS_S1\",\"NOORDERS_S1\",\"ORDERQTY_S1\"]\n",
    "columns3 =  [\"Date\",\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",\"PreClosePx\",\n",
    "                   \"PxChnage1\",\"PXChange2\",\"openPrice\",\"HighPx\",\"LowPx\",\"close\",\"NumTrades\",\"cum_volume\",\"cum_amount\",\"PE1\",\"PE2\",\"TradingPhase\",\n",
    "                   \"totalofferqty\", \"wa_offerPrice\", \"totalbidqty\", \"wa_bidPrice\", \"PreNAV\", \"RealTimeNAV\", \"WarrantPremiumRate\", \"UpLimitPx\",\n",
    "                   \"DownLimitPx\", \"TotalLongPosition\"]\n",
    "\n",
    "# startTm = datetime.datetime.now()\n",
    "# readPath = r'\\\\192.168.10.30\\Kevin_zhenyu\\day_stock\\***'\n",
    "# dataPathLs = np.array(glob.glob(readPath))\n",
    "# dataPathLs = dataPathLs[[np.array([os.path.basename(i).split('.')[0][:2] == 'SZ' for i in dataPathLs])]]\n",
    "# db = pd.DataFrame()\n",
    "# for p in dataPathLs:\n",
    "#     dayData = pd.read_csv(p, compression='gzip')\n",
    "#     db = pd.concat([db, dayData])\n",
    "# print(datetime.datetime.now() - startTm)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "year = \"2017\"\n",
    "startDate = \"0804\"\n",
    "endDate = \"0804\"\n",
    "df = []\n",
    "bad = []\n",
    "readPath = 'J:\\\\LEVEL2_shenzhen\\\\' + year + '\\\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "\n",
    "for data in dataPathLs:\n",
    "    if len(np.array(glob.glob(data +'\\\\***'))) == 0:\n",
    "        continue\n",
    "    \n",
    "    if len(np.array(glob.glob(data +'\\\\pm_hq_order_spot.7z'))) == 1:\n",
    "        date = os.path.basename(data)\n",
    "        path = 'L:\\\\backup_data\\\\' + year \n",
    "        os.chdir(data)\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\am_hq_order_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\am_hq_order_spot.7z')\n",
    "            bad.append(data + '\\\\am_hq_order_spot.7z')\n",
    "            continue\n",
    "        path1 = path + '\\\\' + date\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\pm_hq_order_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\pm_hq_order_spot.7z')\n",
    "            bad.append(data + '\\\\pm_hq_order_spot.7z')\n",
    "            continue\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        \n",
    "        am_order = pd.read_table(path1 + '\\\\am_hq_order_spot.txt',header=None)\n",
    "        am_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "        pm_order = pd.read_table(path1 + '\\\\pm_hq_order_spot.txt',header=None)\n",
    "        pm_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "        OrderLog1 = pd.concat([am_order, pm_order])\n",
    "        del am_order\n",
    "        del pm_order\n",
    "  \n",
    "    \n",
    "    elif len(np.array(glob.glob(data +'\\\\pm_hq_order_spot.7z.001'))) == 1:\n",
    "        date = os.path.basename(data)\n",
    "        path = 'L:\\\\backup_data\\\\' + year \n",
    "        os.chdir(data)\n",
    "        os.system(\"copy /b am_hq_order_spot.7z.* am_hq_order_spot.7z\")\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\am_hq_order_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\am_hq_order_spot.7z')\n",
    "            bad.append(data + '\\\\am_hq_order_spot.7z')\n",
    "            continue\n",
    "        path1 = path + '\\\\' + date\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        os.system(\"copy /b pm_hq_order_spot.7z.* pm_hq_order_spot.7z\")\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\pm_hq_order_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\pm_hq_order_spot.7z')\n",
    "            bad.append(data + '\\\\pm_hq_order_spot.7z')\n",
    "            continue\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        \n",
    "        am_order = pd.read_table(path1 + '\\\\am_hq_order_spot.txt',header=None)\n",
    "        am_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "        pm_order = pd.read_table(path1 + '\\\\pm_hq_order_spot.txt',header=None)\n",
    "        pm_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "        OrderLog1 = pd.concat([am_order, pm_order])\n",
    "        del am_order\n",
    "        del pm_order\n",
    "\n",
    "    elif len(np.array(glob.glob(data +'\\\\hq_order.7z'))) == 1:\n",
    "        date = os.path.basename(data)\n",
    "        path = 'L:\\\\backup_data\\\\' + year \n",
    "        os.chdir(data)\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\hq_order.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\hq_order.7z')\n",
    "            bad.append(data + '\\\\hq_order.7z')\n",
    "            continue\n",
    "        path1 = path + '\\\\' + date\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        OrderLog1 = pd.read_table(path1 + '\\\\hq_order.txt',header=None)\n",
    "        OrderLog1.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "    \n",
    "    \n",
    "    OrderLog1 = OrderLog1[(OrderLog1[\"SecurityID\"] < 4000) | (OrderLog1[\"SecurityID\"] > 300000)]\n",
    "    OrderLog1[\"skey\"] = OrderLog1[\"SecurityID\"] + 2000000\n",
    "    OrderLog1[\"clockAtArrival\"] = OrderLog1[\"TransactTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    OrderLog1['datetime'] = OrderLog1[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    OrderLog1[\"time\"] = (OrderLog1['TransactTime'] - int(OrderLog1['TransactTime'].iloc[0]//1000000000*1000000000)).astype(np.int64)*1000\n",
    "    OrderLog1[\"order_type\"] =np.where(OrderLog1[\"order_type\"] == 'U', 3, OrderLog1[\"order_type\"])\n",
    "    for col in [\"skey\", \"date\", \"ApplSeqNum\", \"order_qty\", \"order_side\", \"order_type\"]:\n",
    "        OrderLog1[col] = OrderLog1[col].astype('int32')\n",
    "    display(OrderLog1[\"order_price\"].astype(str).apply(lambda x: len(x.split('.')[1])).unique())\n",
    "    \n",
    "    assert(OrderLog1[((OrderLog1[\"order_side\"] != 1) & (OrderLog1[\"order_side\"] != 2)) | (OrderLog1[\"order_type\"].isnull())].shape[0] == 0)\n",
    "    da_te = str(OrderLog1[\"date\"].iloc[0]) \n",
    "    da_te = da_te[:4] + '-' + da_te[4:6] + '-' + da_te[6:8]\n",
    "    db1 = db[db[\"date\"] == da_te]\n",
    "    sl = (db1[\"ID\"].str[2:].astype(int) + 2000000).unique()\n",
    "    del db1\n",
    "    try:\n",
    "        assert(len(set(sl) - set(OrderLog1[\"skey\"].unique())) == 0)\n",
    "    except:\n",
    "        print(set(sl) - set(OrderLog1[\"skey\"].unique()))\n",
    "    \n",
    "    OrderLog1 = OrderLog1[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ApplSeqNum\", \"order_side\", \"order_type\", \"order_price\",\n",
    "                                                 \"order_qty\"]]\n",
    "    \n",
    "    print(OrderLog1.dtypes)\n",
    "    print(OrderLog1[\"date\"].iloc[0])\n",
    "    print(\"order finished\")\n",
    "    \n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "    \n",
    "startDate = 20170804\n",
    "endDate = 20170804\n",
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "trade = db1.read('md_trade', start_date=startDate, end_date=endDate)\n",
    "trade = trade[trade['skey'] > 2000000]\n",
    "t1 = trade.groupby('skey')['BidApplSeqNum'].unique().reset_index()\n",
    "t2 = trade.groupby('skey')['OfferApplSeqNum'].unique().reset_index()\n",
    "t3 = OrderLog1.groupby('skey')['ApplSeqNum'].unique().reset_index()\n",
    "t = pd.merge(t1, t2, on='skey')\n",
    "t['union'] = [list(set(a) | set(b)) for a, b in zip(t.BidApplSeqNum, t.OfferApplSeqNum)]\n",
    "t = pd.merge(t, t3, on='skey')\n",
    "t['less'] = [len(set(a) - set(b)) for a, b in zip(t.union, t.ApplSeqNum)]\n",
    "t['less1'] = [list(set(a) - set(b))[0] for a, b in zip(t.union, t.ApplSeqNum)]\n",
    "display(t['less1'].unique())\n",
    "t[t['less'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>clockAtArrival</th>\n",
       "      <th>datetime</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "      <th>order_side</th>\n",
       "      <th>order_type</th>\n",
       "      <th>order_price</th>\n",
       "      <th>order_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2002889</td>\n",
       "      <td>20170804</td>\n",
       "      <td>91500000000</td>\n",
       "      <td>1501809300000000</td>\n",
       "      <td>2017-08-04 09:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27.27</td>\n",
       "      <td>94700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2002889</td>\n",
       "      <td>20170804</td>\n",
       "      <td>91500000000</td>\n",
       "      <td>1501809300000000</td>\n",
       "      <td>2017-08-04 09:15:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27.27</td>\n",
       "      <td>36700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2002889</td>\n",
       "      <td>20170804</td>\n",
       "      <td>91500000000</td>\n",
       "      <td>1501809300000000</td>\n",
       "      <td>2017-08-04 09:15:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27.27</td>\n",
       "      <td>33700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2002889</td>\n",
       "      <td>20170804</td>\n",
       "      <td>91500000000</td>\n",
       "      <td>1501809300000000</td>\n",
       "      <td>2017-08-04 09:15:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27.27</td>\n",
       "      <td>15500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2002890</td>\n",
       "      <td>20170804</td>\n",
       "      <td>91500000000</td>\n",
       "      <td>1501809300000000</td>\n",
       "      <td>2017-08-04 09:15:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22.23</td>\n",
       "      <td>34700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      skey      date         time    clockAtArrival            datetime  \\\n",
       "0  2002889  20170804  91500000000  1501809300000000 2017-08-04 09:15:00   \n",
       "1  2002889  20170804  91500000000  1501809300000000 2017-08-04 09:15:00   \n",
       "2  2002889  20170804  91500000000  1501809300000000 2017-08-04 09:15:00   \n",
       "3  2002889  20170804  91500000000  1501809300000000 2017-08-04 09:15:00   \n",
       "4  2002890  20170804  91500000000  1501809300000000 2017-08-04 09:15:00   \n",
       "\n",
       "   ApplSeqNum  order_side  order_type  order_price  order_qty  \n",
       "0           1           1           2        27.27      94700  \n",
       "1           2           1           2        27.27      36700  \n",
       "2           3           1           2        27.27      33700  \n",
       "3           4           1           2        27.27      15500  \n",
       "4           5           1           2        22.23      34700  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrderLog1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "\n",
    "db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "db1.write('md_order', OrderLog1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\win\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>max_volume</th>\n",
       "      <th>max_amount</th>\n",
       "      <th>skey</th>\n",
       "      <th>cum_volume</th>\n",
       "      <th>cum_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>SZ001872</td>\n",
       "      <td>13885068.0</td>\n",
       "      <td>4.105728e+08</td>\n",
       "      <td>2001872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>419</td>\n",
       "      <td>SZ001914</td>\n",
       "      <td>4722353.0</td>\n",
       "      <td>4.991092e+07</td>\n",
       "      <td>2001914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  max_volume    max_amount     skey  cum_volume  cum_amount\n",
       "417  SZ001872  13885068.0  4.105728e+08  2001872         NaN         NaN\n",
       "419  SZ001914   4722353.0  4.991092e+07  2001914         NaN         NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>max_volume</th>\n",
       "      <th>max_amount</th>\n",
       "      <th>skey</th>\n",
       "      <th>cum_volume</th>\n",
       "      <th>cum_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>SZ001872</td>\n",
       "      <td>13885068.0</td>\n",
       "      <td>4.105728e+08</td>\n",
       "      <td>2001872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>419</td>\n",
       "      <td>SZ001914</td>\n",
       "      <td>4722353.0</td>\n",
       "      <td>4.991092e+07</td>\n",
       "      <td>2001914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  max_volume    max_amount     skey  cum_volume  cum_amount\n",
       "417  SZ001872  13885068.0  4.105728e+08  2001872         NaN         NaN\n",
       "419  SZ001914   4722353.0  4.991092e+07  2001914         NaN         NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-04\n",
      "trade finished\n",
      "0:12:30.713481\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from unrar import rarfile\n",
    "import py7zr\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "columns1 = [\"Date\",\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",\"PreClosePx\",\n",
    "                   \"PxChnage1\",\"PXChange2\",\"openPrice\",\"HighPx\",\"LowPx\",\"close\",\"NumTrades\",\"cum_volume\",\"cum_amount\",\"PE1\",\"PE2\",\"TradingPhase\",\n",
    "                   \"totalofferqty\", \"wa_offerPrice\", \"totalbidqty\", \"wa_bidPrice\", \"PreNAV\", \"RealTimeNAV\", \"WarrantPremiumRate\", \"UpLimitPx\",\n",
    "                   \"DownLimitPx\", \"TotalLongPosition\", \"unknown1\", \"unknown2\", \"unknown3\"]\n",
    "columns2 = ['Date',\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",'ask1p','bid1p',\n",
    "                   \"ask1q\",\"bid1q\", 'ask2p','bid2p',\"ask2q\",\"bid2q\",'ask3p','bid3p',\"ask3q\",\"bid3q\",'ask4p','bid4p',\"ask4q\",\"bid4q\",'ask5p',\n",
    "                    'bid5p',\"ask5q\",\"bid5q\",'ask6p','bid6p',\"ask6q\",\"bid6q\",'ask7p','bid7p',\"ask7q\",\"bid7q\",'ask8p','bid8p',\"ask8q\",\"bid8q\",\n",
    "                   'ask9p','bid9p',\"ask9q\",\"bid9q\",'ask10p','bid10p',\"ask10q\",\"bid10q\",\"NUMORDERS_B1\",\"NOORDERS_B1\",\"ORDERQTY_B1\",\n",
    "                    \"NUMORDERS_S1\",\"NOORDERS_S1\",\"ORDERQTY_S1\"]\n",
    "columns3 =  [\"Date\",\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",\"PreClosePx\",\n",
    "                   \"PxChnage1\",\"PXChange2\",\"openPrice\",\"HighPx\",\"LowPx\",\"close\",\"NumTrades\",\"cum_volume\",\"cum_amount\",\"PE1\",\"PE2\",\"TradingPhase\",\n",
    "                   \"totalofferqty\", \"wa_offerPrice\", \"totalbidqty\", \"wa_bidPrice\", \"PreNAV\", \"RealTimeNAV\", \"WarrantPremiumRate\", \"UpLimitPx\",\n",
    "                   \"DownLimitPx\", \"TotalLongPosition\"]\n",
    "\n",
    "# startTm = datetime.datetime.now()\n",
    "# readPath = r'\\\\192.168.10.30\\Kevin_zhenyu\\day_stock\\***'\n",
    "# dataPathLs = np.array(glob.glob(readPath))\n",
    "# dataPathLs = dataPathLs[[np.array([os.path.basename(i).split('.')[0][:2] == 'SZ' for i in dataPathLs])]]\n",
    "# db = pd.DataFrame()\n",
    "# for p in dataPathLs:\n",
    "#     dayData = pd.read_csv(p, compression='gzip')\n",
    "#     db = pd.concat([db, dayData])\n",
    "# print(datetime.datetime.now() - startTm)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "year = \"2017\"\n",
    "startDate = \"0804\"\n",
    "endDate = \"0804\"\n",
    "df = []\n",
    "bad = []\n",
    "readPath = 'J:\\\\LEVEL2_shenzhen\\\\' + year + '\\\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "\n",
    "for data in dataPathLs:\n",
    "    if len(np.array(glob.glob(data +'\\\\***'))) == 0:\n",
    "        continue\n",
    "    \n",
    "    if len(np.array(glob.glob(data +'\\\\am_hq_trade_spot.7z'))) == 1:\n",
    "        date = os.path.basename(data)\n",
    "        path = 'L:\\\\backup data\\\\' + year \n",
    "        os.chdir(data)\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\am_hq_trade_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\am_hq_trade_spot.7z')\n",
    "            bad.append(data + '\\\\am_hq_trade_spot.7z')\n",
    "            continue\n",
    "        path1 = path + '\\\\' + date\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\pm_hq_trade_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\pm_hq_trade_spot.7z')\n",
    "            bad.append(data + '\\\\pm_hq_trade_spot.7z')\n",
    "            continue\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "\n",
    "        am_trade = pd.read_table(path1 + \"\\\\am_hq_trade_spot.txt\",header=None)\n",
    "        am_trade.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"BidApplSeqNum\",\n",
    "                   \"OfferApplSeqNum\",\"trade_price\",\"trade_qty\",\"trade_type\",\"TransactTime\"]\n",
    "        pm_trade = pd.read_table(path1 + \"\\\\pm_hq_trade_spot.txt\",header=None)\n",
    "        pm_trade.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"BidApplSeqNum\",\n",
    "                   \"OfferApplSeqNum\",\"trade_price\",\"trade_qty\",\"trade_type\",\"TransactTime\"]\n",
    "        TradeLogSZ1 = pd.concat([am_trade, pm_trade])\n",
    "        del am_trade\n",
    "        del pm_trade\n",
    "        \n",
    "    elif len(np.array(glob.glob(data +'\\\\am_hq_trade_spot.7z.001'))) == 1:\n",
    "        date = os.path.basename(data)\n",
    "        path = 'L:\\\\backup data\\\\' + year \n",
    "        os.chdir(data)\n",
    "        os.system(\"copy /b am_hq_trade_spot.7z.* am_hq_trade_spot.7z\")\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\am_hq_trade_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\am_hq_trade_spot.7z')\n",
    "            bad.append(data + '\\\\am_hq_trade_spot.7z')\n",
    "            continue\n",
    "        path1 = path + '\\\\' + date\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        os.system(\"copy /b pm_hq_trade_spot.7z.* pm_hq_trade_spot.7z\")\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\pm_hq_trade_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\pm_hq_trade_spot.7z')\n",
    "            bad.append(data + '\\\\pm_hq_trade_spot.7z')\n",
    "            continue\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        \n",
    "        am_trade = pd.read_table(path1 + \"\\\\am_hq_trade_spot.txt\",header=None)\n",
    "        am_trade.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"BidApplSeqNum\",\n",
    "                   \"OfferApplSeqNum\",\"trade_price\",\"trade_qty\",\"trade_type\",\"TransactTime\"]\n",
    "        pm_trade = pd.read_table(path1 + \"\\\\pm_hq_trade_spot.txt\",header=None)\n",
    "        pm_trade.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"BidApplSeqNum\",\n",
    "                   \"OfferApplSeqNum\",\"trade_price\",\"trade_qty\",\"trade_type\",\"TransactTime\"]\n",
    "        TradeLogSZ1 = pd.concat([am_trade, pm_trade])\n",
    "        del am_trade\n",
    "        del pm_trade\n",
    "        \n",
    "    elif len(np.array(glob.glob(data +'\\\\hq_trade.7z'))) == 1:\n",
    "        date = os.path.basename(data)\n",
    "        path = 'L:\\\\backup data\\\\' + year \n",
    "        os.chdir(data)\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\hq_trade.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\hq_trade.7z')\n",
    "            bad.append(data + '\\\\hq_trade.7z')\n",
    "            continue\n",
    "        path1 = path + '\\\\' + date\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        \n",
    "        TradeLogSZ1 = pd.read_table(path1 + \"\\\\hq_trade.txt\",header=None)\n",
    "        TradeLogSZ1.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"BidApplSeqNum\",\n",
    "                   \"OfferApplSeqNum\",\"trade_price\",\"trade_qty\",\"trade_type\",\"TransactTime\"]\n",
    "\n",
    "    \n",
    "    TradeLogSZ1 = TradeLogSZ1[(TradeLogSZ1[\"SecurityID\"] < 4000) | (TradeLogSZ1[\"SecurityID\"] > 300000)]\n",
    "    TradeLogSZ1[\"trade_money\"] = TradeLogSZ1[\"trade_price\"] * TradeLogSZ1[\"trade_qty\"]\n",
    "    TradeLogSZ1[\"trade_flag\"] = 0\n",
    "    TradeLogSZ1[\"skey\"] = TradeLogSZ1[\"SecurityID\"] + 2000000\n",
    "    TradeLogSZ1[\"clockAtArrival\"] = TradeLogSZ1[\"TransactTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    TradeLogSZ1['datetime'] = TradeLogSZ1[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    TradeLogSZ1[\"time\"] = (TradeLogSZ1['TransactTime'] - int(TradeLogSZ1['TransactTime'].iloc[0]//1000000000*1000000000)).astype(np.int64)*1000\n",
    "    TradeLogSZ1[\"trade_type\"] = np.where(TradeLogSZ1[\"trade_type\"] == 'F', 1, TradeLogSZ1[\"trade_type\"])\n",
    "    for col in [\"skey\", \"date\", \"ApplSeqNum\", \"BidApplSeqNum\", \"OfferApplSeqNum\", \"trade_qty\", \"trade_type\", \"trade_flag\"]:\n",
    "        TradeLogSZ1[col] = TradeLogSZ1[col].astype('int32')\n",
    "    for cols in [\"trade_money\"]:\n",
    "        TradeLogSZ1[cols] = TradeLogSZ1[cols].round(2)\n",
    "    display(TradeLogSZ1[\"trade_price\"].astype(str).apply(lambda x: len(x.split('.')[1])).unique())\n",
    "    \n",
    "    da_te = str(TradeLogSZ1[\"date\"].iloc[0]) \n",
    "    da_te = da_te[:4] + '-' + da_te[4:6] + '-' + da_te[6:8]\n",
    "    db1 = db[db[\"date\"] == da_te]\n",
    "    sl = (db1[\"ID\"].str[2:].astype(int) + 2000000).unique()\n",
    "    db1[\"max_volume\"] = db1.groupby(\"ID\")[\"d_volume\"].transform(\"max\")\n",
    "    db1[\"max_amount\"] = db1.groupby(\"ID\")[\"d_amount\"].transform(\"max\")\n",
    "    t1 = db1.groupby(\"ID\")[\"max_volume\", \"max_amount\"].first().reset_index()\n",
    "    del db1\n",
    "    t1[\"skey\"] = t1[\"ID\"].str[2:].astype(int) + 2000000\n",
    "    trade1 = TradeLogSZ1[TradeLogSZ1[\"trade_type\"] == 1].groupby(\"skey\")[\"trade_qty\"].sum().reset_index()\n",
    "    trade1.columns=[\"skey\", \"cum_volume\"]\n",
    "    trade2 = TradeLogSZ1[TradeLogSZ1[\"trade_type\"] == 1].groupby(\"skey\")[\"trade_money\"].sum().reset_index()\n",
    "    trade2.columns=[\"skey\", \"cum_amount\"]\n",
    "    t2 = pd.merge(trade1, trade2, on=\"skey\")\n",
    "    re = pd.merge(t1, t2, on=\"skey\", how=\"outer\")\n",
    "    try:\n",
    "        assert(t1.shape[0] == t2.shape[0])\n",
    "        assert(re[re[\"cum_volume\"] != re[\"max_volume\"]].shape[0] == 0)\n",
    "        assert(re[re[\"cum_amount\"].round(2) != re[\"max_amount\"]].shape[0] == 0)\n",
    "    except:\n",
    "        display(set(t1[\"skey\"]) - set(t2[\"skey\"]))\n",
    "        display(re[re[\"cum_volume\"] != re[\"max_volume\"]])\n",
    "        display(re[re[\"cum_amount\"].round(2) != re[\"max_amount\"]])\n",
    "    del t1\n",
    "    del t2\n",
    "    del re\n",
    " \n",
    "    TradeLogSZ1 = TradeLogSZ1[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ApplSeqNum\", \"trade_type\", \"trade_flag\",\n",
    "                                                 \"trade_price\", \"trade_qty\", \"BidApplSeqNum\", \"OfferApplSeqNum\"]]\n",
    "    print(da_te)\n",
    "    print(\"trade finished\")\n",
    "\n",
    "    print(datetime.datetime.now() - startTm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skey                        int32\n",
       "date                        int32\n",
       "time                        int64\n",
       "clockAtArrival              int64\n",
       "datetime           datetime64[ns]\n",
       "ApplSeqNum                  int32\n",
       "trade_type                  int32\n",
       "trade_flag                  int32\n",
       "trade_price               float64\n",
       "trade_qty                   int32\n",
       "BidApplSeqNum               int32\n",
       "OfferApplSeqNum             int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TradeLogSZ1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database_name = 'com_md_eq_cn'\n",
    "# user = \"zhenyuy\"\n",
    "# password = \"bnONBrzSMGoE\"\n",
    "\n",
    "# db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "# db1.write('md_trade', TradeLogSZ1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
