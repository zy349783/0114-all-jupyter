{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get list of stocks In_fromTop, In_fromBottom, Out_toTop, Out_toBottom at the time of underlying changing\n",
    "csi_index = pd.read_csv('D:\\\\work\\\\project 3 event study\\\\index_comp_SH000905.csv',\n",
    "                        encoding=\"utf-8\")\n",
    "csi_index_300 = pd.read_csv('D:\\\\work\\\\project 3 event study\\\\index_comp_SH000300.csv',\n",
    "                            encoding=\"utf-8\")\n",
    "csi_index_1000 = pd.read_csv('D:\\\\work\\\\project 3 event study\\\\index_comp_SH000852.csv',\n",
    "                        encoding=\"utf-8\")\n",
    "csi_rest = pd.read_csv('D:\\\\work\\\\project 3 event study\\\\index_comp_SH000985.csv',\n",
    "                        encoding=\"utf-8\")\n",
    "# l1 = pd.read_csv(\"C:\\\\Users\\\\win\\\\Desktop\\\\预测沪深调入.csv\", encoding=\"GBK\")\n",
    "# l2 = pd.read_csv(\"C:\\\\Users\\\\win\\\\Desktop\\\\预测沪深调出.csv\", encoding=\"GBK\")\n",
    "# l3 = pd.read_csv(\"C:\\\\Users\\\\win\\\\Desktop\\\\预测中证调入.csv\", encoding=\"GBK\")\n",
    "# l4 = pd.read_csv(\"C:\\\\Users\\\\win\\\\Desktop\\\\预测中证调出.csv\", encoding=\"GBK\")\n",
    "alpha = pd.read_csv('E:\\\\new_beta.csv', encoding=\"GBK\").iloc[:, 1:]\n",
    "alpha[\"Date\"] = alpha[\"Date\"].apply(lambda x: str(x))\n",
    "alpha[\"Date\"] = pd.to_datetime(alpha[\"Date\"])\n",
    "csi_index[\"Date\"] = csi_index[\"Date\"].apply(lambda x: str(x))\n",
    "csi_index_300[\"Date\"] = csi_index_300[\"Date\"].apply(lambda x: str(x))\n",
    "csi_index_1000[\"Date\"] = csi_index_1000[\"Date\"].apply(lambda x: str(x))\n",
    "csi_rest[\"Date\"] = csi_rest[\"Date\"].apply(lambda x: str(x))\n",
    "da_te = csi_index[\"Date\"]\n",
    "sto_ck = pd.read_csv('E:\\\\all_stock.csv', encoding=\"GBK\").iloc[:, 1:]\n",
    "sto_ck[\"returns\"] = sto_ck.groupby(\"Symbol\")['close'].apply(lambda x: x/x.shift(1)-1)\n",
    "sto_ck[\"Date\"] = sto_ck[\"Date\"].apply(lambda x: str(x))\n",
    "sto_ck[\"Date\"] = pd.to_datetime(sto_ck[\"Date\"])\n",
    "xx = []\n",
    "dd1 = []\n",
    "dd2 = []\n",
    "new_in = {}\n",
    "old_out = {}\n",
    "In_fromTop = {}\n",
    "In_fromBottom = {}\n",
    "Out_toTop = {}\n",
    "Out_toBottom = {}\n",
    "# new_in = pd.DataFrame()\n",
    "# old_out = pd.DataFrame()\n",
    "# In_fromTop = pd.DataFrame(index=np.arange(50))\n",
    "# In_fromBottom = pd.DataFrame(index=np.arange(50))\n",
    "# Out_toTop = pd.DataFrame(index=np.arange(50))\n",
    "# Out_toBottom = pd.DataFrame(index=np.arange(50))\n",
    "\n",
    "# IF\n",
    "xx.append(csi_index_300.columns[csi_index_300.iloc[0, :] != 0])\n",
    "for i in range(1, len(csi_index_300)):\n",
    "    xx.append(csi_index_300.columns[csi_index_300.iloc[i, :] != 0])\n",
    "    new_in[csi_index_300.iloc[i, 0]] = list(set(xx[i][1:]) - set(xx[i - 1][1:]))\n",
    "    old_out[csi_index_300.iloc[i, 0]] = list(set(xx[i - 1][1:]) - set(xx[i][1:]))\n",
    "new_in = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in new_in.items()]))\n",
    "old_out = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in old_out.items()]))\n",
    "new_in = new_in.dropna(axis=1, thresh=5)\n",
    "old_out = old_out.dropna(axis=1, thresh=5)\n",
    "print(new_in)\n",
    "print(old_out)\n",
    "\n",
    "\n",
    "# # IC\n",
    "# xx.append(csi_index.columns[csi_index.iloc[0, :] != 0])\n",
    "# for i in range(1, len(csi_index)):\n",
    "#     xx.append(csi_index.columns[csi_index.iloc[i, :] != 0])\n",
    "#     new_in[csi_index.iloc[i, 0]] = pd.Series(list(set(xx[i][1:]) - set(xx[i - 1][1:])))\n",
    "#     old_out[csi_index.iloc[i, 0]] = pd.Series(list(set(xx[i - 1][1:]) - set(xx[i][1:])))\n",
    "# new_in = new_in.dropna(axis=1, how=\"any\")\n",
    "# old_out = old_out.dropna(axis=1, how=\"any\")\n",
    "#\n",
    "# print(da_te)\n",
    "# print(new_in)\n",
    "# print(old_out)\n",
    "#\n",
    "# hs300_list = csi_index_300.columns\n",
    "# for i in range(len(old_out.columns)):\n",
    "#     test1 = csi_index_300[csi_index_300[\"Date\"] == old_out.columns[i]][list(set(hs300_list) & set(old_out.iloc[:, i]))]\n",
    "#     Out_toTop[old_out.columns[i]] = pd.Series(test1.columns[(test1 != 0).values[0]])\n",
    "#     Out_toBottom[old_out.columns[i]] = pd.Series(list(set(old_out.iloc[:, i]) - set(Out_toTop[old_out.columns[i]])))\n",
    "#     print(Out_toTop.iloc[:, i].count() + Out_toBottom.iloc[:, i].count())\n",
    "# for i in range(len(new_in.columns)):\n",
    "#     t = da_te[da_te[da_te == new_in.columns[i]].index[0] - 1]\n",
    "#     test1 = csi_index_300[csi_index_300[\"Date\"] == t][list(set(hs300_list) & set(new_in.iloc[:, i]))]\n",
    "#     In_fromTop[new_in.columns[i]] = pd.Series(test1.columns[(test1 != 0).values[0]])\n",
    "#     In_fromBottom[new_in.columns[i]] = pd.Series(list(set(new_in.iloc[:, i]) - set(In_fromTop[new_in.columns[i]])))\n",
    "#     print(In_fromTop.iloc[:, i].count() + In_fromBottom.iloc[:, i].count())\n",
    "\n",
    "\n",
    "# # CSI1000\n",
    "# xx.append(csi_index_1000.columns[csi_index_1000.iloc[0, :] != 0])\n",
    "# for i in range(1, len(csi_index_1000)):\n",
    "#     xx.append(csi_index_1000.columns[csi_index_1000.iloc[i, :] != 0])\n",
    "#     new_in[csi_index_1000.iloc[i, 0]] = list(set(xx[i][1:]) - set(xx[i - 1][1:]))\n",
    "#     old_out[csi_index_1000.iloc[i, 0]] = list(set(xx[i - 1][1:]) - set(xx[i][1:]))\n",
    "# new_in[\"20200102\"].remove(\"SZ001914\")\n",
    "# old_out[\"20200102\"].remove(\"SZ000043\")\n",
    "# new_in = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in new_in.items()]))\n",
    "# old_out = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in old_out.items()]))\n",
    "# new_in = new_in.dropna(axis=1, thresh=5)\n",
    "# old_out = old_out.dropna(axis=1, thresh=5)\n",
    "# print(new_in)\n",
    "# print(old_out)\n",
    "#\n",
    "# hs300_list = csi_index_300.columns\n",
    "# zz500_list = csi_index.columns\n",
    "# for i in range(len(old_out.columns)):\n",
    "#     test1 = csi_index_300[csi_index_300[\"Date\"] == old_out.columns[i]][list(set(hs300_list) & set(old_out.iloc[:, i]))]\n",
    "#     test2 = csi_index[csi_index[\"Date\"] == old_out.columns[i]][list(set(zz500_list) & set(old_out.iloc[:, i]))]\n",
    "#     Out_toTop[old_out.columns[i]] = list(set(test1.columns[(test1 != 0).values[0]]) | set(test2.columns[(test2 != 0).values[0]]))\n",
    "#     Out_toBottom[old_out.columns[i]] = list(set(old_out.iloc[:, i]) - set(Out_toTop[old_out.columns[i]]))\n",
    "# for i in range(len(new_in.columns)):\n",
    "#     t = da_te[da_te[da_te == new_in.columns[i]].index[0] - 1]\n",
    "#     test1 = csi_index_300[csi_index_300[\"Date\"] == t][list(set(hs300_list) & set(new_in.iloc[:, i]))]\n",
    "#     test2 = csi_index[csi_index[\"Date\"] == t][list(set(zz500_list) & set(new_in.iloc[:, i]))]\n",
    "#     In_fromTop[new_in.columns[i]] = list(set(test1.columns[(test1 != 0).values[0]]) | set(test2.columns[(test2 != 0).values[0]]))\n",
    "#     In_fromBottom[new_in.columns[i]] = list(set(new_in.iloc[:, i]) - set(In_fromTop[new_in.columns[i]]))\n",
    "#\n",
    "# Out_toTop = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in Out_toTop.items()]))\n",
    "# Out_toBottom = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in Out_toBottom.items()]))\n",
    "# In_fromTop = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in In_fromTop.items()]))\n",
    "# In_fromBottom = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in In_fromBottom.items()]))\n",
    "\n",
    "# # CSIRest\n",
    "# csi_rest = csi_rest[csi_rest[\"Date\"] >= '20141103']\n",
    "# csi_index_300 = csi_index_300[csi_index_300[\"Date\"] >= '20141103']\n",
    "# csi_index1 = csi_index[csi_index[\"Date\"] >= '20141103']\n",
    "# csi_rest1 = {}\n",
    "# csi_rest1[\"Date\"] = []\n",
    "# csi_rest1[\"Stocks\"] = []\n",
    "# for i in range(len(csi_rest)):\n",
    "#     x1 = csi_rest.columns[csi_rest.iloc[i, :] != 0][1:]\n",
    "#     x2 = csi_index_300.columns[csi_index_300.iloc[i, :] != 0][1:]\n",
    "#     x3 = csi_index1.columns[csi_index1.iloc[i, :] != 0][1:]\n",
    "#     x4 = csi_index_1000.columns[csi_index_1000.iloc[i, :] != 0][1:]\n",
    "#     rx = list(((set(x1) - set(x2)) - set(x3)) - set(x4))\n",
    "#     csi_rest1[\"Date\"].append(csi_rest.iloc[i, 0])\n",
    "#     csi_rest1[\"Stocks\"].append(rx)\n",
    "# csi_rest1 = pd.DataFrame(csi_rest1)\n",
    "#\n",
    "# xx.append(csi_rest1.iloc[0, 1])\n",
    "# for i in range(1, len(csi_rest)):\n",
    "#     xx.append(csi_rest1.iloc[i, 1])\n",
    "#     new_in[csi_rest1.iloc[i, 0]] = list(set(xx[i]) - set(xx[i - 1]))\n",
    "#     old_out[csi_rest1.iloc[i, 0]] = list(set(xx[i - 1]) - set(xx[i]))\n",
    "# if \"SZ001914\" in new_in[\"20200102\"]:\n",
    "#     new_in[\"20200102\"].remove(\"SZ001914\")\n",
    "#     old_out[\"20200102\"].remove(\"SZ000043\")\n",
    "# if \"SZ001872\" in new_in[\"20200102\"]:\n",
    "#     new_in[\"20200102\"].remove(\"SZ001872\")\n",
    "#     old_out[\"20200102\"].remove(\"SZ000022\")\n",
    "# new_in = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in new_in.items()]))\n",
    "# old_out = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in old_out.items()]))\n",
    "# new_in = new_in.dropna(axis=1, thresh=30)\n",
    "# old_out = old_out.dropna(axis=1, thresh=30)\n",
    "# print(new_in)\n",
    "# print(old_out)\n",
    "#\n",
    "# hs300_list = csi_index_300.columns\n",
    "# zz500_list = csi_index.columns\n",
    "# zz1000_list = csi_index_1000.columns\n",
    "# for i in range(len(old_out.columns)):\n",
    "#     test1 = csi_index_300[csi_index_300[\"Date\"] == old_out.columns[i]][list(set(hs300_list) & set(old_out.iloc[:, i]))]\n",
    "#     test2 = csi_index1[csi_index1[\"Date\"] == old_out.columns[i]][list(set(zz500_list) & set(old_out.iloc[:, i]))]\n",
    "#     test3 = csi_index_1000[csi_index_1000[\"Date\"] == old_out.columns[i]][list(set(zz1000_list) & set(old_out.iloc[:, i]))]\n",
    "#     Out_toTop[old_out.columns[i]] = list((set(test1.columns[(test1 != 0).values[0]]) | set(test2.columns[(test2 != 0).values[0]])) | set(test3.columns[(test3 != 0).values[0]]))\n",
    "#     Out_toBottom[old_out.columns[i]] = list(set(old_out.iloc[:, i]) - set(Out_toTop[old_out.columns[i]]))\n",
    "# for i in range(len(new_in.columns)):\n",
    "#     t = da_te[da_te[da_te == new_in.columns[i]].index[0] - 1]\n",
    "#     test1 = csi_index_300[csi_index_300[\"Date\"] == t][list(set(hs300_list) & set(new_in.iloc[:, i]))]\n",
    "#     test2 = csi_index1[csi_index1[\"Date\"] == t][list(set(zz500_list) & set(new_in.iloc[:, i]))]\n",
    "#     test3 = csi_index_1000[csi_index_1000[\"Date\"] == t][list(set(zz1000_list) & set(new_in.iloc[:, i]))]\n",
    "#     In_fromTop[new_in.columns[i]] = list((set(test1.columns[(test1 != 0).values[0]]) | set(test2.columns[(test2 != 0).values[0]])) | set(test3.columns[(test3 != 0).values[0]]))\n",
    "#     In_fromBottom[new_in.columns[i]] = list(set(new_in.iloc[:, i]) - set(In_fromTop[new_in.columns[i]]))\n",
    "#\n",
    "# Out_toTop = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in Out_toTop.items()]))\n",
    "# Out_toBottom = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in Out_toBottom.items()]))\n",
    "# In_fromTop = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in In_fromTop.items()]))\n",
    "# In_fromBottom = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in In_fromBottom.items()]))\n",
    "\n",
    "# 2. Get the exact effect day and notice day from 2010 to 2019\n",
    "da_te = pd.to_datetime(csi_index[\"Date\"])\n",
    "def find_date1(year, month):\n",
    "    date1 = da_te[da_te[(da_te.dt.year == year) & (da_te.dt.month == month)].index[-1] + 1]\n",
    "    date2 = date1 - timedelta(days=14)\n",
    "    return [date1, date2]\n",
    "\n",
    "def find_date(year, month):\n",
    "    c = calendar.Calendar(firstweekday=calendar.SUNDAY)\n",
    "    monthcal = c.monthdatescalendar(year, month)\n",
    "    second_friday = [day for week in monthcal for day in week if \\\n",
    "                     day.weekday() == calendar.FRIDAY and \\\n",
    "                     day.month == month][1]\n",
    "    if (da_te == second_friday).any():\n",
    "        date1 = da_te[da_te[da_te == second_friday].index[0] + 1]\n",
    "        date2 = date1 - timedelta(days=14)\n",
    "        if(da_te == date2).any():\n",
    "            date2 = date2\n",
    "        elif (da_te == date2 + timedelta(days=1)).any():\n",
    "            date2 = da_te[da_te == date2 + timedelta(days=1)].values[0]\n",
    "        elif(da_te == date2 + timedelta(days=2)).any():\n",
    "            date2 = da_te[da_te == date2 + timedelta(days=2)].values[0]\n",
    "    elif (da_te == second_friday - timedelta(days=2)).any():\n",
    "        date1 = da_te[da_te[da_te == second_friday - timedelta(days=2)].index[0] + 1]\n",
    "        date2 = date1 - timedelta(days=14)\n",
    "        if (da_te == date2).any():\n",
    "            date2 = date2\n",
    "        elif (da_te == date2 + timedelta(days=1)).any():\n",
    "            date2 = da_te[da_te == date2 + timedelta(days=1)].values[0]\n",
    "        elif (da_te == date2 + timedelta(days=2)).any():\n",
    "            date2 = da_te[da_te == date2 + timedelta(days=2)].values[0]\n",
    "    # For the last day 2019.12, it has not come yet\n",
    "    else:\n",
    "        date1 = []\n",
    "        date2 = []\n",
    "    return [date1, date2]\n",
    "\n",
    "for year in range(2010, 2014):\n",
    "    for month in [6, 12]:\n",
    "        dd1.append(find_date1(year, month)[0])\n",
    "        dd2.append(find_date1(year, month)[1])\n",
    "dd1 = dd1[:-1]\n",
    "dd2 = dd2[:-1]\n",
    "for year in range(2013, 2020):\n",
    "    for month in [6, 12]:\n",
    "        dd1.append(find_date(year, month)[0])\n",
    "        dd2.append(find_date(year, month)[1])\n",
    "del dd1[7]\n",
    "del dd2[7]\n",
    "time_df = pd.DataFrame({\"Effect Day\": dd1, \"Notice Day\": dd2})\n",
    "print(time_df)\n",
    "\n",
    "# 3. calculate cumulative mean abnormal returns and plot it from pre_event_10days to post_event_20days\n",
    "# Effect day + new_in\n",
    "def align_yaxis_np(ax1, ax2):\n",
    "    \"\"\"Align zeros of the two axes, zooming them out by same ratio\"\"\"\n",
    "    axes = np.array([ax1, ax2])\n",
    "    extrema = np.array([ax.get_ylim() for ax in axes])\n",
    "    tops = extrema[:, 1] / (extrema[:, 1] - extrema[:, 0])\n",
    "    # Ensure that plots (intervals) are ordered bottom to top:\n",
    "    if tops[0] > tops[1]:\n",
    "        axes, extrema, tops = [a[::-1] for a in (axes, extrema, tops)]\n",
    "\n",
    "    # How much would the plot overflow if we kept current zoom levels?\n",
    "    tot_span = tops[1] + 1 - tops[0]\n",
    "\n",
    "    extrema[0, 1] = extrema[0, 0] + tot_span * (extrema[0, 1] - extrema[0, 0])\n",
    "    extrema[1, 0] = extrema[1, 1] + tot_span * (extrema[1, 0] - extrema[1, 1])\n",
    "    [axes[i].set_ylim(*extrema[i]) for i in range(2)]\n",
    "\n",
    "#time_df = time_df[(da_te[da_te.isin(time_df[\"Effect Day\"]).values].index - da_te[da_te.isin(time_df[\"Notice Day\"]).values].index) == 10]\n",
    "\n",
    "\n",
    "def cal1(dataframe):\n",
    "    df = pd.DataFrame()\n",
    "    m = 0\n",
    "    CAR = []\n",
    "    T = []\n",
    "    M = []\n",
    "\n",
    "    event_date = time_df[\"Notice Day\"].iloc[-2]\n",
    "    time_period = da_te[da_te[da_te == event_date].index[0] - 10:da_te[da_te == event_date].index[0] + 21]\n",
    "    stocks = dataframe.iloc[:, -2][~dataframe.iloc[:, -2].isnull()]\n",
    "    for j in stocks:\n",
    "        data1 = alpha[alpha[\"Symbol\"] == j]\n",
    "        tp = pd.DataFrame(time_period)\n",
    "        tp = pd.DataFrame(pd.merge(tp, data1, left_on=\"Date\", right_on=\"Date\", how=\"left\")[\"alpha\"])\n",
    "        tp = tp.rename(columns={'alpha': m})\n",
    "        df = pd.concat([df, tp], axis=1)\n",
    "        m = m + 1\n",
    "    print(df)\n",
    "    # for i in range(df.shape[0]):\n",
    "    #     T.append(np.nanmean(df.iloc[i, :]) * np.sqrt(df.shape[1]) / np.nanstd(df.iloc[i, :]))\n",
    "    CAR = np.cumsum(df.mean(axis=1)) * 10000\n",
    "    T = df.mean(axis=1) * 10000\n",
    "    M = df.median(axis=1) * 10000\n",
    "    # d = mf[(mf[\"date\"] >= 20180528) & (mf[\"date\"] <= 20180611) & (mf[\"StockID\"].isin(stocks))]\n",
    "    # nd = d.groupby(\"date\")[\"buy_lg_vol\", \"buy_elg_vol\", \"sell_lg_vol\", \"sell_elg_vol\"].sum()\n",
    "    # nd[\"sum_buy\"] = nd[\"buy_lg_vol\"] + nd[\"buy_elg_vol\"]\n",
    "    # nd[\"sum_sell\"] = nd[\"sell_lg_vol\"] + nd[\"sell_elg_vol\"]\n",
    "    # nd_time = pd.Series(nd.index.values).apply(lambda x: str(x))\n",
    "    # nd_time = pd.to_datetime(nd_time)\n",
    "    # nd = nd.set_index(nd_time)\n",
    "    #fig, ax1 = plt.subplots()\n",
    "    #plt.plot(nd[\"sum_buy\"], 'b-', label=\"total buy volume\")\n",
    "    #plt.plot(nd[\"sum_sell\"], 'r-', label=\"total sell volume\")\n",
    "    #plt.xticks(rotation=90)\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    print(df.mean(axis=1)[:10].sum()*10000)\n",
    "    print(df.mean(axis=1)[11:20].sum()*10000)\n",
    "    print(df.mean(axis=1)[21:].sum()*10000)\n",
    "\n",
    "    print(df.mean(axis=1)[:5].sum() * 10000)\n",
    "    print(df.mean(axis=1)[5:10].sum() * 10000)\n",
    "    print(df.mean(axis=1)[11:15].sum() * 10000)\n",
    "    print(df.mean(axis=1)[15:20].sum() * 10000)\n",
    "    print(df.mean(axis=1)[21:26].sum() * 10000)\n",
    "    print(df.mean(axis=1)[26:].sum() * 10000)\n",
    "\n",
    "\n",
    "\n",
    "    return pd.DataFrame({\"CAR\": CAR, \"T value\": T, \"stock number\": np.repeat(stocks.size, CAR.size), \"Median_alpha\": M})\n",
    "\n",
    "\n",
    "\n",
    "def cal2(day, dataframe):\n",
    "    df = pd.DataFrame()\n",
    "    m = 0\n",
    "    CAR = []\n",
    "    T = []\n",
    "    for i in range(18):\n",
    "        event_date = time_df[day].iloc[i]\n",
    "        print(event_date)\n",
    "        time_period = da_te[da_te[da_te == event_date].index[0] - 10:da_te[da_te == event_date].index[0] + 21]\n",
    "        stocks = dataframe.iloc[:, i+1][~dataframe.iloc[:, i+1].isnull()]\n",
    "        for j in stocks:\n",
    "            data1 = alpha[alpha[\"Symbol\"] == j]\n",
    "            tp = pd.DataFrame(time_period)\n",
    "            tp = pd.DataFrame(pd.merge(tp, data1, left_on=\"Date\", right_on=\"Date\", how=\"left\")[\"alpha\"])\n",
    "            tp = tp.rename(columns={'alpha': m})\n",
    "            df = pd.concat([df, tp], axis=1)\n",
    "            m = m + 1\n",
    "    print(df)\n",
    "    print(df.shape[1])\n",
    "    T = df.mean(axis=1) * 10000\n",
    "    CAR = np.cumsum(df.mean(axis=1)) * 10000\n",
    "\n",
    "    print(df.mean(axis=1)[:10].sum()*10000)\n",
    "    #print(df.mean(axis=1)[:10].mean() * 10000)\n",
    "    #print((df.mean(axis=1)[9] - df.mean(axis=1)[0]) * 10000)\n",
    "    #print(df.mean(axis=1)[10]*10000)\n",
    "    print(df.mean(axis=1)[11:19].sum()*10000)\n",
    "    #print(df.mean(axis=1)[11:19].mean() * 10000)\n",
    "    #print((df.mean(axis=1)[18] - df.mean(axis=1)[11]) * 10000)\n",
    "    #print((df.mean(axis=1)[19]) * 10000)\n",
    "    print(df.mean(axis=1)[20:].sum() * 10000)\n",
    "    #print(df.mean(axis=1)[20:].mean() * 10000)\n",
    "    #print((df.mean(axis=1)[30] - df.mean(axis=1)[20]) * 10000)\n",
    "\n",
    "    # print(df.mean(axis=1)[0] * 10000)\n",
    "    # #print(df.mean(axis=1)[1] * 10000)\n",
    "    # print(df.mean(axis=1)[2:10].sum() * 10000)\n",
    "    # #print(df.mean(axis=1)[2:10].mean() * 10000)\n",
    "    # #print((df.mean(axis=1)[9] - df.mean(axis=1)[2]) * 10000)\n",
    "    # #print((df.mean(axis=1)[10]) * 10000)\n",
    "    # print(df.mean(axis=1)[11:].sum() * 10000)\n",
    "    # #print(df.mean(axis=1)[11:].mean() * 10000)\n",
    "    # #print((df.mean(axis=1)[30] - df.mean(axis=1)[11]) * 10000)\n",
    "\n",
    "    print(df.mean(axis=1)[:5].sum() * 10000)\n",
    "    print(df.mean(axis=1)[5:10].sum() * 10000)\n",
    "    # print(df.mean(axis=1)[:10].mean() * 10000)\n",
    "    # print((df.mean(axis=1)[9] - df.mean(axis=1)[0]) * 10000)\n",
    "    # print(df.mean(axis=1)[10]*10000)\n",
    "    print(df.mean(axis=1)[11:15].sum() * 10000)\n",
    "    print(df.mean(axis=1)[15:19].sum() * 10000)\n",
    "    # print(df.mean(axis=1)[11:19].mean() * 10000)\n",
    "    # print((df.mean(axis=1)[18] - df.mean(axis=1)[11]) * 10000)\n",
    "    # print((df.mean(axis=1)[19]) * 10000)\n",
    "    print(df.mean(axis=1)[20:25].sum() * 10000)\n",
    "    print(df.mean(axis=1)[25:].sum() * 10000)\n",
    "    # print(df.mean(axis=1)[20:].mean() * 10000)\n",
    "    # print((df.mean(axis=1)[30] - df.mean(axis=1)[20]) * 10000)\n",
    "\n",
    "\n",
    "\n",
    "    return pd.DataFrame({\"CAR\": CAR, \"T value\": T, \"stock number\": np.repeat(stocks.size, CAR.size)})\n",
    "\n",
    "\n",
    "x = range(-10, 21)\n",
    "sns.set()\n",
    "fig, ax1 = plt.subplots(2, 2, figsize=(8, 8))\n",
    "# fig, ax1 = plt.subplots(1, 2, figsize=(8, 8))\n",
    "\n",
    "# r1 = cal1(In_fromBottom)\n",
    "r1 = cal2(\"Notice Day\", new_in)\n",
    "# r1 = cal1(new_in)\n",
    "len = r1.loc[0, \"stock number\"]\n",
    "ax1[0, 0].axvspan(-10, 0, facecolor='lightgreen', alpha=0.5)\n",
    "ax1[0, 0].axvspan(0, 10, facecolor='green', alpha=0.5)\n",
    "ax1[0, 0].axvspan(10, 20, facecolor='darkgreen', alpha=0.5)\n",
    "ax1[0, 0].set_ylabel('Cumulative Alpha', fontname=\"Arial\", fontsize=8)\n",
    "ax1[0, 0].plot(x, r1[\"CAR\"], marker='.', color='blue', alpha=1, linewidth=1, markersize=2)\n",
    "ax1[0, 0].tick_params('y')\n",
    "ax1[0, 0].tick_params(labelsize=8)\n",
    "ax1[0, 0].axhline(y=0, color='salmon', linestyle=(0, (1, 1)), alpha=0.6, linewidth=1)\n",
    "ax2 = ax1[0, 0].twinx()\n",
    "ax2.set_ylabel('Mean Alpha', fontname=\"Arial\", fontsize=8)\n",
    "ax2.bar(x, r1[\"T value\"], color='salmon', alpha=0.8)\n",
    "# ax2.scatter(x, r1[\"Median_alpha\"], color='red', alpha=0.8, s=4)\n",
    "# if len < 30:\n",
    "#     ax2.axhline(y=stats.t.ppf(1 - 0.025, len - 1), color='green', linestyle=(0, (1, 1)), alpha=0.6, linewidth=1)\n",
    "#     ax2.axhline(y=-stats.t.ppf(1 - 0.025, len - 1), color='green', linestyle=(0, (1, 1)), alpha=0.6,\n",
    "#                 linewidth=1)\n",
    "# else:\n",
    "#     ax2.axhline(y=1.96, color='green', linestyle=(0, (1, 1)), alpha=0.6, linewidth=1)\n",
    "#     ax2.axhline(y=-1.96, color='green', linestyle=(0, (1, 1)), alpha=0.6,\n",
    "#                 linewidth=1)\n",
    "ax2.tick_params('y')\n",
    "ax2.tick_params(labelsize=8)\n",
    "# plt.title(\"In_fromBottom_201906_\" + str(len) + \"stocks\", fontname=\"Arial\", fontsize=10)\n",
    "plt.title(\"Cumulative Average alpha for stocks In_fromBottom before/after notice day\", fontname=\"Arial\", fontsize=10)\n",
    "# plt.title(\"New_in_201906_\" + str(len) + \"stocks\", fontname=\"Arial\", fontsize=10)\n",
    "ax1[0, 0].grid(True)\n",
    "ax2.grid(None)\n",
    "ax1[0, 0].set_ylim(-1000, 200)\n",
    "ax2.set_ylim(-200, 200)\n",
    "align_yaxis_np(ax1[0, 0], ax2)\n",
    "\n",
    "\n",
    "\n",
    "# r2 = cal1(In_fromTop)\n",
    "r2 = cal2(\"Notice Day\", old_out)\n",
    "# r2 = cal1(old_out)\n",
    "len = r2.loc[0, \"stock number\"]\n",
    "ax1[0, 1].axvspan(-10, 0, facecolor='lightgreen', alpha=0.5)\n",
    "ax1[0, 1].axvspan(0, 10, facecolor='green', alpha=0.5)\n",
    "ax1[0, 1].axvspan(10, 20, facecolor='darkgreen', alpha=0.5)\n",
    "ax1[0, 1].set_ylabel('Cumulative Alpha', fontname=\"Arial\", fontsize=8)\n",
    "ax1[0, 1].plot(x, r2[\"CAR\"], marker='.', color='blue', alpha=1, linewidth=1, markersize=2)\n",
    "ax1[0, 1].tick_params('y')\n",
    "ax1[0, 1].tick_params(labelsize=8)\n",
    "ax1[0, 1].axhline(y=0, color='salmon', linestyle=(0, (1, 1)), alpha=0.6, linewidth=1)\n",
    "ax2 = ax1[0, 1].twinx()\n",
    "ax2.set_ylabel('Mean Alpha', fontname=\"Arial\", fontsize=8)\n",
    "ax2.bar(x, r2[\"T value\"], color='salmon', alpha=0.8)\n",
    "# ax2.scatter(x, r2[\"Median_alpha\"], color='red', alpha=0.8, s=4)\n",
    "# if len < 30:\n",
    "#     ax2.axhline(y=stats.t.ppf(1 - 0.025, len - 1), color='green', linestyle=(0, (1, 1)), alpha=0.6, linewidth=1)\n",
    "#     ax2.axhline(y=-stats.t.ppf(1 - 0.025, len - 1), color='green', linestyle=(0, (1, 1)), alpha=0.6,\n",
    "#                 linewidth=1)\n",
    "# else:\n",
    "#     ax2.axhline(y=1.96, color='green', linestyle=(0, (1, 1)), alpha=0.6, linewidth=1)\n",
    "#     ax2.axhline(y=-1.96, color='green', linestyle=(0, (1, 1)), alpha=0.6,\n",
    "#                 linewidth=1)\n",
    "ax2.tick_params('y')\n",
    "ax2.tick_params(labelsize=8)\n",
    "# plt.title(\"In_fromTop_201906_\" + str(len) + \"stocks\", fontname=\"Arial\", fontsize=10)\n",
    "plt.title(\"Cumulative Average alpha for stocks In_fromTop before/after notice day\", fontname=\"Arial\", fontsize=10)\n",
    "# plt.title(\"Old_out_201906_\" + str(len) + \"stocks\", fontname=\"Arial\", fontsize=10)\n",
    "ax1[0, 1].grid(True)\n",
    "ax2.grid(None)\n",
    "ax1[0, 1].set_ylim(-1000, 200)\n",
    "ax2.set_ylim(-200, 200)\n",
    "align_yaxis_np(ax1[0, 1], ax2)\n",
    "\n",
    "\n",
    "# r3 = cal1(Out_toTop)\n",
    "# # r3 = cal2(\"Notice Day\", Out_toTop)\n",
    "# len = r3.loc[0, \"stock number\"]\n",
    "# ax1[1, 0].axvspan(-10, 0, facecolor='lightgreen', alpha=0.5)\n",
    "# ax1[1, 0].axvspan(0, 9, facecolor='green', alpha=0.5)\n",
    "# ax1[1, 0].axvspan(9, 20, facecolor='darkgreen', alpha=0.5)\n",
    "# ax1[1, 0].set_ylabel('Cumulative Alpha', fontname=\"Arial\", fontsize=8)\n",
    "# ax1[1, 0].plot(x, r3[\"CAR\"], marker='.', color='blue', alpha=1, linewidth=1, markersize=2)\n",
    "# ax1[1, 0].tick_params('y')\n",
    "# ax1[1, 0].tick_params(labelsize=8)\n",
    "# ax1[1, 0].axhline(y=0, color='salmon', linestyle=(0, (1, 1)), alpha=0.6, linewidth=1)\n",
    "# ax2 = ax1[1, 0].twinx()\n",
    "# ax2.set_ylabel('Mean Alpha', fontname=\"Arial\", fontsize=8)\n",
    "# ax2.bar(x, r3[\"T value\"], color='salmon', alpha=0.8)\n",
    "# # ax2.scatter(x, r3[\"Median_alpha\"], color='red', alpha=0.8, s=4)\n",
    "# # if len < 30:\n",
    "# #     ax2.axhline(y=stats.t.ppf(1 - 0.025, len - 1), color='green', linestyle=(0, (1, 1)), alpha=0.6, linewidth=1)\n",
    "# #     ax2.axhline(y=-stats.t.ppf(1 - 0.025, len - 1), color='green', linestyle=(0, (1, 1)), alpha=0.6,\n",
    "# #                 linewidth=1)\n",
    "# # else:\n",
    "# #     ax2.axhline(y=1.96, color='green', linestyle=(0, (1, 1)), alpha=0.6, linewidth=1)\n",
    "# #     ax2.axhline(y=-1.96, color='green', linestyle=(0, (1, 1)), alpha=0.6,\n",
    "# #                 linewidth=1)\n",
    "# ax2.tick_params('y')\n",
    "# ax2.tick_params(labelsize=8)\n",
    "# # plt.title(\"Out_toTop_201906_\" + str(len) + \"stocks\", fontname=\"Arial\", fontsize=10)\n",
    "# plt.title(\"Cumulative Average alpha for stocks Out_toTop before/after notice day\", fontname=\"Arial\", fontsize=10)\n",
    "# ax1[1, 0].grid(True)\n",
    "# ax2.grid(None)\n",
    "# ax1[1, 0].set_ylim(-1000, 200)\n",
    "# ax2.set_ylim(-200, 200)\n",
    "# align_yaxis_np(ax1[1, 0], ax2)\n",
    "#\n",
    "#\n",
    "# r4 = cal1(Out_toBottom)\n",
    "# # r4 = cal2(\"Notice Day\", Out_toBottom)\n",
    "# len = r4.loc[0, \"stock number\"]\n",
    "# ax1[1, 1].axvspan(-10, 0, facecolor='lightgreen', alpha=0.5)\n",
    "# ax1[1, 1].axvspan(0, 9, facecolor='green', alpha=0.5)\n",
    "# ax1[1, 1].axvspan(9, 20, facecolor='darkgreen', alpha=0.5)\n",
    "# ax1[1, 1].set_ylabel('Cumulative Alpha', fontname=\"Arial\", fontsize=8)\n",
    "# ax1[1, 1].plot(x, r4[\"CAR\"], marker='.', color='blue', alpha=1, linewidth=1, markersize=2)\n",
    "# ax1[1, 1].tick_params('y')\n",
    "# ax1[1, 1].tick_params(labelsize=8)\n",
    "# ax1[1, 1].axhline(y=0, color='salmon', linestyle=(0, (1, 1)), alpha=0.6, linewidth=1)\n",
    "# ax2 = ax1[1, 1].twinx()\n",
    "# ax2.set_ylabel('Mean Alpha', fontname=\"Arial\", fontsize=8)\n",
    "# ax2.bar(x, r4[\"T value\"], color='salmon', alpha=0.8)\n",
    "# # ax2.scatter(x, r4[\"Median_alpha\"], color='red', alpha=0.8, s=4)\n",
    "# # if len < 30:\n",
    "# #     ax2.axhline(y=stats.t.ppf(1 - 0.025, len - 1), color='green', linestyle=(0, (1, 1)), alpha=0.6, linewidth=1)\n",
    "# #     ax2.axhline(y=-stats.t.ppf(1 - 0.025, len - 1), color='green', linestyle=(0, (1, 1)), alpha=0.6,\n",
    "# #                 linewidth=1)\n",
    "# # else:\n",
    "# #     ax2.axhline(y=1.96, color='green', linestyle=(0, (1, 1)), alpha=0.6, linewidth=1)\n",
    "# #     ax2.axhline(y=-1.96, color='green', linestyle=(0, (1, 1)), alpha=0.6,\n",
    "# #                 linewidth=1)\n",
    "# ax2.tick_params('y')\n",
    "# ax2.tick_params(labelsize=8)\n",
    "# # plt.title(\"Out_toBottom_201906_\" + str(len) + \"stocks\", fontname=\"Arial\", fontsize=10)\n",
    "# plt.title(\"Cumulative Average alpha for stocks Out_toBottom before/after notice day\", fontname=\"Arial\", fontsize=10)\n",
    "# ax1[1, 1].grid(True)\n",
    "# ax2.grid(None)\n",
    "# ax1[1, 1].set_ylim(-1000, 200)\n",
    "# ax2.set_ylim(-200, 200)\n",
    "# align_yaxis_np(ax1[1, 1], ax2)\n",
    "#\n",
    "# fig.tight_layout()\n",
    "#\n",
    "# plt.show()\n",
    "#\n",
    "# # time_period = da_te[da_te[da_te == time_df[\"Notice Day\"].iloc[-1]].index[0] - 10:\n",
    "# #                     da_te[da_te == time_df[\"Notice Day\"].iloc[-1]].index[0] + 21]\n",
    "# # IC[\"ret\"] = IC[\"close\"]/IC[\"close\"].shift(1)-1\n",
    "# # CSI[\"ret\"] = CSI[\"close\"]/CSI[\"close\"].shift(1)-1\n",
    "# # IC[\"Date\"] = IC[\"Date\"].apply(lambda x: str(x))\n",
    "# # IC[\"Date\"] = pd.to_datetime(IC[\"Date\"])\n",
    "# # CSI[\"Date\"] = CSI[\"Date\"].apply(lambda x: str(x))\n",
    "# # CSI[\"Date\"] = pd.to_datetime(CSI[\"Date\"])\n",
    "# # diff = (CSI.loc[CSI[\"Date\"].isin(time_period), \"ret\"].values - IC.loc[IC[\"Date\"].isin(time_period), \"ret\"].values)*10000\n",
    "# # x = range(-10, 21)\n",
    "# # sns.set()\n",
    "# # fig, ax = plt.subplots()\n",
    "# # ax.axvspan(-10, 0, facecolor='lightgreen', alpha=0.5)\n",
    "# # ax.axvspan(0, 10, facecolor='green', alpha=0.5)\n",
    "# # ax.axvspan(10, 20, facecolor='darkgreen', alpha=0.5)\n",
    "# # ax.set_ylabel('spreads', fontname=\"Arial\", fontsize=8)\n",
    "# # ax.bar(x, diff, color='salmon', alpha=0.8, label=\"spreads\")\n",
    "# # ax.plot(x, diff.cumsum(), marker='.', color='blue', alpha=1, linewidth=1, markersize=2, label=\"cumulative spreads\")\n",
    "# # ax.legend(loc='upper right')\n",
    "# # ax.set_title(\"Spreads between CSI and IC on 201912\")\n",
    "# # ax.grid(True)\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "In1 = pd.read_csv(\"E:\\\\预测中证调入.csv\", encoding='GBK')\n",
    "beta = pd.read_csv('E:\\\\new_beta_CSI.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     SZ002506\n",
       "1     SH600675\n",
       "2     SZ000898\n",
       "3     SZ002563\n",
       "4     SH600372\n",
       "5     SZ300070\n",
       "6     SZ000629\n",
       "7     SZ000046\n",
       "8     SZ000540\n",
       "9     SZ002081\n",
       "10    SH600535\n",
       "11    SH600153\n",
       "12    SH600733\n",
       "13    SZ002411\n",
       "14    SZ300017\n",
       "15    SZ300558\n",
       "16    SZ002010\n",
       "17    SZ000630\n",
       "18    SZ300024\n",
       "19    SZ000415\n",
       "20    SH603786\n",
       "21    SH600566\n",
       "22    SZ300357\n",
       "23    SZ002294\n",
       "24    SZ002901\n",
       "25    SZ000785\n",
       "26    SZ002185\n",
       "27    SZ300595\n",
       "28    SZ300271\n",
       "29    SH600157\n",
       "30    SZ002396\n",
       "31    SZ002080\n",
       "32    SZ300212\n",
       "33    SH600667\n",
       "34    SZ300482\n",
       "35    SH601512\n",
       "36    SZ300496\n",
       "37    SH603605\n",
       "38    SZ002138\n",
       "39    SZ002511\n",
       "40    SZ000800\n",
       "41    SZ002156\n",
       "42    SZ002557\n",
       "43    SZ300474\n",
       "44    SZ300618\n",
       "45    SH600529\n",
       "46    SZ002595\n",
       "47    SZ300630\n",
       "48    SZ001914\n",
       "49    SZ002458\n",
       "Name: Symbol, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "In1['Symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20200518, 20200519, 20200520, 20200521, 20200522, 20200525,\n",
       "       20200526, 20200527, 20200528, 20200529, 20200601, 20200602,\n",
       "       20200603, 20200604, 20200605, 20200608, 20200609, 20200610,\n",
       "       20200611, 20200612, 20200615], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sort(beta[beta['Date'] < 20200616]['Date'].unique())[-21:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-25.610518838597514"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta[(beta['Symbol'].isin(list(set(In1['Symbol']) - set(['SH600372']) | (set(['SH600100']))))) & (beta['Date'] >= 20200518) & (beta['Date'] <= 20200522)].groupby('Date')['alpha'].mean().sum() * 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-282.67456972050087"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta[(beta['Symbol'].isin(['SZ000890', 'SZ000509', 'SH600241', 'SZ002319', 'SZ000595',\n",
    "       'SZ000679', 'SH600892', 'SZ000673', 'SZ002502', 'SH600083',\n",
    "       'SZ000017', 'SZ002255', 'SH600821', 'SZ002513', 'SH600225',\n",
    "       'SH600311', 'SZ000837', 'SH600122', 'SZ002418', 'SH600416',\n",
    "       'SZ002575', 'SZ002700', 'SZ002077', 'SH600243', 'SZ002076',\n",
    "       'SH600212', 'SH600898', 'SH603389', 'SZ002496', 'SH600836'])) \n",
    "     & (beta['Date'] >= 20200623) & (beta['Date'] <= 20200701)].groupby('Date')['alpha'].mean().sum() * 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "20200608    88\n",
       "20200609    88\n",
       "20200610    88\n",
       "20200611    88\n",
       "20200612    88\n",
       "Name: Symbol, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta[(beta['Symbol'].isin(['SZ002967', 'SH600556', 'SH601900', 'SZ300799', 'SZ300604', 'SH603887', 'SH603053', 'SZ002214', 'SZ002869', 'SH603690', 'SZ300815', 'SZ300526', 'SH603060', 'SZ002459', 'SZ002479', 'SH600510', 'SZ300793', 'SH603005', 'SZ002962', 'SZ300397', 'SZ300319', 'SZ000912', 'SZ002961', 'SZ000408', 'SH601311', 'SZ000403', 'SH600965', 'SH603698', 'SH600682', 'SH603520', 'SH600882', 'SZ300080', 'SZ002970', 'SZ002324', 'SZ300657', 'SZ300552', 'SZ300792', 'SZ002838', 'SZ300573', 'SH603551', 'SH603258', 'SZ300709', 'SH603530', 'SZ002706', 'SZ300455', 'SH603093', 'SH603489', 'SZ300805', 'SZ300762', 'SZ300346', 'SZ300598', 'SZ300663', 'SH603992', 'SZ300798', 'SZ300590', 'SH600267', 'SZ300395', 'SZ300672', 'SZ002291', 'SZ000503', 'SZ002791', 'SZ300525', 'SH603601', 'SZ002973', 'SZ002017', 'SZ002960', 'SZ300803', 'SH600246', 'SZ002194', 'SZ300659', 'SZ300577', 'SZ300579', 'SZ300603', 'SZ002310', 'SZ000823', 'SH601965', 'SZ002959', 'SZ002106', 'SH603815', 'SH603610', 'SH603927', 'SZ300119', 'SZ300267', 'SH600395', 'SH600732', 'SZ002161', 'SH603730', 'SZ002969', 'SZ002015'])) & (beta['Date'] >= 20200608) & (beta['Date'] <= 20200612)].groupby('Date')['Symbol'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>s_returns</th>\n",
       "      <th>m_returns</th>\n",
       "      <th>beta</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1501560</td>\n",
       "      <td>1501560</td>\n",
       "      <td>20200608</td>\n",
       "      <td>SH600745</td>\n",
       "      <td>-0.016926</td>\n",
       "      <td>-0.001812</td>\n",
       "      <td>1.919757</td>\n",
       "      <td>-0.013448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1501561</td>\n",
       "      <td>1501561</td>\n",
       "      <td>20200609</td>\n",
       "      <td>SH600745</td>\n",
       "      <td>0.028914</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>1.889133</td>\n",
       "      <td>0.017029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1501562</td>\n",
       "      <td>1501562</td>\n",
       "      <td>20200611</td>\n",
       "      <td>SH600745</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>-0.004655</td>\n",
       "      <td>1.887741</td>\n",
       "      <td>0.018973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1501563</td>\n",
       "      <td>1501563</td>\n",
       "      <td>20200612</td>\n",
       "      <td>SH600745</td>\n",
       "      <td>-0.036730</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>1.881712</td>\n",
       "      <td>-0.037533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      Date    Symbol  s_returns  m_returns      beta  \\\n",
       "1501560     1501560  20200608  SH600745  -0.016926  -0.001812  1.919757   \n",
       "1501561     1501561  20200609  SH600745   0.028914   0.006291  1.889133   \n",
       "1501562     1501562  20200611  SH600745   0.010186  -0.004655  1.887741   \n",
       "1501563     1501563  20200612  SH600745  -0.036730   0.000427  1.881712   \n",
       "\n",
       "            alpha  \n",
       "1501560 -0.013448  \n",
       "1501561  0.017029  \n",
       "1501562  0.018973  \n",
       "1501563 -0.037533  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta[(beta['Date'] >= 20200608) & (beta['Date'] <= 20200612) & (beta['Symbol'] == 'SH600745')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
