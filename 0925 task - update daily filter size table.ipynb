{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_config = {\n",
    "    'user': 'user_rw',\n",
    "    'password': 'faa96dfc',\n",
    "    'host': '192.168.10.178',\n",
    "    'port': '27017',\n",
    "    'db': 'com_md_eq_cn'\n",
    "    }\n",
    "\n",
    "\n",
    "def sta_sizeFilter(stockID, db_config, startDate, endDate, regWindowSize = 20, weekInterval = 1): \n",
    "    db = DB(db_config['host'], db_config['db'], db_config['user'], db_config['password'])\n",
    "    print(' ...... Now Calculating SizeFilter for  ', stockID)\n",
    "#    startTm = datetime.datetime.now()\n",
    "    stockData = db.read_tick('md_snapshot_l2', start_date=startDate, end_date=endDate, symbol=[stockID])\n",
    "    stockData = stockData.loc[((stockData.bid1p != 0) | (stockData.ask1p != 0)), \\\n",
    "                              ['skey','date','time','clockAtArrival','datetime','ordering',\n",
    "                               'cum_amount','bid1p','bid1q','bid5q','ask5q']].reset_index(drop=True)\n",
    "    stockData = stockData[((stockData.time >= 93000000000) & (stockData.time <= 113000000000)) | \\\n",
    "                          ((stockData.time >= 130000000000) & (stockData.time <= 150000000000))].reset_index(drop=True)\n",
    "    indexDaily = db.read_daily('index_memb', start_date=startDate, end_date=endDate, index_name='IF')\n",
    "    indexDaily['tradeConsDay'] = indexDaily.groupby(['date']).grouper.group_info[0]\n",
    "    indexDaily = indexDaily.groupby('date')['tradeConsDay'].first().reset_index()\n",
    "    df_train = stockData.merge(indexDaily[['date','tradeConsDay']], how='left', on=['date'], validate='many_to_one')\n",
    "    \n",
    "    df_train = df_train[(df_train['time'] >= 93000000000) & (df_train['time'] < 145655000000)].reset_index(drop=True)\n",
    "    groupAllData = df_train.groupby(['skey','date'])\n",
    "    df_train['amountThisUpdate'] = df_train.cum_amount - groupAllData['cum_amount'].shift(1)\n",
    "    df_train['amountThisUpdate'] = np.where(pd.isnull(df_train.amountThisUpdate), df_train.cum_amount, df_train.amountThisUpdate)\n",
    "\n",
    "    ### add useful day indicator\n",
    "    df_train['curNearLimit'] = np.where((df_train.ask5q == 0) | (df_train.bid5q == 0), 1.0, 0.0)\n",
    "    df_train['curNearLimit_L1'] = groupAllData['curNearLimit'].shift(1)\n",
    "    df_train['dailyCount'] = groupAllData['time'].transform('count')\n",
    "    df_train['nearLimitCount'] = groupAllData['curNearLimit'].transform('sum')\n",
    "    dateInfo = groupAllData['dailyCount', 'nearLimitCount', 'tradeConsDay'].mean().reset_index()\n",
    "    del groupAllData\n",
    "    dateInfo['useFlag'] = np.where(dateInfo['nearLimitCount']*2 < dateInfo['dailyCount'], 1, 0)\n",
    "    dateInfo['useConsDay'] = dateInfo['useFlag'].cumsum()\n",
    "    df_train = pd.merge(df_train, dateInfo[['date', 'tradeConsDay', 'useFlag', 'useConsDay']],\n",
    "                        how='left', on=['date', 'tradeConsDay'], validate='many_to_one') \n",
    "    \n",
    "    df_train['weekday'] = df_train['datetime'].dt.weekday\n",
    "    sizeFilterData = df_train.groupby(['date'])['tradeConsDay'].first().reset_index()\n",
    "    sizeFilterData['amountFilter'] = np.nan\n",
    "    ## we only update on Thrusday\n",
    "    regDays = sorted(list(df_train.loc[df_train.weekday == 3, 'tradeConsDay'].unique()))      \n",
    "\n",
    "    weekInterval = 1      \n",
    "    for d in range(int(regWindowSize/5), len(regDays), weekInterval):\n",
    "        amountFilter = np.nan\n",
    "        ## get current Thrusday\n",
    "        endTradeConsDay = regDays[d]\n",
    "        endUseConsDay = dateInfo[dateInfo['tradeConsDay'] == endTradeConsDay]['useConsDay'].values[0]\n",
    "        startUseConsDay = max(endUseConsDay - regWindowSize + 1, 1)\n",
    "        \n",
    "        ## check 60 consecutive days\n",
    "        if dateInfo['useConsDay'].max() < 1: \n",
    "            amountFilter = np.nan\n",
    "            continue\n",
    "        startTradeConsDay = dateInfo[dateInfo['useConsDay'] == startUseConsDay]['tradeConsDay'].values[0]\n",
    "        endTradeConsDay = dateInfo[dateInfo['tradeConsDay'] == endTradeConsDay]['tradeConsDay'].values[0]\n",
    "        if (endTradeConsDay - startTradeConsDay > 59) or (endUseConsDay - startUseConsDay < 9):\n",
    "            amountFilter = np.nan\n",
    "            continue      \n",
    "        ## get the Monday right after current Thursday update\n",
    "        oss_intdate = df_train.loc[df_train.tradeConsDay == endTradeConsDay, 'date'].unique()[0]\n",
    "        oss_intdate = (datetime.datetime.strptime(str(oss_intdate), '%Y%m%d') - datetime.datetime(1899,12,30)).days + 4\n",
    "        oss = datetime.datetime(1899,12,30) + datetime.timedelta(int(oss_intdate)) \n",
    "        ## get the Friday right after next Thursday update\n",
    "        if d >= len(regDays) - weekInterval:\n",
    "            ose = df_train.date.max()\n",
    "        else:\n",
    "            ose_intdate = df_train.loc[df_train.tradeConsDay == regDays[d+weekInterval], 'date'].unique()[0]\n",
    "            ose_intdate = (datetime.datetime.strptime(str(ose_intdate), '%Y%m%d') - datetime.datetime(1899,12,30)).days + 1\n",
    "            ose =  datetime.datetime(1899,12,30) + datetime.timedelta(int(ose_intdate))         \n",
    "        inSampleSlice = df_train[(df_train.useConsDay >= startUseConsDay) &\\\n",
    "                               (df_train.useConsDay <= endUseConsDay) &\\\n",
    "                               (df_train.useFlag == 1)].reset_index(drop=True)\n",
    "        amountFilter = inSampleSlice[(inSampleSlice['curNearLimit'] == 0) &\\\n",
    "                                     (inSampleSlice['curNearLimit_L1'] == 0)].amountThisUpdate.quantile(.75)\n",
    "        if ose < oss:\n",
    "            print('out of sample end day < start day, skip')\n",
    "            continue \n",
    "        sizeFilterData.loc[(sizeFilterData.date >= oss)&(sizeFilterData.date <= ose), 'amountFilter'] = amountFilter\n",
    "    sizeFilterData['skey'] = int(stockID)\n",
    "    sizeFilterData = sizeFilterData[['skey', 'date', 'amountFilter']]\n",
    "    \n",
    "#    sizeFilterData.reset_index(drop = True).to_pickle(os.path.join(r'test_path',str(stockID) +'.pkl'))\n",
    "#    print(datetime.datetime.now() - startTm)    \n",
    "#    return sizeFilterData, [stock, df_train.date.max(), amountFilter]\n",
    "    return sizeFilterData\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "import glob\n",
    "def mp_size(startDate, endDate):\n",
    "    db = DB(db_config['host'], db_config['db'], db_config['user'], db_config['password'])\n",
    "    weight_db = db.read_daily('index_memb', start_date=start_date, \n",
    "                              end_date=endDate, index_name=bench)\n",
    "    stockList = sorted(list(weight_db['skey'].unique()))\n",
    "\n",
    "    pool = multiprocessing.Pool(5)    \n",
    "    pool.map(partial(sta_sizeFilter,db_config=db_config,startDate=startDate, endDate=endDate, \n",
    "                     regWindowSize = 20, weekInterval = 1), stockList)\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "    \n",
    "    def read_daily(self, table_name, start_date=None, end_date=None, index_id=None, skey=None, interval=None, col=None, return_sdi=True):\n",
    "        collection = self.db[table_name]\n",
    "        # Build projection\n",
    "        prj = {'_id': 0}\n",
    "        if col is not None:\n",
    "            if return_sdi:\n",
    "                col = ['skey', 'date', 'interval'] + col\n",
    "            for col_name in col:\n",
    "                prj[col_name] = 1\n",
    "    \n",
    "        # Build query\n",
    "        query = {}\n",
    "        if skey is not None:\n",
    "            query['skey'] = {'$in': skey}\n",
    "        if index_id is not None:\n",
    "            query['index_id'] = {'$in': index_id}\n",
    "        if interval is not None:\n",
    "            query['interval'] = {'$in': interval}\n",
    "        if start_date is not None:\n",
    "            if end_date is not None:\n",
    "                query['date'] = {'$gte': start_date, '$lte': end_date}\n",
    "            else:\n",
    "                query['date'] = {'$gte': start_date}\n",
    "        elif end_date is not None:\n",
    "            query['date'] = {'$lte': end_date}\n",
    "\n",
    "        # Load data\n",
    "        cur = collection.find(query, prj)\n",
    "        df = pd.DataFrame.from_records(cur)\n",
    "        if df.empty:\n",
    "            df = pd.DataFrame()\n",
    "        else:\n",
    "            df = df.sort_values(by=['date', 'index_id', 'skey'])\n",
    "        return df    \n",
    "\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tradeConsDay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20200102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20200103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20200106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20200107</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20200108</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>20200109</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>20200110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>20200113</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>20200114</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>20200115</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>20200116</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>20200117</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>20200120</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>20200121</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  tradeConsDay\n",
       "0   20200102             0\n",
       "1   20200103             1\n",
       "2   20200106             2\n",
       "3   20200107             3\n",
       "4   20200108             4\n",
       "5   20200109             5\n",
       "6   20200110             6\n",
       "7   20200113             7\n",
       "8   20200114             8\n",
       "9   20200115             9\n",
       "10  20200116            10\n",
       "11  20200117            11\n",
       "12  20200120            12\n",
       "13  20200121            13"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startDate = 20200102\n",
    "endDate = 20200121\n",
    "\n",
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "\n",
    "pd.set_option('max_columns', 200)\n",
    "db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "indexDaily = db1.read_daily('index_memb', start_date=startDate, end_date=endDate, index_id=[1000905])\n",
    "\n",
    "indexDaily['tradeConsDay'] = indexDaily.groupby(['date']).grouper.group_info[0]\n",
    "indexDaily = indexDaily.groupby('date')['tradeConsDay'].first().reset_index()\n",
    "indexDaily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationFailure",
     "evalue": "Authentication failed., full error: {'ok': 0.0, 'errmsg': 'Authentication failed.', 'code': 18, 'codeName': 'AuthenticationFailed'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationFailure\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-423cd58be208>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'host'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'db'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'password'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m \u001b[0mstockData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'md_snapshot_l2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstartDate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mendDate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1600000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m stockData = stockData.loc[((stockData.bid1p != 0) | (stockData.ask1p != 0)), \\\n\u001b[0;32m    198\u001b[0m                               ['skey','date','time','clockAtArrival','datetime','ordering',\n",
      "\u001b[1;32m<ipython-input-9-423cd58be208>\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, table_name, start_date, end_date, symbol)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0msegs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ver'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0msegs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1205\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_refresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1208\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__manipulate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m                 \u001b[0m_db\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\cursor.py\u001b[0m in \u001b[0;36m_refresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1122\u001b[0m                                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m                                   self.__allow_disk_use)\n\u001b[1;32m-> 1124\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__send_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1125\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__id\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Get More\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__limit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\cursor.py\u001b[0m in \u001b[0;36m__send_message\u001b[1;34m(self, operation)\u001b[0m\n\u001b[0;32m    999\u001b[0m             response = client._run_operation_with_response(\n\u001b[0;32m   1000\u001b[0m                 \u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unpack_response\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__exhaust\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1001\u001b[1;33m                 address=self.__address)\n\u001b[0m\u001b[0;32m   1002\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOperationFailure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__killed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_run_operation_with_response\u001b[1;34m(self, operation, unpack_res, exhaust, address)\u001b[0m\n\u001b[0;32m   1370\u001b[0m             \u001b[0maddress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m             \u001b[0mretryable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Query\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1372\u001b[1;33m             exhaust=exhaust)\n\u001b[0m\u001b[0;32m   1373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_retry_with_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretryable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbulk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_retryable_read\u001b[1;34m(self, func, read_pref, session, address, retryable, exhaust)\u001b[0m\n\u001b[0;32m   1463\u001b[0m                     \u001b[0mretryable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m                 with self._slaveok_for_server(read_pref, server, session,\n\u001b[1;32m-> 1465\u001b[1;33m                                               \u001b[0mexhaust\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1466\u001b[0m                                                                    slave_ok):\n\u001b[0;32m   1467\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mretrying\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mretryable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_slaveok_for_server\u001b[1;34m(self, read_preference, server, session, exhaust)\u001b[0m\n\u001b[0;32m   1307\u001b[0m         \u001b[0msingle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopology_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTOPOLOGY_TYPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSingle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1309\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msock_info\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1310\u001b[0m             slave_ok = (single and not sock_info.is_mongos) or (\n\u001b[0;32m   1311\u001b[0m                 read_preference != ReadPreference.PRIMARY)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_get_socket\u001b[1;34m(self, server, session, exhaust)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_MongoClientErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr_handler\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m             with server.get_socket(\n\u001b[1;32m-> 1247\u001b[1;33m                     self.__all_credentials, checkout=exhaust) as sock_info:\n\u001b[0m\u001b[0;32m   1248\u001b[0m                 \u001b[0merr_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontribute_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m                 if (self._encrypter and\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\pool.py\u001b[0m in \u001b[0;36mget_socket\u001b[1;34m(self, all_credentials, checkout)\u001b[0m\n\u001b[0;32m   1223\u001b[0m             \u001b[0mlisteners\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpublish_connection_check_out_started\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1225\u001b[1;33m         \u001b[0msock_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_credentials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled_for_cmap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\pool.py\u001b[0m in \u001b[0;36m_get_socket\u001b[1;34m(self, all_credentials)\u001b[0m\n\u001b[0;32m   1277\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_perished\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m                         \u001b[0msock_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1279\u001b[1;33m             \u001b[0msock_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_auth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_credentials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1280\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1281\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msock_info\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\pool.py\u001b[0m in \u001b[0;36mcheck_auth\u001b[1;34m(self, all_credentials)\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcredentials\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcached\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mauthset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 793\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthenticate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m         \u001b[1;31m# CMAP spec says to publish the ready event only after authenticating\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\pool.py\u001b[0m in \u001b[0;36mauthenticate\u001b[1;34m(self, credentials)\u001b[0m\n\u001b[0;32m    808\u001b[0m           \u001b[1;33m-\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mMongoCredential\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m         \"\"\"\n\u001b[1;32m--> 810\u001b[1;33m         \u001b[0mauth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthenticate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;31m# negotiated_mechanisms are no longer needed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\auth.py\u001b[0m in \u001b[0;36mauthenticate\u001b[1;34m(credentials, sock_info)\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[0mmechanism\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmechanism\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[0mauth_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_AUTH_MAP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmechanism\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m     \u001b[0mauth_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msock_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\auth.py\u001b[0m in \u001b[0;36m_authenticate_default\u001b[1;34m(credentials, sock_info)\u001b[0m\n\u001b[0;32m    589\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_authenticate_scram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SCRAM-SHA-256'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_authenticate_scram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SCRAM-SHA-1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msock_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_wire_version\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_authenticate_scram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SCRAM-SHA-1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\auth.py\u001b[0m in \u001b[0;36m_authenticate_scram\u001b[1;34m(credentials, sock_info, mechanism)\u001b[0m\n\u001b[0;32m    293\u001b[0m         nonce, first_bare, cmd = _authenticate_scram_start(\n\u001b[0;32m    294\u001b[0m             credentials, mechanism)\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msock_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[0mserver_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'payload'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\pool.py\u001b[0m in \u001b[0;36mcommand\u001b[1;34m(self, dbname, spec, slave_ok, read_preference, codec_options, check, allowable_errors, check_keys, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[0m\n\u001b[0;32m    692\u001b[0m                            \u001b[0munacknowledged\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munacknowledged\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m                            \u001b[0muser_fields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_fields\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m                            exhaust_allowed=exhaust_allowed)\n\u001b[0m\u001b[0;32m    695\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOperationFailure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\network.py\u001b[0m in \u001b[0;36mcommand\u001b[1;34m(sock_info, dbname, spec, slave_ok, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, check_keys, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields, exhaust_allowed)\u001b[0m\n\u001b[0;32m    160\u001b[0m                     \u001b[0mresponse_doc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msock_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_wire_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                     \u001b[0mallowable_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                     parse_write_concern_error=parse_write_concern_error)\n\u001b[0m\u001b[0;32m    163\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpublish\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\helpers.py\u001b[0m in \u001b[0;36m_check_command_response\u001b[1;34m(response, max_wire_version, msg, allowable_errors, parse_write_concern_error)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"%s\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             raise OperationFailure(msg % errmsg, code, response,\n\u001b[1;32m--> 168\u001b[1;33m                                    max_wire_version)\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationFailure\u001b[0m: Authentication failed., full error: {'ok': 0.0, 'errmsg': 'Authentication failed.', 'code': 18, 'codeName': 'AuthenticationFailed'}"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "db_config = {\n",
    "    'user': 'user_rw',\n",
    "    'password': 'faa96dfc',\n",
    "    'host': '192.168.10.178',\n",
    "    'port': '27017',\n",
    "    'db': 'com_md_eq_cn'\n",
    "    }\n",
    "\n",
    "\n",
    "startDate = 20200102\n",
    "endDate = 20200102\n",
    "StockID = 1600000\n",
    "\n",
    "db = DB(db_config['host'], db_config['db'], db_config['user'], db_config['password'])\n",
    "stockData = db.read('md_snapshot_l2', start_date=startDate, end_date=endDate, symbol=[1600000])\n",
    "stockData = stockData.loc[((stockData.bid1p != 0) | (stockData.ask1p != 0)), \\\n",
    "                              ['skey','date','time','clockAtArrival','datetime','ordering',\n",
    "                               'cum_amount','bid1p','bid1q','bid5q','ask5q']].reset_index(drop=True)\n",
    "#     stockData = stockData[((stockData.time >= 93000000000) & (stockData.time <= 113000000000)) | \\\n",
    "#                           ((stockData.time >= 130000000000) & (stockData.time <= 150000000000))].reset_index(drop=True)\n",
    "#     indexDaily = db.read_daily('index_memb', start_date=startDate, end_date=endDate, index_name='IF')\n",
    "#     indexDaily['tradeConsDay'] = indexDaily.groupby(['date']).grouper.group_info[0]\n",
    "#     indexDaily = indexDaily.groupby('date')['tradeConsDay'].first().reset_index()\n",
    "#     df_train = stockData.merge(indexDaily[['date','tradeConsDay']], how='left', on=['date'], validate='many_to_one')\n",
    "    \n",
    "#     df_train = df_train[(df_train['time'] >= 93000000000) & (df_train['time'] < 145655000000)].reset_index(drop=True)\n",
    "#     groupAllData = df_train.groupby(['skey','date'])\n",
    "#     df_train['amountThisUpdate'] = df_train.cum_amount - groupAllData['cum_amount'].shift(1)\n",
    "#     df_train['amountThisUpdate'] = np.where(pd.isnull(df_train.amountThisUpdate), df_train.cum_amount, df_train.amountThisUpdate)\n",
    "\n",
    "#     ### add useful day indicator\n",
    "#     df_train['curNearLimit'] = np.where((df_train.ask5q == 0) | (df_train.bid5q == 0), 1.0, 0.0)\n",
    "#     df_train['curNearLimit_L1'] = groupAllData['curNearLimit'].shift(1)\n",
    "#     df_train['dailyCount'] = groupAllData['time'].transform('count')\n",
    "#     df_train['nearLimitCount'] = groupAllData['curNearLimit'].transform('sum')\n",
    "#     dateInfo = groupAllData['dailyCount', 'nearLimitCount', 'tradeConsDay'].mean().reset_index()\n",
    "#     del groupAllData\n",
    "#     dateInfo['useFlag'] = np.where(dateInfo['nearLimitCount']*2 < dateInfo['dailyCount'], 1, 0)\n",
    "#     dateInfo['useConsDay'] = dateInfo['useFlag'].cumsum()\n",
    "#     df_train = pd.merge(df_train, dateInfo[['date', 'tradeConsDay', 'useFlag', 'useConsDay']],\n",
    "#                         how='left', on=['date', 'tradeConsDay'], validate='many_to_one') \n",
    "    \n",
    "#     df_train['weekday'] = df_train['datetime'].dt.weekday\n",
    "#     sizeFilterData = df_train.groupby(['date'])['tradeConsDay'].first().reset_index()\n",
    "#     sizeFilterData['amountFilter'] = np.nan\n",
    "#     ## we only update on Thrusday\n",
    "#     regDays = sorted(list(df_train.loc[df_train.weekday == 3, 'tradeConsDay'].unique()))      \n",
    "\n",
    "#     weekInterval = 1      \n",
    "#     for d in range(int(regWindowSize/5), len(regDays), weekInterval):\n",
    "#         amountFilter = np.nan\n",
    "#         ## get current Thrusday\n",
    "#         endTradeConsDay = regDays[d]\n",
    "#         endUseConsDay = dateInfo[dateInfo['tradeConsDay'] == endTradeConsDay]['useConsDay'].values[0]\n",
    "#         startUseConsDay = max(endUseConsDay - regWindowSize + 1, 1)\n",
    "        \n",
    "#         ## check 60 consecutive days\n",
    "#         if dateInfo['useConsDay'].max() < 1: \n",
    "#             amountFilter = np.nan\n",
    "#             continue\n",
    "#         startTradeConsDay = dateInfo[dateInfo['useConsDay'] == startUseConsDay]['tradeConsDay'].values[0]\n",
    "#         endTradeConsDay = dateInfo[dateInfo['tradeConsDay'] == endTradeConsDay]['tradeConsDay'].values[0]\n",
    "#         if (endTradeConsDay - startTradeConsDay > 59) or (endUseConsDay - startUseConsDay < 9):\n",
    "#             amountFilter = np.nan\n",
    "#             continue      \n",
    "#         ## get the Monday right after current Thursday update\n",
    "#         oss = df_train.loc[df_train.tradeConsDay == endTradeConsDay, 'date'].unique()[0] + 4  \n",
    "#         ## get the Friday right after next Thursday update\n",
    "#         if d >= len(regDays) - weekInterval:\n",
    "#             ose = df_train.date.max()\n",
    "#         else:\n",
    "#             ose = df_train.loc[df_train.tradeConsDay == regDays[d+weekInterval], 'date'].unique()[0] + 1        \n",
    "#         inSampleSlice = df_train[(df_train.useConsDay >= startUseConsDay) &\\\n",
    "#                                (df_train.useConsDay <= endUseConsDay) &\\\n",
    "#                                (df_train.useFlag == 1)].reset_index(drop=True)\n",
    "#         amountFilter = inSampleSlice[(inSampleSlice['curNearLimit'] == 0) &\\\n",
    "#                                      (inSampleSlice['curNearLimit_L1'] == 0)].amountThisUpdate.quantile(.75)\n",
    "#         if ose < oss:\n",
    "#             print('out of sample end day < start day, skip')\n",
    "#             continue \n",
    "#         sizeFilterData.loc[(sizeFilterData.date >= oss)&(sizeFilterData.date <= ose), 'amountFilter'] = amountFilter\n",
    "#     sizeFilterData['skey'] = int(stockID)\n",
    "#     sizeFilterData = sizeFilterData[['skey', 'date', 'amountFilter']]\n",
    "    \n",
    "# #    sizeFilterData.reset_index(drop = True).to_pickle(os.path.join(r'test_path',str(stockID) +'.pkl'))\n",
    "# #    print(datetime.datetime.now() - startTm)    \n",
    "# #    return sizeFilterData, [stock, df_train.date.max(), amountFilter]\n",
    "#     return sizeFilterData\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
