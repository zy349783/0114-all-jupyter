{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:195: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:46.010462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:256: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\win\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:257: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2000403,\n",
       " 2000409,\n",
       " 2000422,\n",
       " 2000511,\n",
       " 2000585,\n",
       " 2000655,\n",
       " 2000693,\n",
       " 2000707,\n",
       " 2000720,\n",
       " 2000737,\n",
       " 2000816,\n",
       " 2000893,\n",
       " 2000912,\n",
       " 2000922,\n",
       " 2000939,\n",
       " 2000953,\n",
       " 2000972,\n",
       " 2002102,\n",
       " 2002122,\n",
       " 2002194,\n",
       " 2002259,\n",
       " 2002260,\n",
       " 2002263,\n",
       " 2002306,\n",
       " 2002427,\n",
       " 2002445,\n",
       " 2002473,\n",
       " 2002496,\n",
       " 2002570,\n",
       " 2002604,\n",
       " 2002680,\n",
       " 2300299,\n",
       " 2300301,\n",
       " 2300302,\n",
       " 2300303,\n",
       " 2300304,\n",
       " 2300305,\n",
       " 2300306,\n",
       " 2300307,\n",
       " 2300308,\n",
       " 2300309,\n",
       " 2300310,\n",
       " 2300311,\n",
       " 2300312,\n",
       " 2300314,\n",
       " 2300316,\n",
       " 2300317,\n",
       " 2300318,\n",
       " 2300319,\n",
       " 2300320,\n",
       " 2300321,\n",
       " 2300322,\n",
       " 2300323,\n",
       " 2300325,\n",
       " 2300326,\n",
       " 2300327,\n",
       " 2300328,\n",
       " 2300329,\n",
       " 2300330,\n",
       " 2300331,\n",
       " 2300332,\n",
       " 2300333,\n",
       " 2300334,\n",
       " 2300335,\n",
       " 2300336,\n",
       " 2300337,\n",
       " 2300338,\n",
       " 2300339,\n",
       " 2300340,\n",
       " 2300341,\n",
       " 2300342,\n",
       " 2300344,\n",
       " 2300345,\n",
       " 2300346,\n",
       " 2300348,\n",
       " 2300349,\n",
       " 2300351,\n",
       " 2300352,\n",
       " 2300353,\n",
       " 2300354,\n",
       " 2300355,\n",
       " 2300356,\n",
       " 2300357,\n",
       " 2300358,\n",
       " 2300360,\n",
       " 2300363,\n",
       " 2300365,\n",
       " 2300366,\n",
       " 2300367,\n",
       " 2300368,\n",
       " 2300369,\n",
       " 2300371,\n",
       " 2300373,\n",
       " 2300375,\n",
       " 2300376,\n",
       " 2300377,\n",
       " 2300378,\n",
       " 2300379,\n",
       " 2300380,\n",
       " 2300381,\n",
       " 2300382,\n",
       " 2300383,\n",
       " 2300384,\n",
       " 2300385,\n",
       " 2300386,\n",
       " 2300387,\n",
       " 2300388,\n",
       " 2300389,\n",
       " 2300390,\n",
       " 2300391,\n",
       " 2300392,\n",
       " 2300393,\n",
       " 2300395,\n",
       " 2300396,\n",
       " 2300397,\n",
       " 2300398,\n",
       " 2300399,\n",
       " 2300400,\n",
       " 2300401,\n",
       " 2300402,\n",
       " 2300403,\n",
       " 2300405,\n",
       " 2300406,\n",
       " 2300407,\n",
       " 2300408,\n",
       " 2300409,\n",
       " 2300410,\n",
       " 2300411,\n",
       " 2300412}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>max_volume</th>\n",
       "      <th>max_amount</th>\n",
       "      <th>skey</th>\n",
       "      <th>cum_volume</th>\n",
       "      <th>cum_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>SZ000403</td>\n",
       "      <td>3083673.0</td>\n",
       "      <td>5.373307e+07</td>\n",
       "      <td>2000403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>SZ000409</td>\n",
       "      <td>8845104.0</td>\n",
       "      <td>9.233572e+07</td>\n",
       "      <td>2000409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>SZ000422</td>\n",
       "      <td>51173396.0</td>\n",
       "      <td>3.958065e+08</td>\n",
       "      <td>2000422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>SZ000511</td>\n",
       "      <td>66122038.0</td>\n",
       "      <td>5.755510e+08</td>\n",
       "      <td>2000511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>SZ000585</td>\n",
       "      <td>11698694.0</td>\n",
       "      <td>4.800403e+07</td>\n",
       "      <td>2000585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1419</td>\n",
       "      <td>SZ300408</td>\n",
       "      <td>2295399.0</td>\n",
       "      <td>1.078508e+08</td>\n",
       "      <td>2300408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>SZ300409</td>\n",
       "      <td>1630035.0</td>\n",
       "      <td>7.465354e+07</td>\n",
       "      <td>2300409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1421</td>\n",
       "      <td>SZ300410</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>6.494200e+04</td>\n",
       "      <td>2300410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1422</td>\n",
       "      <td>SZ300411</td>\n",
       "      <td>6050.0</td>\n",
       "      <td>1.226335e+05</td>\n",
       "      <td>2300411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1423</td>\n",
       "      <td>SZ300412</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>7.000500e+04</td>\n",
       "      <td>2300412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  max_volume    max_amount     skey  cum_volume  cum_amount\n",
       "71    SZ000403   3083673.0  5.373307e+07  2000403         NaN         NaN\n",
       "75    SZ000409   8845104.0  9.233572e+07  2000409         NaN         NaN\n",
       "84    SZ000422  51173396.0  3.958065e+08  2000422         NaN         NaN\n",
       "96    SZ000511  66122038.0  5.755510e+08  2000511         NaN         NaN\n",
       "146   SZ000585  11698694.0  4.800403e+07  2000585         NaN         NaN\n",
       "...        ...         ...           ...      ...         ...         ...\n",
       "1419  SZ300408   2295399.0  1.078508e+08  2300408         NaN         NaN\n",
       "1420  SZ300409   1630035.0  7.465354e+07  2300409         NaN         NaN\n",
       "1421  SZ300410      3800.0  6.494200e+04  2300410         NaN         NaN\n",
       "1422  SZ300411      6050.0  1.226335e+05  2300411         NaN         NaN\n",
       "1423  SZ300412      3250.0  7.000500e+04  2300412         NaN         NaN\n",
       "\n",
       "[129 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>max_volume</th>\n",
       "      <th>max_amount</th>\n",
       "      <th>skey</th>\n",
       "      <th>cum_volume</th>\n",
       "      <th>cum_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>SZ000403</td>\n",
       "      <td>3083673.0</td>\n",
       "      <td>5.373307e+07</td>\n",
       "      <td>2000403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>SZ000409</td>\n",
       "      <td>8845104.0</td>\n",
       "      <td>9.233572e+07</td>\n",
       "      <td>2000409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>SZ000422</td>\n",
       "      <td>51173396.0</td>\n",
       "      <td>3.958065e+08</td>\n",
       "      <td>2000422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>SZ000511</td>\n",
       "      <td>66122038.0</td>\n",
       "      <td>5.755510e+08</td>\n",
       "      <td>2000511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>SZ000585</td>\n",
       "      <td>11698694.0</td>\n",
       "      <td>4.800403e+07</td>\n",
       "      <td>2000585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1419</td>\n",
       "      <td>SZ300408</td>\n",
       "      <td>2295399.0</td>\n",
       "      <td>1.078508e+08</td>\n",
       "      <td>2300408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>SZ300409</td>\n",
       "      <td>1630035.0</td>\n",
       "      <td>7.465354e+07</td>\n",
       "      <td>2300409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1421</td>\n",
       "      <td>SZ300410</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>6.494200e+04</td>\n",
       "      <td>2300410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1422</td>\n",
       "      <td>SZ300411</td>\n",
       "      <td>6050.0</td>\n",
       "      <td>1.226335e+05</td>\n",
       "      <td>2300411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1423</td>\n",
       "      <td>SZ300412</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>7.000500e+04</td>\n",
       "      <td>2300412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  max_volume    max_amount     skey  cum_volume  cum_amount\n",
       "71    SZ000403   3083673.0  5.373307e+07  2000403         NaN         NaN\n",
       "75    SZ000409   8845104.0  9.233572e+07  2000409         NaN         NaN\n",
       "84    SZ000422  51173396.0  3.958065e+08  2000422         NaN         NaN\n",
       "96    SZ000511  66122038.0  5.755510e+08  2000511         NaN         NaN\n",
       "146   SZ000585  11698694.0  4.800403e+07  2000585         NaN         NaN\n",
       "...        ...         ...           ...      ...         ...         ...\n",
       "1419  SZ300408   2295399.0  1.078508e+08  2300408         NaN         NaN\n",
       "1420  SZ300409   1630035.0  7.465354e+07  2300409         NaN         NaN\n",
       "1421  SZ300410      3800.0  6.494200e+04  2300410         NaN         NaN\n",
       "1422  SZ300411      6050.0  1.226335e+05  2300411         NaN         NaN\n",
       "1423  SZ300412      3250.0  7.000500e+04  2300412         NaN         NaN\n",
       "\n",
       "[129 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-05\n",
      "trade finished\n",
      "0:05:22.273162\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "readPath = 'L:\\\\daily\\\\2015\\\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dataPathLs = dataPathLs[[np.array([os.path.basename(i).split('.')[0][:2] == 'SZ' for i in dataPathLs])]]\n",
    "db = pd.DataFrame()\n",
    "for p in dataPathLs:\n",
    "    dayData = pd.read_csv(p, compression='gzip')\n",
    "    db = pd.concat([db, dayData])\n",
    "print(datetime.datetime.now() - startTm)\n",
    "\n",
    "year = \"2015\"\n",
    "startDate = '20150101'\n",
    "endDate = '20151231'\n",
    "readPath = 'H:\\\\' + year + '\\\\SZ\\\\x64release\\\\Transaction\\\\SZ\\\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "date = np.unique(np.array([os.path.basename(i) for i in dataPathLs]))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "ll = []\n",
    "problems = []\n",
    "\n",
    "for d in date: \n",
    "    TradeLog = []\n",
    "    path = dataPathLs[dateLs == d]\n",
    "    for p in path:\n",
    "        readPath = p + '\\\\***'\n",
    "        datapath = np.array(glob.glob(readPath))\n",
    "        dd = np.array([int(os.path.basename(i).split('.')[0]) for i in datapath])\n",
    "        datapath = datapath[(dd < 4000) | ((dd > 300000) & (dd < 310000))]\n",
    "        for i in datapath:\n",
    "            try:\n",
    "                df = pd.read_csv(i, encoding='GBK')\n",
    "            except:\n",
    "                print(\"empty data\")\n",
    "                print(i)\n",
    "                ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "                continue\n",
    "            TradeLog += [df]\n",
    "    TradeLog = pd.concat(TradeLog).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    TradeLog = TradeLog.rename(columns={\"function_code\": \"trade_type\", \"trade_volume\":\"trade_qty\",\n",
    "                                       \"bid_order\":\"BidApplSeqNum\", \"ask_order\":\"OfferApplSeqNum\"})\n",
    "    TradeLog['skey'] = TradeLog['wind_code'].apply(lambda x: x.split('.')[0]).astype(int) + 2000000\n",
    "    TradeLog[\"trade_type\"] = np.where(TradeLog[\"trade_type\"] == 67, 4, 1)\n",
    "    TradeLog[\"trade_flag\"] = 0\n",
    "    TradeLog['trade_price'] = (TradeLog['trade_price'] / 10000).round(2)\n",
    "    TradeLog[\"trade_money\"] = TradeLog[\"trade_price\"] * TradeLog[\"trade_qty\"]\n",
    "    TradeLog['TransactTime'] = (TradeLog['date'] * 1000000000).astype('int64') + TradeLog['time']\n",
    "    TradeLog = TradeLog[TradeLog[\"TransactTime\"].astype(str).str[12:14].astype(int) < 60]\n",
    "    TradeLog[\"clockAtArrival\"] = TradeLog[\"TransactTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    TradeLog['datetime'] = TradeLog[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    TradeLog[\"time\"] = TradeLog['time'].astype(np.int64)*1000\n",
    "    \n",
    "    for col in [\"skey\", \"date\", \"BidApplSeqNum\", \"OfferApplSeqNum\", \"trade_qty\", \"trade_type\", \"trade_flag\"]:\n",
    "        TradeLog[col] = TradeLog[col].astype('int32')\n",
    "    for cols in [\"trade_money\"]:\n",
    "        TradeLog[cols] = TradeLog[cols].round(2)\n",
    "    \n",
    "    da_te = str(TradeLog[\"date\"].iloc[0]) \n",
    "    da_te = da_te[:4] + '-' + da_te[4:6] + '-' + da_te[6:8]\n",
    "    db1 = db[db[\"date\"] == da_te]\n",
    "    sl = (db1[\"ID\"].str[2:].astype(int) + 2000000).unique()\n",
    "    db1[\"max_volume\"] = db1.groupby(\"ID\")[\"volume\"].transform(\"max\")\n",
    "    db1[\"max_amount\"] = db1.groupby(\"ID\")[\"amount\"].transform(\"max\")\n",
    "    t1 = db1.groupby(\"ID\")[\"max_volume\", \"max_amount\"].first().reset_index()\n",
    "    del db1\n",
    "    t1[\"skey\"] = t1[\"ID\"].str[2:].astype(int) + 2000000\n",
    "    trade1 = TradeLog[TradeLog[\"trade_type\"] == 1].groupby(\"skey\")[\"trade_qty\"].sum().reset_index()\n",
    "    trade1.columns=[\"skey\", \"cum_volume\"]\n",
    "    trade2 = TradeLog[TradeLog[\"trade_type\"] == 1].groupby(\"skey\")[\"trade_money\"].sum().reset_index()\n",
    "    trade2.columns=[\"skey\", \"cum_amount\"]\n",
    "    t2 = pd.merge(trade1, trade2, on=\"skey\")\n",
    "    re = pd.merge(t1, t2, on=\"skey\", how=\"outer\")\n",
    "    try:\n",
    "        assert(t1.shape[0] == t2.shape[0])\n",
    "        assert(re[re[\"cum_volume\"] != re[\"max_volume\"]].shape[0] == 0)\n",
    "        assert(re[re[\"cum_amount\"].round(2) != re[\"max_amount\"]].shape[0] == 0)\n",
    "    except:\n",
    "        display(set(t1[\"skey\"]) - set(t2[\"skey\"]))\n",
    "        display(re[re[\"cum_volume\"] != re[\"max_volume\"]])\n",
    "        display(re[re[\"cum_amount\"].round(2) != re[\"max_amount\"]])\n",
    "        re['date'] = d\n",
    "        add = TradeLog[TradeLog['skey'].isin(re[(re[\"cum_amount\"].round(2) != re[\"max_amount\"]) & (~re['skey'].isin([2001872, 2001914]))]['skey'].unique())].groupby('skey')['time'].max().reset_index()\n",
    "        problems += [pd.merge(re[(re[\"cum_amount\"].round(2) != re[\"max_amount\"]) & (~re['skey'].isin([2001872, 2001914]))], add, on='skey')[['date', 'skey', 'time']]]\n",
    "    del t1\n",
    "    del t2\n",
    "    del re\n",
    "    \n",
    "    TradeLog['ApplSeqNum'] = 0\n",
    "    TradeLog['ApplSeqNum'] = TradeLog['ApplSeqNum'].astype(int)\n",
    "    TradeLog = TradeLog[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ApplSeqNum\", \"trade_type\", \"trade_flag\",\n",
    "                                                 \"trade_price\", \"trade_qty\", \"BidApplSeqNum\", \"OfferApplSeqNum\"]]\n",
    "    print(da_te)\n",
    "    print(\"trade finished\")\n",
    "\n",
    "\n",
    "    \n",
    "    database_name = 'com_md_eq_cn'\n",
    "    user = \"zhenyuy\"\n",
    "    password = \"bnONBrzSMGoE\"\n",
    "\n",
    "    db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "    db1.write('md_trade', TradeLog)\n",
    "    \n",
    "    del TradeLog\n",
    "\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "problems = pd.concat(problems).reset_index(drop=True)\n",
    "print(problems)\n",
    "problems.to_pickle(r'G:\\\\2015_trade_1.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
