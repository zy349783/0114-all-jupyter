{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade finished\n",
      "0:04:18.452466\n"
     ]
    }
   ],
   "source": [
    "import pymongo \n",
    "import io \n",
    "import pandas as pd \n",
    "import pickle \n",
    "import datetime \n",
    "import time \n",
    "import gzip \n",
    "import lzma \n",
    "import pytz \n",
    "import pyarrow as pa \n",
    "import pyarrow.parquet as pq \n",
    "import numpy as np \n",
    "import re\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db', version=3): \n",
    "        self.db_name = db_name \n",
    "        self.uri = uri \n",
    "        self.client = pymongo.MongoClient(self.uri) \n",
    "        self.db = self.client[self.db_name] \n",
    "        self.chunk_size = 20000 \n",
    "        self.symbol_column = symbol_column \n",
    "        self.date_column = 'date' \n",
    "        self.version = version\n",
    "\n",
    "    def parse_uri(self, uri): \n",
    "        # mongodb://user:password@example.com \n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"date must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid date type: \" + str(type(x)))\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "        return query\n",
    "\n",
    "    def read_tick(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name] \n",
    "        query = self.build_query(start_date, end_date, symbol) \n",
    "        if not query: \n",
    "            print('cannot read the whole table') \n",
    "            return None  \n",
    "        segs = [] \n",
    "        for x in collection.find(query): \n",
    "            x['data'] = self.deser(x['data'], x['ver']) \n",
    "            segs.append(x) \n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start'])) \n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def read_daily(self, table_name, start_date=None, end_date=None, skey=None, index_id=None, interval=None, index_name=None, col=None, return_sdi=True): \n",
    "        collection = self.db[table_name]\n",
    "        # Build projection \n",
    "        prj = {'_id': 0} \n",
    "        if col is not None: \n",
    "            if return_sdi: \n",
    "                col = ['skey', 'date', 'index_id'] + col \n",
    "            for col_name in col: \n",
    "                prj[col_name] = 1 \n",
    "        # Build query \n",
    "        query = {} \n",
    "        if skey is not None: \n",
    "            query['skey'] = {'$in': skey} \n",
    "        if interval is not None: \n",
    "            query['interval'] = {'$in': interval} \n",
    "        if index_id is not None: \n",
    "            query['index_id'] = {'$in': index_id}    \n",
    "        if index_name is not None:\n",
    "            n = '' \n",
    "            for name in index_name: \n",
    "                try: \n",
    "                    name = re.compile('[\\u4e00-\\u9fff]+').findall(name)[0] \n",
    "                    if len(n) == 0: \n",
    "                        n = n = \"|\".join(name) \n",
    "                    else: \n",
    "                        n = n + '|' + \"|\".join(name) \n",
    "                except: \n",
    "                    if len(n) == 0: \n",
    "                        n = name \n",
    "                    else: \n",
    "                        n = n + '|' + name \n",
    "            query['index_name'] = {'$regex': n}\n",
    "        if start_date is not None: \n",
    "            if end_date is not None: \n",
    "                query['date'] = {'$gte': start_date, '$lte': end_date} \n",
    "            else: \n",
    "                query['date'] = {'$gte': start_date} \n",
    "        elif end_date is not None: \n",
    "            query['date'] = {'$lte': end_date} \n",
    "        # Load data \n",
    "        cur = collection.find(query, prj) \n",
    "        df = pd.DataFrame.from_records(cur) \n",
    "        if df.empty: \n",
    "            df = pd.DataFrame() \n",
    "        else:\n",
    "            if 'index_id' in df.columns:\n",
    "                df = df.sort_values(by=['date', 'index_id', 'skey']).reset_index(drop=True)\n",
    "            else:\n",
    "                df = df.sort_values(by=['date','skey']).reset_index(drop=True)\n",
    "        return df \n",
    " \n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = self.version\n",
    "            ser_data = self.ser(df_seg, version)\n",
    "            seg = {'ver': version, 'data': ser_data, 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        elif version == 3:\n",
    "            # 32-bit number needs more space than 64-bit for parquet\n",
    "            for col_name in s.columns:\n",
    "                col = s[col_name]\n",
    "                if col.dtype == np.int32:\n",
    "                    s[col_name] = s[col_name].astype(np.int64)\n",
    "                elif col.dtype == np.uint32:\n",
    "                    s[col_name] = s[col_name].astype(np.uint64)\n",
    "            tbl = pa.Table.from_pandas(s)\n",
    "            f = io.BytesIO()\n",
    "            pq.write_table(tbl, f, use_dictionary=False, compression='ZSTD', compression_level=0)\n",
    "            f.seek(0)\n",
    "            data = f.read()\n",
    "            return data\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        print(version)\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        elif version == 3:\n",
    "            f = io.BytesIO()\n",
    "            f.write(s)\n",
    "            f.seek(0)\n",
    "            return pq.read_table(f, use_threads=False).to_pandas()\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from unrar import rarfile\n",
    "import py7zr\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "year = \"2017\"\n",
    "startDate = \"0714\"\n",
    "endDate = \"0714\"\n",
    "df = []\n",
    "bad = []\n",
    "readPath = 'L:\\\\backup data\\\\' + year + '\\\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "\n",
    "for data in dataPathLs:\n",
    "#     if len(np.array(glob.glob(data +'\\\\***'))) == 0:\n",
    "#         continue\n",
    "    \n",
    "#     if len(np.array(glob.glob(data +'\\\\am_hq_trade_spot.7z'))) == 1:\n",
    "#         date = os.path.basename(data)\n",
    "#         path = 'L:\\\\backup data\\\\' + year \n",
    "#         os.chdir(data)\n",
    "#         try:\n",
    "#             a = py7zr.SevenZipFile(data + '\\\\am_hq_trade_spot.7z','r',filters=None)\n",
    "#         except:\n",
    "#             print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "#             print(data + '\\\\am_hq_trade_spot.7z')\n",
    "#             bad.append(data + '\\\\am_hq_trade_spot.7z')\n",
    "#             continue\n",
    "#         path1 = path + '\\\\' + date\n",
    "#         a.extractall(path = path1)\n",
    "#         a.close()\n",
    "#         try:\n",
    "#             a = py7zr.SevenZipFile(data + '\\\\pm_hq_trade_spot.7z','r',filters=None)\n",
    "#         except:\n",
    "#             print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "#             print(data + '\\\\pm_hq_trade_spot.7z')\n",
    "#             bad.append(data + '\\\\pm_hq_trade_spot.7z')\n",
    "#             continue\n",
    "#         a.extractall(path = path1)\n",
    "#         a.close()\n",
    "\n",
    "#         am_trade = pd.read_table(path1 + \"\\\\am_hq_trade_spot.txt\",header=None)\n",
    "#         am_trade.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"BidApplSeqNum\",\n",
    "#                    \"OfferApplSeqNum\",\"trade_price\",\"trade_qty\",\"trade_type\",\"TransactTime\"]\n",
    "#         pm_trade = pd.read_table(path1 + \"\\\\pm_hq_trade_spot.txt\",header=None)\n",
    "#         pm_trade.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"BidApplSeqNum\",\n",
    "#                    \"OfferApplSeqNum\",\"trade_price\",\"trade_qty\",\"trade_type\",\"TransactTime\"]\n",
    "#         TradeLogSZ1 = pd.concat([am_trade, pm_trade])\n",
    "#         del am_trade\n",
    "#         del pm_trade\n",
    "        \n",
    "#     elif len(np.array(glob.glob(data +'\\\\am_hq_trade_spot.7z.001'))) == 1:\n",
    "#         date = os.path.basename(data)\n",
    "#         path = 'L:\\\\backup data\\\\' + year \n",
    "#         os.chdir(data)\n",
    "#         os.system(\"copy /b am_hq_trade_spot.7z.* am_hq_trade_spot.7z\")\n",
    "#         try:\n",
    "#             a = py7zr.SevenZipFile(data + '\\\\am_hq_trade_spot.7z','r',filters=None)\n",
    "#         except:\n",
    "#             print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "#             print(data + '\\\\am_hq_trade_spot.7z')\n",
    "#             bad.append(data + '\\\\am_hq_trade_spot.7z')\n",
    "#             continue\n",
    "#         path1 = path + '\\\\' + date\n",
    "#         a.extractall(path = path1)\n",
    "#         a.close()\n",
    "#         os.system(\"copy /b pm_hq_trade_spot.7z.* pm_hq_trade_spot.7z\")\n",
    "#         try:\n",
    "#             a = py7zr.SevenZipFile(data + '\\\\pm_hq_trade_spot.7z','r',filters=None)\n",
    "#         except:\n",
    "#             print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "#             print(data + '\\\\pm_hq_trade_spot.7z')\n",
    "#             bad.append(data + '\\\\pm_hq_trade_spot.7z')\n",
    "#             continue\n",
    "#         a.extractall(path = path1)\n",
    "#         a.close()\n",
    "        \n",
    "#         am_trade = pd.read_table(path1 + \"\\\\am_hq_trade_spot.txt\",header=None)\n",
    "#         am_trade.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"BidApplSeqNum\",\n",
    "#                    \"OfferApplSeqNum\",\"trade_price\",\"trade_qty\",\"trade_type\",\"TransactTime\"]\n",
    "#         pm_trade = pd.read_table(path1 + \"\\\\pm_hq_trade_spot.txt\",header=None)\n",
    "#         pm_trade.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"BidApplSeqNum\",\n",
    "#                    \"OfferApplSeqNum\",\"trade_price\",\"trade_qty\",\"trade_type\",\"TransactTime\"]\n",
    "#         TradeLogSZ1 = pd.concat([am_trade, pm_trade])\n",
    "#         del am_trade\n",
    "#         del pm_trade\n",
    "        \n",
    "#     elif len(np.array(glob.glob(data +'\\\\hq_trade.7z'))) == 1:\n",
    "#         date = os.path.basename(data)\n",
    "#         path = 'L:\\\\backup data\\\\' + year \n",
    "#         os.chdir(data)\n",
    "#         try:\n",
    "#             a = py7zr.SevenZipFile(data + '\\\\hq_trade.7z','r',filters=None)\n",
    "#         except:\n",
    "#             print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "#             print(data + '\\\\hq_trade.7z')\n",
    "#             bad.append(data + '\\\\hq_trade.7z')\n",
    "#             continue\n",
    "#         path1 = path + '\\\\' + date\n",
    "#         a.extractall(path = path1)\n",
    "#         a.close()\n",
    "        \n",
    "#         TradeLogSZ1 = pd.read_table(path1 + \"\\\\hq_trade.txt\",header=None)\n",
    "#         TradeLogSZ1.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"BidApplSeqNum\",\n",
    "#                    \"OfferApplSeqNum\",\"trade_price\",\"trade_qty\",\"trade_type\",\"TransactTime\"]\n",
    "\n",
    "\n",
    "    am_trade = pd.read_table(data + \"\\\\am_hq_trade_spot.txt\",header=None)\n",
    "    am_trade.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"BidApplSeqNum\",\n",
    "               \"OfferApplSeqNum\",\"trade_price\",\"trade_qty\",\"trade_type\",\"TransactTime\"]\n",
    "    pm_trade = pd.read_table(data + \"\\\\pm_hq_trade_spot.txt\",header=None)\n",
    "    pm_trade.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"BidApplSeqNum\",\n",
    "               \"OfferApplSeqNum\",\"trade_price\",\"trade_qty\",\"trade_type\",\"TransactTime\"]\n",
    "    TradeLogSZ1 = pd.concat([am_trade, pm_trade])\n",
    "    del am_trade\n",
    "    del pm_trade\n",
    "    TradeLogSZ1 = TradeLogSZ1[(TradeLogSZ1[\"SecurityID\"] < 4000) | (TradeLogSZ1[\"SecurityID\"] > 300000)]\n",
    "    TradeLogSZ1[\"trade_money\"] = TradeLogSZ1[\"trade_price\"] * TradeLogSZ1[\"trade_qty\"]\n",
    "    TradeLogSZ1[\"trade_flag\"] = 0\n",
    "    TradeLogSZ1[\"skey\"] = TradeLogSZ1[\"SecurityID\"] + 2000000\n",
    "    TradeLogSZ1[\"clockAtArrival\"] = TradeLogSZ1[\"TransactTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    TradeLogSZ1['datetime'] = TradeLogSZ1[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    TradeLogSZ1[\"time\"] = (TradeLogSZ1['TransactTime'] - int(TradeLogSZ1['TransactTime'].iloc[0]//1000000000*1000000000)).astype(np.int64)*1000\n",
    "    TradeLogSZ1[\"trade_type\"] = np.where(TradeLogSZ1[\"trade_type\"] == 'F', 1, TradeLogSZ1[\"trade_type\"])\n",
    "    for col in [\"skey\", \"date\", \"ApplSeqNum\", \"BidApplSeqNum\", \"OfferApplSeqNum\", \"trade_qty\", \"trade_type\", \"trade_flag\"]:\n",
    "        TradeLogSZ1[col] = TradeLogSZ1[col].astype('int32')\n",
    "    for cols in [\"trade_money\"]:\n",
    "        TradeLogSZ1[cols] = TradeLogSZ1[cols].round(2)\n",
    "    display(TradeLogSZ1[\"trade_price\"].astype(str).apply(lambda x: len(x.split('.')[1])).unique())\n",
    " \n",
    "    TradeLogSZ1 = TradeLogSZ1[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ApplSeqNum\", \"trade_type\", \"trade_flag\",\n",
    "                                                 \"trade_price\", \"trade_qty\", \"BidApplSeqNum\", \"OfferApplSeqNum\"]]\n",
    "    print(\"trade finished\")\n",
    "\n",
    "    print(datetime.datetime.now() - startTm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "database_name = 'com_md_eq_cn'\n",
    "user = 'zhenyuy'\n",
    "password = 'bnONBrzSMGoE'\n",
    "\n",
    "import sys\n",
    "TradeLogSZ1 = TradeLogSZ1[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"ApplSeqNum\", \"trade_type\", \"trade_flag\",\n",
    "                                                 \"trade_price\", \"trade_qty\", \"BidApplSeqNum\", \"OfferApplSeqNum\"]]\n",
    "pd.set_option('max_columns', 200)\n",
    "db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "db1.write('md_trade', TradeLogSZ1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TradeLogSZ1 = TradeLogSZ1[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"ApplSeqNum\", \"trade_type\", \"trade_flag\",\n",
    "                                                 \"trade_price\", \"trade_qty\", \"BidApplSeqNum\", \"OfferApplSeqNum\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "    \n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "def dailyDB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    url = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    client = pymongo.MongoClient(url, maxPoolSize=None)\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def read_stock_daily(db, name, start_date=None, end_date=None, skey=None, index_name=None, interval=None, col=None, return_sdi=True):\n",
    "    collection = db[name]\n",
    "    # Build projection\n",
    "    prj = {'_id': 0}\n",
    "    if col is not None:\n",
    "        if return_sdi:\n",
    "            col = ['skey', 'date'] + col\n",
    "        for col_name in col:\n",
    "            prj[col_name] = 1\n",
    "\n",
    "    # Build query\n",
    "    query = {}\n",
    "    if skey is not None:\n",
    "        query['skey'] = {'$in': skey}\n",
    "    if index_name is not None:\n",
    "        query['index_name'] = {'$in': index_name}\n",
    "    if start_date is not None:\n",
    "        if end_date is not None:\n",
    "            query['date'] = {'$gte': start_date, '$lte': end_date}\n",
    "        else:\n",
    "            query['date'] = {'$gte': start_date}\n",
    "    elif end_date is not None:\n",
    "        query['date'] = {'$lte': end_date}\n",
    "\n",
    "    # Load data\n",
    "    cur = collection.find(query, prj)\n",
    "    df = pd.DataFrame.from_records(cur)\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        df = df.sort_values(by=['date', 'skey'])\n",
    "    return df    \n",
    "\n",
    "database_name = 'com_md_eq_cn'\n",
    "user = 'zhenyuy'\n",
    "password = 'bnONBrzSMGoE'\n",
    "\n",
    "import sys\n",
    "\n",
    "pd.set_option('max_columns', 200)\n",
    "db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "db = dailyDB(\"192.168.10.178\", database_name, user, password)\n",
    "# trade = db1.read('md_trade', start_date=20200221, end_date=20200221)\n",
    "# check = read_stock_daily(db, 'mdbar1d_tr', start_date=20200221, end_date=20200221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skey                        int32\n",
       "date                        int32\n",
       "time                        int64\n",
       "clockAtArrival              int64\n",
       "datetime           datetime64[ns]\n",
       "ApplSeqNum                  int32\n",
       "trade_type                  int32\n",
       "trade_flag                  int32\n",
       "trade_price               float64\n",
       "trade_qty                   int32\n",
       "BidApplSeqNum               int32\n",
       "OfferApplSeqNum             int32\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "skey                        int32\n",
       "date                        int32\n",
       "time                        int64\n",
       "clockAtArrival              int64\n",
       "datetime           datetime64[ns]\n",
       "ApplSeqNum                  int32\n",
       "trade_type                  int32\n",
       "trade_flag                  int32\n",
       "trade_price               float64\n",
       "trade_qty                   int32\n",
       "BidApplSeqNum               int32\n",
       "OfferApplSeqNum             int32\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(TradeLogSZ1.dtypes)\n",
    "display(trade.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>trade_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2000001</td>\n",
       "      <td>99507102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2000002</td>\n",
       "      <td>105920154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2000004</td>\n",
       "      <td>6313742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2000005</td>\n",
       "      <td>13090051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2000006</td>\n",
       "      <td>10850429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2190</td>\n",
       "      <td>2300815</td>\n",
       "      <td>4190165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2191</td>\n",
       "      <td>2300816</td>\n",
       "      <td>5490562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2192</td>\n",
       "      <td>2300817</td>\n",
       "      <td>34904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2193</td>\n",
       "      <td>2300818</td>\n",
       "      <td>5251440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2194</td>\n",
       "      <td>2300820</td>\n",
       "      <td>1281659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         skey  trade_qty\n",
       "0     2000001   99507102\n",
       "1     2000002  105920154\n",
       "2     2000004    6313742\n",
       "3     2000005   13090051\n",
       "4     2000006   10850429\n",
       "...       ...        ...\n",
       "2190  2300815    4190165\n",
       "2191  2300816    5490562\n",
       "2192  2300817      34904\n",
       "2193  2300818    5251440\n",
       "2194  2300820    1281659\n",
       "\n",
       "[2195 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{2000029, 2002450}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 6, 1, 8, 7, 9, 5], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>cum_volume</th>\n",
       "      <th>cum_amount</th>\n",
       "      <th>volume</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2195</td>\n",
       "      <td>2000029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2196</td>\n",
       "      <td>2002450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         skey  cum_volume  cum_amount  volume  amount\n",
       "2195  2000029         NaN         NaN       0     0.0\n",
       "2196  2002450         NaN         NaN       0     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>cum_volume</th>\n",
       "      <th>cum_amount</th>\n",
       "      <th>volume</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2195</td>\n",
       "      <td>2000029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2196</td>\n",
       "      <td>2002450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         skey  cum_volume  cum_amount  volume  amount\n",
       "2195  2000029         NaN         NaN       0     0.0\n",
       "2196  2002450         NaN         NaN       0     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TradeLogSZ1['trade_money'] = TradeLogSZ1[\"trade_price\"] * TradeLogSZ1[\"trade_qty\"]\n",
    "# trade1 = TradeLogSZ1[TradeLogSZ1[\"trade_type\"] == 1].groupby(\"skey\")[\"trade_qty\"].sum().reset_index()\n",
    "# trade1.columns=[\"skey\", \"cum_volume\"]\n",
    "# trade2 = TradeLogSZ1[TradeLogSZ1[\"trade_type\"] == 1].groupby(\"skey\")[\"trade_money\"].sum().reset_index()\n",
    "# trade2.columns=[\"skey\", \"cum_amount\"]\n",
    "# re1 = pd.merge(trade1, trade2, on=\"skey\")\n",
    "re2 = check[['skey', 'volume', 'amount']]\n",
    "re2 = re2[re2['skey'] > 2000000]\n",
    "display(set(re1['skey']) - set(re2['skey']))\n",
    "display(set(re2['skey']) - set(re1['skey']))\n",
    "display(re1['cum_amount'].astype(str).apply(lambda x: len(x.split('.')[1])).unique())\n",
    "display(re2['amount'].astype(str).apply(lambda x: len(x.split('.')[1])).unique())\n",
    "re = pd.merge(re1, re2, on=['skey'], how='outer')\n",
    "display(re[re['cum_volume'] != re['volume']])\n",
    "re['cum_amount'] = re['cum_amount'].round(2)\n",
    "display(re[re['cum_amount'] != re['amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1.write('md_trade', TradeLogSZ1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skey                        int32\n",
       "date                        int32\n",
       "time                        int64\n",
       "clockAtArrival              int64\n",
       "datetime           datetime64[ns]\n",
       "ApplSeqNum                  int32\n",
       "trade_type                  int32\n",
       "trade_flag                  int32\n",
       "trade_price               float64\n",
       "trade_qty                   int32\n",
       "BidApplSeqNum               int32\n",
       "OfferApplSeqNum             int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TradeLogSZ1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skey                       int32\n",
      "date                       int32\n",
      "time                       int64\n",
      "clockAtArrival             int64\n",
      "datetime          datetime64[ns]\n",
      "ApplSeqNum                 int32\n",
      "order_side                 int32\n",
      "order_type                 int32\n",
      "order_price              float64\n",
      "order_qty                  int32\n",
      "dtype: object\n",
      "20200106\n",
      "order finished\n",
      "0:24:26.446792\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from unrar import rarfile\n",
    "import py7zr\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "year = \"2020\"\n",
    "startDate = \"0106\"\n",
    "endDate = \"0106\"\n",
    "df = []\n",
    "bad = []\n",
    "readPath = 'L:\\\\backup data\\\\' + year + '\\\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "\n",
    "for data in dataPathLs:\n",
    "    if len(np.array(glob.glob(data +'\\\\***'))) == 0:\n",
    "        continue\n",
    "    \n",
    "    if len(np.array(glob.glob(data +'\\\\pm_hq_order_spot.7z'))) == 1:\n",
    "        date = os.path.basename(data)\n",
    "        path = 'L:\\\\backup_data\\\\' + year \n",
    "        os.chdir(data)\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\am_hq_order_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\am_hq_order_spot.7z')\n",
    "            bad.append(data + '\\\\am_hq_order_spot.7z')\n",
    "            continue\n",
    "        path1 = path + '\\\\' + date\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\pm_hq_order_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\pm_hq_order_spot.7z')\n",
    "            bad.append(data + '\\\\pm_hq_order_spot.7z')\n",
    "            continue\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        \n",
    "        am_order = pd.read_table(path1 + '\\\\am_hq_order_spot.txt',header=None)\n",
    "        am_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "        pm_order = pd.read_table(path1 + '\\\\pm_hq_order_spot.txt',header=None)\n",
    "        pm_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "        OrderLog1 = pd.concat([am_order, pm_order])\n",
    "        del am_order\n",
    "        del pm_order\n",
    "  \n",
    "    \n",
    "    elif len(np.array(glob.glob(data +'\\\\pm_hq_order_spot.7z.001'))) == 1:\n",
    "        date = os.path.basename(data)\n",
    "        path = 'L:\\\\backup_data\\\\' + year \n",
    "        os.chdir(data)\n",
    "        os.system(\"copy /b am_hq_order_spot.7z.* am_hq_order_spot.7z\")\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\am_hq_order_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\am_hq_order_spot.7z')\n",
    "            bad.append(data + '\\\\am_hq_order_spot.7z')\n",
    "            continue\n",
    "        path1 = path + '\\\\' + date\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        os.system(\"copy /b pm_hq_order_spot.7z.* pm_hq_order_spot.7z\")\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\pm_hq_order_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\pm_hq_order_spot.7z')\n",
    "            bad.append(data + '\\\\pm_hq_order_spot.7z')\n",
    "            continue\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        \n",
    "        am_order = pd.read_table(path1 + '\\\\am_hq_order_spot.txt',header=None)\n",
    "        am_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "        pm_order = pd.read_table(path1 + '\\\\pm_hq_order_spot.txt',header=None)\n",
    "        pm_order.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "        OrderLog1 = pd.concat([am_order, pm_order])\n",
    "        del am_order\n",
    "        del pm_order\n",
    "\n",
    "    elif len(np.array(glob.glob(data +'\\\\hq_order.7z'))) == 1:\n",
    "        date = os.path.basename(data)\n",
    "        path = 'L:\\\\backup_data\\\\' + year \n",
    "        os.chdir(data)\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(data + '\\\\hq_order.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(data + '\\\\hq_order.7z')\n",
    "            bad.append(data + '\\\\hq_order.7z')\n",
    "            continue\n",
    "        path1 = path + '\\\\' + date\n",
    "        a.extractall(path = path1)\n",
    "        a.close()\n",
    "        OrderLog1 = pd.read_table(path1 + '\\\\hq_order.txt',header=None)\n",
    "        OrderLog1.columns = [\"date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"order_price\",\n",
    "                   \"order_qty\",\"TransactTime\",\"order_side\",\"order_type\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "    \n",
    "    \n",
    "    OrderLog1 = OrderLog1[(OrderLog1[\"SecurityID\"] < 4000) | (OrderLog1[\"SecurityID\"] > 300000)]\n",
    "    OrderLog1[\"skey\"] = OrderLog1[\"SecurityID\"] + 2000000\n",
    "    OrderLog1[\"clockAtArrival\"] = OrderLog1[\"TransactTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    OrderLog1['datetime'] = OrderLog1[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    OrderLog1[\"time\"] = (OrderLog1['TransactTime'] - int(OrderLog1['TransactTime'].iloc[0]//1000000000*1000000000)).astype(np.int64)*1000\n",
    "    OrderLog1[\"order_type\"] =np.where(OrderLog1[\"order_type\"] == 'U', 3, OrderLog1[\"order_type\"])\n",
    "    for col in [\"skey\", \"date\", \"ApplSeqNum\", \"order_qty\", \"order_side\", \"order_type\"]:\n",
    "        OrderLog1[col] = OrderLog1[col].astype('int32')\n",
    "    display(OrderLog1[\"order_price\"].astype(str).apply(lambda x: len(x.split('.')[1])).unique())\n",
    "    \n",
    "    assert(OrderLog1[((OrderLog1[\"order_side\"] != 1) & (OrderLog1[\"order_side\"] != 2)) | (OrderLog1[\"order_type\"].isnull())].shape[0] == 0)\n",
    "    \n",
    "    OrderLog1 = OrderLog1[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ApplSeqNum\", \"order_side\", \"order_type\", \"order_price\",\n",
    "                                                 \"order_qty\"]]\n",
    "    \n",
    "    print(OrderLog1.dtypes)\n",
    "    print(OrderLog1[\"date\"].iloc[0])\n",
    "    print(\"order finished\")\n",
    "    \n",
    "    print(datetime.datetime.now() - startTm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>clockAtArrival</th>\n",
       "      <th>datetime</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "      <th>trade_type</th>\n",
       "      <th>trade_flag</th>\n",
       "      <th>trade_price</th>\n",
       "      <th>trade_qty</th>\n",
       "      <th>BidApplSeqNum</th>\n",
       "      <th>OfferApplSeqNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150016</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>92500000000</td>\n",
       "      <td>1578273900000000</td>\n",
       "      <td>2020-01-06 09:25:00.000</td>\n",
       "      <td>295880</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.89</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>266119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150017</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>92500000000</td>\n",
       "      <td>1578273900000000</td>\n",
       "      <td>2020-01-06 09:25:00.000</td>\n",
       "      <td>295881</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.89</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>141266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150018</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>92500000000</td>\n",
       "      <td>1578273900000000</td>\n",
       "      <td>2020-01-06 09:25:00.000</td>\n",
       "      <td>295882</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.89</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>221586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238666</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>93000000000</td>\n",
       "      <td>1578274200000000</td>\n",
       "      <td>2020-01-06 09:30:00.000</td>\n",
       "      <td>317475</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.97</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>236319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238667</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>93000000000</td>\n",
       "      <td>1578274200000000</td>\n",
       "      <td>2020-01-06 09:30:00.000</td>\n",
       "      <td>317476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.05</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>234077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279276</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>93000230000</td>\n",
       "      <td>1578274200230000</td>\n",
       "      <td>2020-01-06 09:30:00.230</td>\n",
       "      <td>341180</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>500</td>\n",
       "      <td>662</td>\n",
       "      <td>341179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9110058</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>100001000000</td>\n",
       "      <td>1578276001000000</td>\n",
       "      <td>2020-01-06 10:00:01.000</td>\n",
       "      <td>5111624</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>400</td>\n",
       "      <td>2</td>\n",
       "      <td>5109328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9110059</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>100001000000</td>\n",
       "      <td>1578276001000000</td>\n",
       "      <td>2020-01-06 10:00:01.000</td>\n",
       "      <td>5111625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>5108650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9110060</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>100001000000</td>\n",
       "      <td>1578276001000000</td>\n",
       "      <td>2020-01-06 10:00:01.000</td>\n",
       "      <td>5111626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>5110614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9110061</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>100001000000</td>\n",
       "      <td>1578276001000000</td>\n",
       "      <td>2020-01-06 10:00:01.000</td>\n",
       "      <td>5111627</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>5106876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9110062</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>100001000000</td>\n",
       "      <td>1578276001000000</td>\n",
       "      <td>2020-01-06 10:00:01.000</td>\n",
       "      <td>5111628</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>5103582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9110063</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>100001000000</td>\n",
       "      <td>1578276001000000</td>\n",
       "      <td>2020-01-06 10:00:01.000</td>\n",
       "      <td>5111629</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>5108160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9110064</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>100001000000</td>\n",
       "      <td>1578276001000000</td>\n",
       "      <td>2020-01-06 10:00:01.000</td>\n",
       "      <td>5111630</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>5100097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9110065</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>100001000000</td>\n",
       "      <td>1578276001000000</td>\n",
       "      <td>2020-01-06 10:00:01.000</td>\n",
       "      <td>5111631</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>5100444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9110066</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>100001000000</td>\n",
       "      <td>1578276001000000</td>\n",
       "      <td>2020-01-06 10:00:01.000</td>\n",
       "      <td>5111632</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>5102019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9110067</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>100001000000</td>\n",
       "      <td>1578276001000000</td>\n",
       "      <td>2020-01-06 10:00:01.000</td>\n",
       "      <td>5111633</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>5102897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9110068</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>100001000000</td>\n",
       "      <td>1578276001000000</td>\n",
       "      <td>2020-01-06 10:00:01.000</td>\n",
       "      <td>5111634</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>5103263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9110069</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>100001000000</td>\n",
       "      <td>1578276001000000</td>\n",
       "      <td>2020-01-06 10:00:01.000</td>\n",
       "      <td>5111635</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>5103281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9110070</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>100001000000</td>\n",
       "      <td>1578276001000000</td>\n",
       "      <td>2020-01-06 10:00:01.000</td>\n",
       "      <td>5111636</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>5104592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9110071</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>100001000000</td>\n",
       "      <td>1578276001000000</td>\n",
       "      <td>2020-01-06 10:00:01.000</td>\n",
       "      <td>5111637</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>5105224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            skey      date          time    clockAtArrival  \\\n",
       "150016   2002973  20200106   92500000000  1578273900000000   \n",
       "150017   2002973  20200106   92500000000  1578273900000000   \n",
       "150018   2002973  20200106   92500000000  1578273900000000   \n",
       "238666   2002973  20200106   93000000000  1578274200000000   \n",
       "238667   2002973  20200106   93000000000  1578274200000000   \n",
       "279276   2002973  20200106   93000230000  1578274200230000   \n",
       "9110058  2002973  20200106  100001000000  1578276001000000   \n",
       "9110059  2002973  20200106  100001000000  1578276001000000   \n",
       "9110060  2002973  20200106  100001000000  1578276001000000   \n",
       "9110061  2002973  20200106  100001000000  1578276001000000   \n",
       "9110062  2002973  20200106  100001000000  1578276001000000   \n",
       "9110063  2002973  20200106  100001000000  1578276001000000   \n",
       "9110064  2002973  20200106  100001000000  1578276001000000   \n",
       "9110065  2002973  20200106  100001000000  1578276001000000   \n",
       "9110066  2002973  20200106  100001000000  1578276001000000   \n",
       "9110067  2002973  20200106  100001000000  1578276001000000   \n",
       "9110068  2002973  20200106  100001000000  1578276001000000   \n",
       "9110069  2002973  20200106  100001000000  1578276001000000   \n",
       "9110070  2002973  20200106  100001000000  1578276001000000   \n",
       "9110071  2002973  20200106  100001000000  1578276001000000   \n",
       "\n",
       "                       datetime  ApplSeqNum  trade_type  trade_flag  \\\n",
       "150016  2020-01-06 09:25:00.000      295880           1           0   \n",
       "150017  2020-01-06 09:25:00.000      295881           1           0   \n",
       "150018  2020-01-06 09:25:00.000      295882           1           0   \n",
       "238666  2020-01-06 09:30:00.000      317475           1           0   \n",
       "238667  2020-01-06 09:30:00.000      317476           1           0   \n",
       "279276  2020-01-06 09:30:00.230      341180           1           0   \n",
       "9110058 2020-01-06 10:00:01.000     5111624           1           0   \n",
       "9110059 2020-01-06 10:00:01.000     5111625           1           0   \n",
       "9110060 2020-01-06 10:00:01.000     5111626           1           0   \n",
       "9110061 2020-01-06 10:00:01.000     5111627           1           0   \n",
       "9110062 2020-01-06 10:00:01.000     5111628           1           0   \n",
       "9110063 2020-01-06 10:00:01.000     5111629           1           0   \n",
       "9110064 2020-01-06 10:00:01.000     5111630           1           0   \n",
       "9110065 2020-01-06 10:00:01.000     5111631           1           0   \n",
       "9110066 2020-01-06 10:00:01.000     5111632           1           0   \n",
       "9110067 2020-01-06 10:00:01.000     5111633           1           0   \n",
       "9110068 2020-01-06 10:00:01.000     5111634           1           0   \n",
       "9110069 2020-01-06 10:00:01.000     5111635           1           0   \n",
       "9110070 2020-01-06 10:00:01.000     5111636           1           0   \n",
       "9110071 2020-01-06 10:00:01.000     5111637           1           0   \n",
       "\n",
       "         trade_price  trade_qty  BidApplSeqNum  OfferApplSeqNum  \n",
       "150016          6.89        500              3           266119  \n",
       "150017          6.89        100              3           141266  \n",
       "150018          6.89        500              3           221586  \n",
       "238666          6.97        500             20           236319  \n",
       "238667          7.05        500             20           234077  \n",
       "279276          7.76        500            662           341179  \n",
       "9110058         8.27        400              2          5109328  \n",
       "9110059         8.27        500              2          5108650  \n",
       "9110060         8.27        500              2          5110614  \n",
       "9110061         8.27        500              2          5106876  \n",
       "9110062         8.27        500              2          5103582  \n",
       "9110063         8.27        500              2          5108160  \n",
       "9110064         8.27        500              2          5100097  \n",
       "9110065         8.27        500              2          5100444  \n",
       "9110066         8.27        500              2          5102019  \n",
       "9110067         8.27        500              2          5102897  \n",
       "9110068         8.27        500              2          5103263  \n",
       "9110069         8.27        500              2          5103281  \n",
       "9110070         8.27        500              2          5104592  \n",
       "9110071         8.27        500              2          5105224  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade[trade['trade_type'] == 1].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>clockAtArrival</th>\n",
       "      <th>datetime</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "      <th>order_side</th>\n",
       "      <th>order_type</th>\n",
       "      <th>order_price</th>\n",
       "      <th>order_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>91500000000</td>\n",
       "      <td>1578273300000000</td>\n",
       "      <td>2020-01-06 09:15:00</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.58</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        skey      date         time    clockAtArrival            datetime  \\\n",
       "115  2002973  20200106  91500000000  1578273300000000 2020-01-06 09:15:00   \n",
       "\n",
       "     ApplSeqNum  order_side  order_type  order_price  order_qty  \n",
       "115          20           1           2         7.58       1300  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order[order['ApplSeqNum'] == 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>clockAtArrival</th>\n",
       "      <th>datetime</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "      <th>order_side</th>\n",
       "      <th>order_type</th>\n",
       "      <th>order_price</th>\n",
       "      <th>order_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>978084</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>92405270000</td>\n",
       "      <td>1578273845270000</td>\n",
       "      <td>2020-01-06 09:24:05.270</td>\n",
       "      <td>236319</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.97</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           skey      date         time    clockAtArrival  \\\n",
       "978084  2002973  20200106  92405270000  1578273845270000   \n",
       "\n",
       "                      datetime  ApplSeqNum  order_side  order_type  \\\n",
       "978084 2020-01-06 09:24:05.270      236319           2           2   \n",
       "\n",
       "        order_price  order_qty  \n",
       "978084         6.97        500  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order[order['ApplSeqNum'] == 236319]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>clockAtArrival</th>\n",
       "      <th>datetime</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "      <th>order_side</th>\n",
       "      <th>order_type</th>\n",
       "      <th>order_price</th>\n",
       "      <th>order_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>968865</td>\n",
       "      <td>2002973</td>\n",
       "      <td>20200106</td>\n",
       "      <td>92359210000</td>\n",
       "      <td>1578273839210000</td>\n",
       "      <td>2020-01-06 09:23:59.210</td>\n",
       "      <td>234077</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7.05</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           skey      date         time    clockAtArrival  \\\n",
       "968865  2002973  20200106  92359210000  1578273839210000   \n",
       "\n",
       "                      datetime  ApplSeqNum  order_side  order_type  \\\n",
       "968865 2020-01-06 09:23:59.210      234077           2           2   \n",
       "\n",
       "        order_price  order_qty  \n",
       "968865         7.05        500  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order[order['ApplSeqNum'] == 234077]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
