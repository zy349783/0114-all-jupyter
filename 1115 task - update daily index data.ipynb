{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date    weight     skey  index_id index_name\n",
      "0    20201116  0.633867  1600000   1000300         IF\n",
      "1    20201116  0.089044  1600004   1000300         IF\n",
      "2    20201116  0.430911  1600009   1000300         IF\n",
      "3    20201116  0.157451  1600010   1000300         IF\n",
      "4    20201116  0.126769  1600011   1000300         IF\n",
      "..        ...       ...      ...       ...        ...\n",
      "295  20201116  0.285988  2300413   1000300         IF\n",
      "296  20201116  0.228365  2300433   1000300         IF\n",
      "297  20201116  0.498126  2300498   1000300         IF\n",
      "298  20201116  0.304329  2300601   1000300         IF\n",
      "299  20201116  0.109754  2300628   1000300         IF\n",
      "\n",
      "[300 rows x 5 columns]\n",
      "         date    weight     skey  index_id index_name\n",
      "0    20201116  0.093259  1600006   1000905         IC\n",
      "1    20201116  0.255017  1600008   1000905         IC\n",
      "2    20201116  0.102042  1600017   1000905         IC\n",
      "3    20201116  0.177064  1600021   1000905         IC\n",
      "4    20201116  0.151050  1600022   1000905         IC\n",
      "..        ...       ...      ...       ...        ...\n",
      "495  20201116  0.553837  2300496   1000905         IC\n",
      "496  20201116  0.408654  2300558   1000905         IC\n",
      "497  20201116  0.404731  2300595   1000905         IC\n",
      "498  20201116  0.209698  2300618   1000905         IC\n",
      "499  20201116  0.167824  2300630   1000905         IC\n",
      "\n",
      "[500 rows x 5 columns]\n",
      "         date    weight     skey  index_id index_name\n",
      "0    20201116  0.063103  1600020   1000852    CSI1000\n",
      "1    20201116  0.049945  1600035   1000852    CSI1000\n",
      "2    20201116  0.043710  1600054   1000852    CSI1000\n",
      "3    20201116  0.075121  1600055   1000852    CSI1000\n",
      "4    20201116  0.134523  1600057   1000852    CSI1000\n",
      "..        ...       ...      ...       ...        ...\n",
      "995  20201116  0.040769  2300799   1000852    CSI1000\n",
      "996  20201116  0.031941  2300800   1000852    CSI1000\n",
      "997  20201116  0.048249  2300803   1000852    CSI1000\n",
      "998  20201116  0.022484  2300805   1000852    CSI1000\n",
      "999  20201116  0.085183  2300815   1000852    CSI1000\n",
      "\n",
      "[1000 rows x 5 columns]\n",
      "          date    weight     skey  index_id index_name\n",
      "0     20201116  0.059392  1600007   1000985    CSIRest\n",
      "1     20201116  0.045773  1600012   1000985    CSIRest\n",
      "2     20201116  0.344448  1600023   1000985    CSIRest\n",
      "3     20201116  0.085738  1600033   1000985    CSIRest\n",
      "4     20201116  0.056812  1600051   1000985    CSIRest\n",
      "...        ...       ...      ...       ...        ...\n",
      "1598  20201116  0.022090  2300809   1000985    CSIRest\n",
      "1599  20201116  0.026548  2300810   1000985    CSIRest\n",
      "1600  20201116  0.027707  2300811   1000985    CSIRest\n",
      "1601  20201116  0.025713  2300812   1000985    CSIRest\n",
      "1602  20201116  0.019389  2300813   1000985    CSIRest\n",
      "\n",
      "[1603 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pyTSL\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    url = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    client = pymongo.MongoClient(url, maxPoolSize=None)\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def read_memb_daily(db, name, start_date=None, end_date=None, skey=None, index_id=None, interval=None, col=None, return_sdi=True):\n",
    "    collection = db[name]\n",
    "    # Build projection\n",
    "    prj = {'_id': 0}\n",
    "    if col is not None:\n",
    "        if return_sdi:\n",
    "            col = ['skey', 'date', 'interval'] + col\n",
    "        for col_name in col:\n",
    "            prj[col_name] = 1\n",
    "\n",
    "    # Build query\n",
    "    query = {}\n",
    "    if skey is not None:\n",
    "        query['skey'] = {'$in': skey}\n",
    "    if index_id is not None:\n",
    "        query['index_id'] = {'$in': index_id}\n",
    "    if interval is not None:\n",
    "        query['interval'] = {'$in': interval}\n",
    "    if start_date is not None:\n",
    "        if end_date is not None:\n",
    "            query['date'] = {'$gte': start_date, '$lte': end_date}\n",
    "        else:\n",
    "            query['date'] = {'$gte': start_date}\n",
    "    elif end_date is not None:\n",
    "        query['date'] = {'$lte': end_date}\n",
    "\n",
    "    # Load data\n",
    "    cur = collection.find(query, prj)\n",
    "    df = pd.DataFrame.from_records(cur)\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        df = df.sort_values(by=['date', 'index_id', 'skey'])\n",
    "    return df\n",
    "\n",
    "def build_query(start_date=None, end_date=None, index_id=None):\n",
    "    query = {}\n",
    "    def parse_date(x):\n",
    "        if type(x) == int:\n",
    "            return x\n",
    "        elif type(x) == str:\n",
    "            if len(x) != 8:\n",
    "                raise Exception(\"date must be YYYYMMDD format\")\n",
    "            return int(x)\n",
    "        elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "            return x.strftime(\"%Y%m%d\").astype(int)\n",
    "        else:\n",
    "            raise Exception(\"invalid date type: \" + str(type(x)))\n",
    "    if start_date is not None or end_date is not None:\n",
    "        query['date'] = {}\n",
    "        if start_date is not None:\n",
    "            query['date']['$gte'] = parse_date(start_date)\n",
    "        if end_date is not None:\n",
    "            query['date']['$lte'] = parse_date(end_date)\n",
    "    def parse_symbol(x):\n",
    "        if type(x) == int:\n",
    "            return x\n",
    "        else:\n",
    "            return int(x)\n",
    "    if index_id:\n",
    "        if type(index_id) == list or type(index_id) == tuple:\n",
    "            query['index_id'] = {'$in': [parse_symbol(x) for x in index_id]}\n",
    "        else:\n",
    "            query['index_id'] = parse_symbol(index_id)\n",
    "    return query\n",
    "\n",
    "def write_memb_data(db, name, df):\n",
    "    collection = db[name]\n",
    "    df1 = []\n",
    "    for symbol in df['index_id'].unique():\n",
    "        if symbol in collection.distinct('index_id'):\n",
    "            symbol = int(symbol)\n",
    "            m_ax = pd.DataFrame.from_records(collection.find({'index_id':{'$in':[symbol]}}).sort([('date',-1)]).skip(0).limit(1))['date'].values[0]\n",
    "            df2 = df[(df['index_id'] == symbol) & (df['date'] > m_ax)]\n",
    "            print(df2)\n",
    "            df1 += [df2]\n",
    "        else:\n",
    "            print(symbol)\n",
    "            df2 = df[(df['index_id'] == symbol)]\n",
    "            print(df2)\n",
    "            df1 += [df2]\n",
    "    df1 = pd.concat(df1).reset_index(drop=True)\n",
    "    df1 = df1.to_dict('records')\n",
    "    collection.insert_many(df1)\n",
    "\n",
    "def delete_memb_data(db, name, start_date=None, end_date=None, index_id=None):\n",
    "    collection = db[name]\n",
    "    query = build_query(start_date, end_date, index_id)\n",
    "    if not query:\n",
    "        print('cannot delete the whole table')\n",
    "        return None\n",
    "    collection.delete_many(query)\n",
    "\n",
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "\n",
    "pd.set_option('max_columns', 200)\n",
    "db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "\n",
    "## TR login in\n",
    "c = pyTSL.Client(\"jqtz\", \"+7.1q2w3e\", \"tsl.tinysoft.com\", 443) ##pyTSL.Client(TR.ini)\n",
    "c.login()\n",
    "assert c.login() == 1\n",
    "\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "import TSLPy3\n",
    "\n",
    "# startDate = datetime.datetime.today().strftime('%Y%m%d')\n",
    "# endDate = datetime.datetime.today().strftime('%Y%m%d')\n",
    "startDate = '20201116'\n",
    "endDate = '20201116'\n",
    "def download_index(startDate, endDate, indexCode):\n",
    "    tsstr = \"\"\"\n",
    "               indexTicker:= '{}';\n",
    "               BegT:= {};\n",
    "               EndT:= {} + 0.99;\n",
    "               dateArr:=MarketTradeDayQk(BegT,EndT);\n",
    "               r:=array();\n",
    "               for nI:=0 to length(dateArr)-1 do\n",
    "               begin\n",
    "                 GetBKWeightByDate(indexTicker,dateArr[nI],t);\n",
    "                 t := t[:,array(\"截止日\",\"代码\",\"比例(%)\")]; \n",
    "                 r:=r union t;\n",
    "               end;\n",
    "               return r;  \n",
    "            \"\"\".format(indexCode, startDate + 'T', endDate + 'T')\n",
    "    weight_table = pd.DataFrame(c.exec(tsstr).value())\n",
    "    weight_table.columns=['date','weight','ID']\n",
    "    weight_table['date'] = pd.to_datetime(weight_table.date.astype(str))\n",
    "    return weight_table\n",
    "IF_weight = download_index(startDate, endDate, 'SH000300')\n",
    "IC_weight = download_index(startDate, endDate, 'SH000905')\n",
    "CSI1000_weight = download_index(startDate, endDate, 'SH000852')\n",
    "weight_table = download_index(startDate, endDate, 'SH000985')\n",
    "\n",
    "CSIRest_weight = []\n",
    "for day in weight_table.date.unique():\n",
    "    IC_stock = list(IC_weight[IC_weight.date == day].ID.unique())\n",
    "    IF_stock = list(IF_weight[IF_weight.date == day].ID.unique())\n",
    "    CSI1000_stock = list(CSI1000_weight[CSI1000_weight.date == day].ID.unique())\n",
    "    ex_stock = list(set(IC_stock + IF_stock + CSI1000_stock))\n",
    "    assert len(ex_stock) == 1800\n",
    "    CSIRest_weight_day = weight_table[(weight_table.date == day) & (~weight_table.ID.isin(ex_stock))]\n",
    "    CSIRest_weight += [CSIRest_weight_day]\n",
    "CSIRest_weight = pd.concat(CSIRest_weight).reset_index(drop=True)\n",
    "sumWeightToday = CSIRest_weight.groupby('date')['weight'].sum().reset_index()\n",
    "sumWeightToday.rename(columns = {'weight':'sumWeightDay'}, inplace = True)\n",
    "weight_table = CSIRest_weight.merge(sumWeightToday, on = 'date', how = 'left')\n",
    "weight_table['weight'] = weight_table['weight'] / weight_table['sumWeightDay'] * 100\n",
    "weight_table = weight_table.drop(columns = {'sumWeightDay'})\n",
    "\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "import TSLPy3\n",
    "# IF_weight = pd.read_pickle(r'G:\\IF_weight.pkl')\n",
    "# IC_weight = pd.read_pickle(r'G:\\IC_weight.pkl')\n",
    "# CSI1000_weight = pd.read_pickle(r'G:\\CSI1000_weight.pkl')\n",
    "# weight_table = pd.read_pickle(r'G:\\CSIRest_weight.pkl')\n",
    "\n",
    "IF_weight['date'] = IF_weight['date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "IF_weight['ID'] = np.where(IF_weight['ID'].str[:2] =='SZ', IF_weight['ID'].str[2:].astype(int) + 2000000, IF_weight['ID'].str[2:].astype(int) + 1000000)\n",
    "IF_weight = IF_weight.rename(columns={'ID':'skey'})\n",
    "IF_weight['index_id'] = 1000300\n",
    "IF_weight['index_name'] = 'IF'\n",
    "IF_weight = IF_weight.sort_values(by=['date', 'skey']).reset_index(drop=True)\n",
    "k = IF_weight.groupby('date')['weight'].sum().reset_index()\n",
    "assert(k[k['weight'] - 100 > 0.02].shape[0] == 0)\n",
    "write_memb_data(db1, 'index_memb', IF_weight)\n",
    "\n",
    "IC_weight['date'] = IC_weight['date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "IC_weight['ID'] = np.where(IC_weight['ID'].str[:2] =='SZ', IC_weight['ID'].str[2:].astype(int) + 2000000, IC_weight['ID'].str[2:].astype(int) + 1000000)\n",
    "IC_weight = IC_weight.rename(columns={'ID':'skey'})\n",
    "IC_weight['index_id'] = 1000905\n",
    "IC_weight['index_name'] = 'IC'\n",
    "IC_weight = IC_weight.sort_values(by=['date', 'skey']).reset_index(drop=True)\n",
    "k = IC_weight.groupby('date')['weight'].sum().reset_index()\n",
    "assert(k[k['weight'] - 100 > 0.02].shape[0] == 0)\n",
    "write_memb_data(db1, 'index_memb', IC_weight)\n",
    "\n",
    "CSI1000_weight['date'] = CSI1000_weight['date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "CSI1000_weight['ID'] = np.where(CSI1000_weight['ID'].str[:2] =='SZ', CSI1000_weight['ID'].str[2:].astype(int) + 2000000, CSI1000_weight['ID'].str[2:].astype(int) + 1000000)\n",
    "CSI1000_weight = CSI1000_weight.rename(columns={'ID':'skey'})\n",
    "CSI1000_weight['index_id'] = 1000852\n",
    "CSI1000_weight['index_name'] = 'CSI1000'\n",
    "CSI1000_weight = CSI1000_weight.sort_values(by=['date', 'skey']).reset_index(drop=True)\n",
    "k = CSI1000_weight.groupby('date')['weight'].sum().reset_index()\n",
    "assert(k[k['weight'] - 100 > 0.02].shape[0] == 0)\n",
    "write_memb_data(db1, 'index_memb', CSI1000_weight)\n",
    "\n",
    "weight_table['date'] = weight_table['date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "weight_table['ID'] = np.where(weight_table['ID'].str[:2] =='SZ', weight_table['ID'].str[2:].astype(int) + 2000000, weight_table['ID'].str[2:].astype(int) + 1000000)\n",
    "weight_table = weight_table.rename(columns={'ID':'skey'})\n",
    "weight_table['index_id'] = 1000985\n",
    "weight_table['index_name'] = 'CSIRest'\n",
    "weight_table = weight_table.sort_values(by=['date', 'skey']).reset_index(drop=True)\n",
    "k = weight_table.groupby('date')['weight'].sum().reset_index()\n",
    "assert(k[k['weight'] - 100 > 0.02].shape[0] == 0)\n",
    "write_memb_data(db1, 'index_memb', weight_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_excel(r'D:\\work\\project 3 event study\\202012\\CSIRest_out_202012.xlsx')\n",
    "d1['skey'] = np.where(d1['Symbol'].str[:2] == 'SH', d1['Symbol'].str[2:].astype(int) + 1000000, d1['Symbol'].str[2:].astype(int) + 2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IF', 'IC', 'CSIRest', 'CSI1000'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pyTSL\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    url = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    client = pymongo.MongoClient(url, maxPoolSize=None)\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def read_stock_daily(db, name, start_date=None, end_date=None, skey=None, index_name=None, interval=None, col=None, return_sdi=True):\n",
    "    collection = db[name]\n",
    "    # Build projection\n",
    "    prj = {'_id': 0}\n",
    "    if col is not None:\n",
    "        if return_sdi:\n",
    "            col = ['skey', 'date', 'interval'] + col\n",
    "        for col_name in col:\n",
    "            prj[col_name] = 1\n",
    "\n",
    "    # Build query\n",
    "    query = {}\n",
    "    if skey is not None:\n",
    "        query['skey'] = {'$in': skey}\n",
    "    if index_name is not None:\n",
    "        query['index_name'] = {'$in': index_name}\n",
    "    if interval is not None:\n",
    "        query['interval'] = {'$in': interval}\n",
    "    if start_date is not None:\n",
    "        if end_date is not None:\n",
    "            query['date'] = {'$gte': start_date, '$lte': end_date}\n",
    "        else:\n",
    "            query['date'] = {'$gte': start_date}\n",
    "    elif end_date is not None:\n",
    "        query['date'] = {'$lte': end_date}\n",
    "\n",
    "    # Load data\n",
    "    cur = collection.find(query, prj)\n",
    "    df = pd.DataFrame.from_records(cur)\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        df = df.sort_values(by=['date', 'skey'])\n",
    "    return df\n",
    "\n",
    "def build_query(start_date=None, end_date=None, index_id=None):\n",
    "    query = {}\n",
    "    def parse_date(x):\n",
    "        if type(x) == int:\n",
    "            return x\n",
    "        elif type(x) == str:\n",
    "            if len(x) != 8:\n",
    "                raise Exception(\"date must be YYYYMMDD format\")\n",
    "            return int(x)\n",
    "        elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "            return x.strftime(\"%Y%m%d\").astype(int)\n",
    "        else:\n",
    "            raise Exception(\"invalid date type: \" + str(type(x)))\n",
    "    if start_date is not None or end_date is not None:\n",
    "        query['date'] = {}\n",
    "        if start_date is not None:\n",
    "            query['date']['$gte'] = parse_date(start_date)\n",
    "        if end_date is not None:\n",
    "            query['date']['$lte'] = parse_date(end_date)\n",
    "    def parse_symbol(x):\n",
    "        if type(x) == int:\n",
    "            return x\n",
    "        else:\n",
    "            return int(x)\n",
    "    if index_id:\n",
    "        if type(index_id) == list or type(index_id) == tuple:\n",
    "            query['index_id'] = {'$in': [parse_symbol(x) for x in index_id]}\n",
    "        else:\n",
    "            query['index_id'] = parse_symbol(index_id)\n",
    "    return query\n",
    "\n",
    "def write_memb_data(db, name, df):\n",
    "    collection = db[name]\n",
    "    df1 = []\n",
    "    for symbol in df['index_id'].unique():\n",
    "        if symbol in collection.distinct('index_id'):\n",
    "            symbol = int(symbol)\n",
    "            m_ax = pd.DataFrame.from_records(collection.find({'index_id':{'$in':[symbol]}}).sort([('date',-1)]).skip(0).limit(1))['date'].values[0]\n",
    "            df2 = df[(df['index_id'] == symbol) & (df['date'] > m_ax)]\n",
    "            print(df2)\n",
    "            df1 += [df2]\n",
    "        else:\n",
    "            print(symbol)\n",
    "            df2 = df[(df['index_id'] == symbol)]\n",
    "            print(df2)\n",
    "            df1 += [df2]\n",
    "    df1 = pd.concat(df1).reset_index(drop=True)\n",
    "    df1 = df1.to_dict('records')\n",
    "    collection.insert_many(df1)\n",
    "\n",
    "def delete_memb_data(db, name, start_date=None, end_date=None, index_id=None):\n",
    "    collection = db[name]\n",
    "    query = build_query(start_date, end_date, index_id)\n",
    "    if not query:\n",
    "        print('cannot delete the whole table')\n",
    "        return None\n",
    "    collection.delete_many(query)\n",
    "\n",
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "\n",
    "pd.set_option('max_columns', 200)\n",
    "db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "\n",
    "\n",
    "read_stock_daily(db1, 'index_memb', start_date=20201118, end_date=20201118)['index_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pyTSL.Client(\"jqtz\", \"+7.1q2w3e\", \"tsl.tinysoft.com\", 443) ##pyTSL.Client(TR.ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "登陆成功\n",
      "服务器设置: b''\n",
      "计算位数设置: 64\n",
      "数据: (0, b'return a string', None)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('C:\\\\Program Files\\\\Tinysoft\\\\Analyse.NET') \n",
    "import TSLPy3 as ts \n",
    "ts.ConnectServer(\"tsl.tinysoft.com.cn\",443)  \n",
    "dl = ts.LoginServer(\"jqtz\",\"+7.1q2w3e\") #Tuple(ErrNo,ErrMsg) 登陆用户 \n",
    "if dl[0]==0 :   \n",
    "    print(\"登陆成功\") \n",
    "    print(\"服务器设置:\",ts.GetService())   \n",
    "    ts.SetComputeBitsOption(64) #设置计算单位  \n",
    "    print(\"计算位数设置:\",ts.GetComputeBitsOption()) \n",
    "    data = ts.RemoteExecute(\"return 'return a string';\",{}) #执行一条语句  \n",
    "    print(\"数据:\",data) \n",
    "    ts.Disconnect() #断开连接 \n",
    "else:  print(dl[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
