{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n",
      "am & pm data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:187: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20200420 SZ lv2 check:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2203\n",
      "2203\n",
      "7122614\n",
      "7122614\n",
      "7122614\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SZE lv2 test is complete'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n",
      "am & pm data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20200421 SZ lv2 check:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2203\n",
      "2203\n",
      "7385615\n",
      "7385615\n",
      "7385615\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SZE lv2 test is complete'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n",
      "am & pm data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20200422 SZ lv2 check:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2210\n",
      "2210\n",
      "7272473\n",
      "7272473\n",
      "7272473\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SZE lv2 test is complete'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n",
      "am & pm data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20200423 SZ lv2 check:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2210\n",
      "2210\n",
      "7324036\n",
      "7324036\n",
      "7324036\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SZE lv2 test is complete'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n",
      "am & pm data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20200424 SZ lv2 check:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2210\n",
      "2210\n",
      "7439170\n",
      "7439170\n",
      "7439170\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SZE lv2 test is complete'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n",
      "am & pm data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20200427 SZ lv2 check:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2210\n",
      "2210\n",
      "7036837\n",
      "7036837\n",
      "7036837\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SZE lv2 test is complete'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n",
      "am & pm data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20200428 SZ lv2 check:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2210\n",
      "2210\n",
      "7339617\n",
      "7339617\n",
      "7339617\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SZE lv2 test is complete'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n",
      "am & pm data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20200429 SZ lv2 check:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2210\n",
      "2210\n",
      "6904537\n",
      "6904537\n",
      "6904537\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SZE lv2 test is complete'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n",
      "am & pm data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20200430 SZ lv2 check:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2210\n",
      "2210\n",
      "7242736\n",
      "7242736\n",
      "7242736\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SZE lv2 test is complete'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n",
      "am & pm data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20200506 SZ lv2 check:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2210\n",
      "2210\n",
      "7201651\n",
      "7201651\n",
      "7201651\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SZE lv2 test is complete'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n",
      "am & pm data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20200507 SZ lv2 check:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2210\n",
      "2210\n",
      "7061586\n",
      "7061586\n",
      "7061586\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SZE lv2 test is complete'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n",
      "am & pm data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20200508 SZ lv2 check:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2217\n",
      "2217\n",
      "7202223\n",
      "7202223\n",
      "7202223\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SZE lv2 test is complete'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Date      Data                 Condition Prob      Time\n",
      "0   0420  lv2 data  SZE lv2 test is complete    C  1.000000\n",
      "1   0421  lv2 data  SZE lv2 test is complete    C  1.000000\n",
      "2   0422  lv2 data  SZE lv2 test is complete    C  1.000000\n",
      "3   0423  lv2 data  SZE lv2 test is complete    C  1.000000\n",
      "4   0424  lv2 data  SZE lv2 test is complete    C  1.000000\n",
      "5   0427  lv2 data  SZE lv2 test is complete    C  1.000000\n",
      "6   0428  lv2 data  SZE lv2 test is complete    C  1.000000\n",
      "7   0429  lv2 data  SZE lv2 test is complete    C  1.000000\n",
      "8   0430  lv2 data  SZE lv2 test is complete    C  1.000000\n",
      "9   0506  lv2 data  SZE lv2 test is complete    C  0.999888\n",
      "10  0507  lv2 data  SZE lv2 test is complete    C  1.000000\n",
      "11  0508  lv2 data  SZE lv2 test is complete    C  1.000000\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import py7zr\n",
    "\n",
    "columns1 = [\"Date\",\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",\"PreClosePx\",\n",
    "                   \"PxChnage1\",\"PXChange2\",\"openPrice\",\"HighPx\",\"LowPx\",\"close\",\"NumTrades\",\"cum_volume\",\"cum_amount\",\"PE1\",\"PE2\",\"TradingPhase\",\n",
    "                   \"totalofferqty\", \"wa_offerPrice\", \"totalbidqty\", \"wa_bidPrice\", \"PreNAV\", \"RealTimeNAV\", \"WarrantPremiumRate\", \"UpLimitPx\",\n",
    "                   \"DownLimitPx\", \"TotalLongPosition\", \"unknown1\", \"unknown2\", \"unknown3\"]\n",
    "columns2 = ['Date',\"OrigTime\",\"SendTime\",\"ercvtime\",\"dbtime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\",'ask1p','bid1p',\n",
    "                   \"ask1q\",\"bid1q\", 'ask2p','bid2p',\"ask2q\",\"bid2q\",'ask3p','bid3p',\"ask3q\",\"bid3q\",'ask4p','bid4p',\"ask4q\",\"bid4q\",'ask5p',\n",
    "                    'bid5p',\"ask5q\",\"bid5q\",'ask6p','bid6p',\"ask6q\",\"bid6q\",'ask7p','bid7p',\"ask7q\",\"bid7q\",'ask8p','bid8p',\"ask8q\",\"bid8q\",\n",
    "                   'ask9p','bid9p',\"ask9q\",\"bid9q\",'ask10p','bid10p',\"ask10q\",\"bid10q\",\"NUMORDERS_B1\",\"NOORDERS_B1\",\"ORDERQTY_B1\",\n",
    "                    \"NUMORDERS_S1\",\"NOORDERS_S1\",\"ORDERQTY_S1\"]\n",
    "\n",
    "\n",
    "startDate = \"0418\"\n",
    "endDate = \"0508\"\n",
    "year = '2020'\n",
    "\n",
    "readPath = 'H:\\\\2020 data\\\\SZ\\\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "\n",
    "bad = []\n",
    "diff = {}\n",
    "for col in ['Date', 'Data', 'Condition', 'Prob', 'Time']:\n",
    "    diff[col] = []\n",
    "    \n",
    "    \n",
    "for p in dataPathLs:\n",
    "    print(\"*************************************************************************************************\")\n",
    "    if len(np.array(glob.glob(p +'\\\\***'))) == 0:\n",
    "        continue\n",
    "        \n",
    "    # am & pm\n",
    "    else:\n",
    "        os.chdir(p)\n",
    "        os.system(\"copy /b am_hq_snap_spot.7z.* am_hq_snap_spot.7z\")\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(p + '\\\\am_hq_snap_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(p + '\\\\am_hq_snap_spot.7z')\n",
    "            bad.append(p + '\\\\am_hq_snap_spot.7z')\n",
    "            continue\n",
    "        a.extractall(path = p)\n",
    "        a.close()\n",
    "        os.system(\"copy /b am_snap_level_spot.7z.* am_snap_level_spot.7z\")\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(p + '\\\\am_snap_level_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(p + '\\\\am_snap_level_spot.7z')\n",
    "            bad.append(p + '\\\\am_snap_level_spot.7z')\n",
    "            continue\n",
    "        a.extractall(path = p)\n",
    "        a.close()\n",
    "        os.system(\"copy /b pm_hq_snap_spot.7z.* pm_hq_snap_spot.7z\")\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(p + '\\\\pm_hq_snap_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(p + '\\\\pm_hq_snap_spot.7z')\n",
    "            bad.append(p + '\\\\pm_hq_snap_spot.7z')\n",
    "            continue\n",
    "        a.extractall(path = p)\n",
    "        a.close()\n",
    "        os.system(\"copy /b pm_snap_level_spot.7z.* pm_snap_level_spot.7z\")\n",
    "        try:\n",
    "            a = py7zr.SevenZipFile(p + '\\\\pm_snap_level_spot.7z','r',filters=None)\n",
    "        except:\n",
    "            print(\"Bad unzip here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(p + '\\\\pm_snap_level_spot.7z')\n",
    "            bad.append(p + '\\\\pm_snap_level_spot.7z')\n",
    "            continue\n",
    "        a.extractall(path = p)\n",
    "        a.close()\n",
    "\n",
    "        \n",
    "        am_snap1 = pd.read_table(p + \"\\\\am_hq_snap_spot.txt\", header=None)\n",
    "        assert(am_snap1.shape[1] == len(columns1))\n",
    "        am_snap1.columns = columns1\n",
    "        am_snap2 = pd.read_table(p + \"\\\\am_snap_level_spot.txt\",header=None)\n",
    "        assert(am_snap2.shape[1] == len(columns2))\n",
    "        am_snap2.columns = columns2\n",
    "        dd1 = int(am_snap2[\"OrigTime\"].iloc[0]//1000000000*1000000000) + 93000000\n",
    "        dd2 = int(am_snap2[\"OrigTime\"].iloc[0]//1000000000*1000000000) + 150000000\n",
    "        am = pd.merge(am_snap2, am_snap1, on=['Date',\"OrigTime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\"], how=\"outer\")\n",
    "        try:\n",
    "            assert((am.shape[0] == am_snap2.shape[0]) & (am.shape[0] == am_snap1.shape[0]) & (am_snap1.shape[0] == am_snap2.shape[0]))\n",
    "        except:\n",
    "            if am.shape[0] == am_snap1.shape[0]:\n",
    "                print(\"am_snap1 have more ticks than am_snap2\")\n",
    "                if all(am[(am[\"dbtime_x\"].isnull()) & ((am[\"SecurityID\"] < 4000) | (am[\"SecurityID\"] > 200000))][\"OrigTime\"].unique() < dd1):\n",
    "                    print(\"More ticks happens before 9:30\")\n",
    "                else:\n",
    "                    print(\"There are ticks happens after 9:30\")      \n",
    "            if am.shape[0] == am_snap2.shape[0]:\n",
    "                print(\"am_snap2 have more ticks than am_snap1\")\n",
    "                if all(am[(am[\"dbtime_y\"].isnull()) & ((am[\"SecurityID\"] < 4000) | (am[\"SecurityID\"] > 200000))][\"OrigTime\"].unique() < dd1):\n",
    "                    print(\"More ticks happens before 9:30\")\n",
    "                else:\n",
    "                    print(\"There are ticks happens after 9:30\")\n",
    "            else:\n",
    "                print(\"am_snap2 don't join with am_snap1\")\n",
    "            am = pd.merge(am_snap2, am_snap1, on=['Date',\"OrigTime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\"])       \n",
    "        del am_snap1\n",
    "        del am_snap2\n",
    "              \n",
    "        pm_snap1 = pd.read_table(p + \"\\\\pm_hq_snap_spot.txt\", header=None)\n",
    "        assert(pm_snap1.shape[1] == len(columns1))\n",
    "        pm_snap1.columns = columns1\n",
    "        pm_snap2 = pd.read_table(p + \"\\\\pm_snap_level_spot.txt\",header=None)\n",
    "        assert(pm_snap2.shape[1] == len(columns2))\n",
    "        pm_snap2.columns = columns2\n",
    "        pm = pd.merge(pm_snap2, pm_snap1, on=['Date',\"OrigTime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\"], how=\"outer\")\n",
    "        try:\n",
    "            assert((pm.shape[0] == pm_snap2.shape[0]) & (pm.shape[0] == pm_snap1.shape[0]) & (pm_snap1.shape[0] == pm_snap2.shape[0]))\n",
    "        except:\n",
    "            if pm.shape[0] == pm_snap1.shape[0]:\n",
    "                print(\"pm_snap1 have more ticks than pm_snap2\")\n",
    "                if all(pm[(pm[\"dbtime_x\"].isnull()) & ((pm[\"SecurityID\"] < 4000) | (pm[\"SecurityID\"] > 200000))][\"OrigTime\"].unique() > dd2):\n",
    "                    print(\"More ticks happens after 15:00\")\n",
    "                else:\n",
    "                    print(\"There are ticks happens before 15:00\")\n",
    "            if pm.shape[0] == pm_snap2.shape[0]:\n",
    "                print(\"pm_snap2 have more ticks than pm_snap1\")\n",
    "                if all(pm[(pm[\"dbtime_y\"].isnull()) & ((pm[\"SecurityID\"] < 4000) | (pm[\"SecurityID\"] > 200000))][\"OrigTime\"].unique() > dd2):\n",
    "                    print(\"More ticks happens after 15:00\")\n",
    "                else:\n",
    "                    print(\"There are ticks happens before 15:00\")\n",
    "            else:\n",
    "                print(\"pm_snap2 don't join with pm_snap1\")\n",
    "            pm = pd.merge(pm_snap2, pm_snap1, on=['Date',\"OrigTime\",\"ChannelNo\",\"SecurityID\",\"SecurityIDsource\", \"MDStreamID\"])   \n",
    "        del pm_snap1\n",
    "        del pm_snap2\n",
    "        snapshot = pd.concat([am, pm]).sort_values(by=[\"SecurityID\", \"OrigTime\"])\n",
    "        del am\n",
    "        del pm\n",
    "        snapshot = snapshot.rename(columns={\"SecurityID\":\"StockID\"})\n",
    "        snapshot = snapshot[(snapshot[\"StockID\"] < 4000) | (snapshot[\"StockID\"] > 200000)]\n",
    "        \n",
    "        print(\"am & pm data\")\n",
    "    \n",
    "    \n",
    "    path = \"\\\\\\\\192.168.10.30\\\\Kevin_zhenyu\\\\rawData\\\\logs_\" + \"2020\" + os.path.basename(p).split('.')[0] + \"_zs_92_01_day_data\\\\mdLog_SZ_***\" \n",
    "    if len(np.array(glob.glob(path))) == 0:\n",
    "        print(os.path.basename(p).split('.')[0])\n",
    "        print(\"92 SZE snapshot data is missing\")\n",
    "        continue\n",
    "    if len(np.array(glob.glob(path))) == 2:\n",
    "        logSZ11 = pd.read_csv(np.array(glob.glob(path))[0], encoding=\"utf-8\").loc[:, [\"clockAtArrival\", \"sequenceNo\", \"source\", \"StockID\",\n",
    "                                              \"exchange\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                                              \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\",\n",
    "                                              \"bid2q\", \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\",\n",
    "                                              \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "                                              \"ask4q\", \"ask5q\", \"openPrice\"]]\n",
    "        logSZ22 = pd.read_csv(np.array(glob.glob(path))[1], encoding=\"utf-8\").loc[:, [\"clockAtArrival\", \"sequenceNo\", \"source\", \"StockID\",\n",
    "                                              \"exchange\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                                              \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\",\n",
    "                                              \"bid2q\", \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\",\n",
    "                                              \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "                                              \"ask4q\", \"ask5q\", \"openPrice\"]]\n",
    "        logSZ = pd.concat([logSZ11, logSZ22])\n",
    "        del logSZ11\n",
    "        del logSZ22\n",
    "    else:\n",
    "        logSZ = pd.read_csv(np.array(glob.glob(path))[0], encoding=\"utf-8\").loc[:, [\"clockAtArrival\", \"sequenceNo\", \"source\", \"StockID\",\n",
    "                                              \"exchange\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                                              \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\",\n",
    "                                              \"bid2q\", \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\",\n",
    "                                              \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "                                              \"ask4q\", \"ask5q\", \"openPrice\"]]\n",
    "    \n",
    "    \n",
    "    logSZ[\"time\"] = logSZ[\"time\"].apply(lambda x: int((x.replace(':', \"\")).replace(\".\", \"\")))\n",
    "    sl = logSZ[\"StockID\"].unique()\n",
    "    logSZ1 = snapshot\n",
    "    logSZ1 = logSZ1[logSZ1[\"StockID\"].isin(sl)]\n",
    "    dd = int(logSZ1[\"OrigTime\"].iloc[0]//1000000000 * 1000000000)\n",
    "    logSZ1['time'] = (logSZ1['OrigTime'] - dd).astype(int)\n",
    "    \n",
    "    # lv2 data comparison\n",
    "    display(year + os.path.basename(p).split('.')[0] + \" SZ lv2 check:\")\n",
    "    data1 = logSZ[(logSZ[\"time\"] > 92500000) & (logSZ[\"time\"] < 145700000) & (logSZ[\"source\"] == 4)]\n",
    "    data2 = logSZ1[(logSZ1[\"time\"] > 92500000) & (logSZ1[\"time\"] < 145700000)]\n",
    "    columns = [\"StockID\", \"cum_volume\", \"cum_amount\", \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "           \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "           \"ask4q\", \"ask5q\", \"openPrice\"]\n",
    "    data1_1 = data1.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    del data1\n",
    "    data2_1 = data2.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    del data2\n",
    "    n1 = len(data1_1[\"StockID\"].unique())\n",
    "    n2 = len(data2_1[\"StockID\"].unique())\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    if n1 > n2:\n",
    "        data1_1 = data1_1[data1_1[\"StockID\"].isin(data2_1[\"StockID\"].unique())]\n",
    "    if n2 > n1:\n",
    "        data2_1 = data2_1[data2_1[\"StockID\"].isin(data1_1[\"StockID\"].unique())]\n",
    "    \n",
    "    data1_1[\"cum_amount\"] = data1_1[\"cum_amount\"].round(2)\n",
    "    data2_1[\"cum_amount\"] = data2_1[\"cum_amount\"].round(2)\n",
    "    test = pd.merge(data1_1, data2_1, left_on=columns, right_on=columns, how=\"outer\")\n",
    "    n1 = test[\"time_x\"].count()\n",
    "    n2 = test[\"time_y\"].count()\n",
    "    len1 = len(test)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    diff[\"Date\"].append(os.path.basename(p).split('.')[0])\n",
    "    diff[\"Data\"].append(\"lv2 data\")\n",
    "    re = test[(~np.isnan(test[\"time_y\"]))&(~np.isnan(test[\"time_x\"]))]\n",
    "    diff[\"Time\"].append(re[re[\"time_x\"] == re[\"time_y\"]].shape[0]/re.shape[0])\n",
    "    if n2 < len1:\n",
    "        display(\"SZE lv2 test is not complete:\")\n",
    "        display(test[np.isnan(test[\"time_y\"])])\n",
    "        print(len(test[np.isnan(test[\"time_y\"])])/n1)\n",
    "        print(test[np.isnan(test[\"time_y\"])][\"time_x\"].unique())\n",
    "        print(test[np.isnan(test[\"time_y\"])][\"StockID\"].unique())\n",
    "        diff[\"Condition\"].append(\"SZE lv2 test is not complete\")\n",
    "        diff[\"Prob\"].append(len(test[np.isnan(test[\"time_y\"])])/n1)\n",
    "    if len1 == n2:\n",
    "        display(\"SZE lv2 test is complete\")\n",
    "        diff[\"Condition\"].append(\"SZE lv2 test is complete\")\n",
    "        diff[\"Prob\"].append('C')\n",
    "    \n",
    "    \n",
    "#     # SZ trade data comparison\n",
    "#     display(year + os.path.basename(p) + \" SZ trade check:\")\n",
    "#     am_trade = pd.read_table(path3[i],header=None)\n",
    "#     am_trade.columns = [\"Date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"BidApplSeqNum\",\n",
    "#                    \"OfferApplSeqNum\",\"TradePrice\",\"TradeQty\",\"ExecType\",\"TransactTime\"]\n",
    "#     pm_trade = pd.read_table(path4[i],header=None)\n",
    "#     pm_trade.columns = [\"Date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"BidApplSeqNum\", \n",
    "#                         \"OfferApplSeqNum\",\"TradePrice\",\"TradeQty\",\"ExecType\",\"TransactTime\"]\n",
    "#     # ---------------------------load 92 data here----------------------------------------------------\n",
    "#     TradeLog = pd.read_csv(r'D:\\work\\project 13 lv2 data check\\logs_20190315_zs_92_01_day_data\\mdTradeLog_20190315_0857.csv',\n",
    "#                     encoding=\"utf-8\").loc[:, [\"clockAtArrival\", \"sequenceNo\", \"exchId\", \"TransactTime\",\n",
    "#                                                  \"ApplSeqNum\", \"SecurityID\", \"ExecType\", \"TradeBSFlag\",\n",
    "#                                                  \"TradePrice\", \"TradeQty\", \"TradeMoney\", \"BidApplSeqNum\",\n",
    "#                                                  \"OfferApplSeqNum\"]]\n",
    "#     TradeLogSZ = TradeLog[TradeLog[\"exchId\"] != 1]\n",
    "#     del TradeLog\n",
    "#     sl = TradeLogSZ[\"SecurityID\"].unique()\n",
    "#     am_trade = am_trade[am_trade[\"SecurityID\"].isin(sl)]\n",
    "#     pm_trade = pm_trade[pm_trade[\"SecurityID\"].isin(sl)]\n",
    "#     TradeLogSZ1 = pd.concat([am_trade, pm_trade])[[\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"BidApplSeqNum\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\\\n",
    "#                    \"OfferApplSeqNum\",\"TradePrice\",\"TradeQty\",\"ExecType\",\"TransactTime\"]]\n",
    "#     del am_trade\n",
    "#     del pm_trade\n",
    "#     TradeLogSZ1[\"TransactTime\"] = TradeLogSZ1[\"TransactTime\"] - 20190315000000000 \n",
    "#     TradeLogSZ[\"ExecType\"] = TradeLogSZ[\"ExecType\"].apply(lambda x: str(x))\n",
    "#     TradeLogSZ1[\"ExecType\"] = TradeLogSZ1[\"ExecType\"].apply(lambda x: str(x))\n",
    "\n",
    "#     columns = [\"TransactTime\",\"ApplSeqNum\", \"SecurityID\", \"ExecType\", \"TradeQty\",\"BidApplSeqNum\",\"OfferApplSeqNum\"]\n",
    "#     n1 = len(TradeLogSZ[\"SecurityID\"].unique())\n",
    "#     n2 = len(TradeLogSZ1[\"SecurityID\"].unique())\n",
    "#     if n1 > n2:\n",
    "#         TradeLogSZ = TradeLogSZ[TradeLogSZ[\"SecurityID\"].isin(TradeLogSZ1[\"SecurityID\"].unique())]\n",
    "#     if n2 > n1:\n",
    "#         TradeLogSZ1 = TradeLogSZ1[TradeLogSZ1[\"SecurityID\"].isin(TradeLogSZ[\"SecurityID\"].unique())]\n",
    "#     re = pd.merge(TradeLogSZ, TradeLogSZ1, left_on=columns, right_on=columns, how=\"outer\", validate='one_to_one')\n",
    "#     n1 = re[\"sequenceNo\"].count()\n",
    "#     n2 = re[\"OrigTime\"].count()\n",
    "#     len1 = len(re)\n",
    "#     print(n1)\n",
    "#     print(n2)\n",
    "#     print(len1)\n",
    "#     print(\"-----------------------------------------------\")\n",
    "#     if n2 < len1:\n",
    "#         display(\"SZE trade test is not complete:\")\n",
    "#         display(re[np.isnan(re[\"OrigTime\"])])\n",
    "#         print(len(re[np.isnan(re[\"OrigTime\"])]))\n",
    "#         print(np.sort(re[np.isnan(re[\"OrigTime\"])][\"TransactTime\"].unique()))\n",
    "#         print(len(re[np.isnan(re[\"OrigTime\"])][\"SecurityID\"].unique()))\n",
    "#         print(re[np.isnan(re[\"OrigTime\"])][\"SecurityID\"].unique())\n",
    "#     if (len1 == n2) & (n1 < len1):\n",
    "#         display(\"SZE trade baseline is not complete:\")\n",
    "#         display(re[np.isnan(re[\"sequenceNo\"])])\n",
    "#         print(np.sort(re[np.isnan(re[\"sequenceNo\"])][\"TransactTime\"].unique()))\n",
    "#         print(len(re[np.isnan(re[\"sequenceNo\"])][\"SecurityID\"].unique()))\n",
    "#         print(re[np.isnan(re[\"sequenceNo\"])][\"SecurityID\"].unique())\n",
    "#         display(n2-n1)\n",
    "#     if (len1 == n2) & (len1 == n1):\n",
    "#         display(\"SZE trade baseline and test exactly same\")\n",
    "#     del TradeLogSZ\n",
    "#     del TradeLogSZ1\n",
    "#     del re\n",
    "    \n",
    "#     # SZ order data comparison\n",
    "#     display(year + os.path.basename(p) + \" SZ order check:\")\n",
    "#     am_order = pd.read_table(r\"\\\\192.168.10.30\\Kevin_zhenyu\\exchange data\\LEVEL2_shenzhen\\0315\\am_hq_order_spot\\am_hq_order_spot.txt\",header=None)\n",
    "#     am_order.columns = [\"Date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"Price\",\n",
    "#                    \"OrderQty\",\"TransactTime\",\"Side\",\"OrderType\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "#     pm_order = pd.read_table(r\"\\\\192.168.10.30\\Kevin_zhenyu\\exchange data\\LEVEL2_shenzhen\\0315\\pm_hq_order_spot\\pm_hq_order_spot.txt\",header=None)\n",
    "#     pm_order.columns = [\"Date\",\"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ChannelNo\",\"MDStreamID\",\"ApplSeqNum\", \"SecurityID\",\"SecurityIDSource\", \"Price\",\n",
    "#                    \"OrderQty\",\"TransactTime\",\"Side\",\"OrderType\",\"ConfirmID\",\"Contactor\",\"ContactInfo\",\"ExpirationDays\",\"ExpirationType\"]\n",
    "\n",
    "#     # ---------------------------load 92 data here----------------------------------------------------\n",
    "#     OrderLog = pd.read_csv(r'D:\\work\\project 13 lv2 data check\\logs_20190315_zs_92_01_day_data\\mdOrderLog_20190315_0857.csv',\n",
    "#                     encoding=\"utf-8\").loc[:, [\"clockAtArrival\", \"sequenceNo\", \"exchId\", \"TransactTime\",\n",
    "#                                                  \"ApplSeqNum\", \"SecurityID\", \"Side\", \"OrderType\", \"Price\",\n",
    "#                                                  \"OrderQty\"]]\n",
    "#     sl = OrderLog[\"SecurityID\"].unique()\n",
    "#     am_order = am_order[am_order[\"SecurityID\"].isin(sl)]\n",
    "#     pm_order = pm_order[pm_order[\"SecurityID\"].isin(sl)]\n",
    "#     OrderLog1 = pd.concat([am_order, pm_order])[[\"TransactTime\", \"OrigTime\",\"SendTime\",\"recvtime\",\"dbtime\",\"ApplSeqNum\",\"Side\",'OrderType', 'Price', 'OrderQty', \"SecurityID\"]]\n",
    "#     del am_order\n",
    "#     del pm_order\n",
    "#     OrderLog1[\"TransactTime\"] = OrderLog1[\"TransactTime\"] - 20190315000000000\n",
    "    \n",
    "#     OrderLog[\"OrderType\"] = OrderLog[\"OrderType\"].apply(lambda x: str(x))\n",
    "#     OrderLog1[\"OrderType\"] = OrderLog1[\"OrderType\"].apply(lambda x: str(x))\n",
    "#     columns = [\"TransactTime\", \"ApplSeqNum\",\"Side\",'OrderType', 'OrderQty', \"SecurityID\"]\n",
    "#     n1 = len(OrderLog[\"SecurityID\"].unique())\n",
    "#     n2 = len(OrderLog1[\"SecurityID\"].unique())\n",
    "#     if n1 > n2:\n",
    "#         OrderLog = OrderLog[OrderLog[\"SecurityID\"].isin(OrderLog1[\"SecurityID\"].unique())]\n",
    "#     if n2 > n1:\n",
    "#         OrderLog1 = OrderLog1[OrderLog1[\"SecurityID\"].isin(OrderLog[\"SecurityID\"].unique())]\n",
    "#     ree = pd.merge(OrderLog, OrderLog1, left_on=columns, right_on=columns, how=\"outer\", validate='one_to_one')\n",
    "#     n1 = ree[\"sequenceNo\"].count()\n",
    "#     n2 = ree[\"OrigTime\"].count()\n",
    "#     len1 = len(ree)\n",
    "#     print(n1)\n",
    "#     print(n2)\n",
    "#     print(len1)\n",
    "#     print(\"-----------------------------------------------\")\n",
    "#     if n2 < len1:\n",
    "#         display(\"SZE order test is not complete:\")\n",
    "#         display(ree[np.isnan(ree[\"OrigTime\"])])\n",
    "#         print(len(ree[np.isnan(ree[\"OrigTime\"])]))\n",
    "#         print(np.sort(ree[np.isnan(ree[\"OrigTime\"])][\"TransactTime\"].unique()))\n",
    "#         print(len(ree[np.isnan(ree[\"OrigTime\"])][\"SecurityID\"].unique()))\n",
    "#         print(ree[np.isnan(ree[\"OrigTime\"])][\"SecurityID\"].unique())\n",
    "#     if (len1 == n2) & (n1 < len1):\n",
    "#         display(\"SZE order test is complete, baseline is not complete:\")\n",
    "#         display(ree[np.isnan(ree[\"sequenceNo\"])])\n",
    "#         print(np.sort(ree[np.isnan(ree[\"sequenceNo\"])][\"TransactTime\"].unique()))\n",
    "#         print(len(ree[np.isnan(ree[\"sequenceNo\"])][\"SecurityID\"].unique()))\n",
    "#         print(ree[np.isnan(ree[\"sequenceNo\"])][\"SecurityID\"].unique())\n",
    "#         display(n2-n1)\n",
    "#     if (len1 == n2) & (len1 == n1):\n",
    "#         display(\"SZE order baseline and test exactly same\")\n",
    "#     del OrderLog\n",
    "#     del OrderLog1\n",
    "#     del ree\n",
    "\n",
    "diff = pd.DataFrame(diff)\n",
    "diff.to_csv(\"F:\\\\SZ4.csv\")\n",
    "print(diff)\n",
    "print(bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Date      Data                 Condition Prob  Time\n",
      "0   0309  lv2 data  SZE lv2 test is complete    C   1.0\n",
      "1   0310  lv2 data  SZE lv2 test is complete    C   1.0\n",
      "2   0311  lv2 data  SZE lv2 test is complete    C   1.0\n",
      "3   0312  lv2 data  SZE lv2 test is complete    C   1.0\n",
      "4   0313  lv2 data  SZE lv2 test is complete    C   1.0\n",
      "5   0316  lv2 data  SZE lv2 test is complete    C   1.0\n",
      "6   0317  lv2 data  SZE lv2 test is complete    C   1.0\n",
      "7   0318  lv2 data  SZE lv2 test is complete    C   1.0\n",
      "8   0319  lv2 data  SZE lv2 test is complete    C   1.0\n",
      "9   0320  lv2 data  SZE lv2 test is complete    C   1.0\n",
      "10  0323  lv2 data  SZE lv2 test is complete    C   1.0\n",
      "11  0324  lv2 data  SZE lv2 test is complete    C   1.0\n",
      "12  0325  lv2 data  SZE lv2 test is complete    C   1.0\n",
      "13  0326  lv2 data  SZE lv2 test is complete    C   1.0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "diff = pd.DataFrame(diff)\n",
    "diff.to_csv(\"F:\\\\SZ3.csv\")\n",
    "print(diff)\n",
    "print(bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20190314 SZ lv2 check:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2133\n",
      "2133\n",
      "7776531\n",
      "7699612\n",
      "7776531\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SZE lv2 test is not complete:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>clockAtArrival</th>\n",
       "      <th>sequenceNo</th>\n",
       "      <th>source</th>\n",
       "      <th>StockID</th>\n",
       "      <th>exchange</th>\n",
       "      <th>time_x</th>\n",
       "      <th>cum_volume</th>\n",
       "      <th>cum_amount</th>\n",
       "      <th>close</th>\n",
       "      <th>...</th>\n",
       "      <th>wa_bidPrice</th>\n",
       "      <th>PreNAV</th>\n",
       "      <th>RealTimeNAV</th>\n",
       "      <th>WarrantPremiumRate</th>\n",
       "      <th>UpLimitPx</th>\n",
       "      <th>DownLimitPx</th>\n",
       "      <th>TotalLongPosition</th>\n",
       "      <th>unknown1</th>\n",
       "      <th>unknown2</th>\n",
       "      <th>unknown3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>395386</td>\n",
       "      <td>1059130</td>\n",
       "      <td>1552527608238742</td>\n",
       "      <td>14819211</td>\n",
       "      <td>4</td>\n",
       "      <td>300662</td>\n",
       "      <td>SZ</td>\n",
       "      <td>93948000</td>\n",
       "      <td>247312</td>\n",
       "      <td>9414215.72</td>\n",
       "      <td>38.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395387</td>\n",
       "      <td>1059131</td>\n",
       "      <td>1552527608238754</td>\n",
       "      <td>14819212</td>\n",
       "      <td>4</td>\n",
       "      <td>300667</td>\n",
       "      <td>SZ</td>\n",
       "      <td>93948000</td>\n",
       "      <td>2513900</td>\n",
       "      <td>86681920.50</td>\n",
       "      <td>33.67</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395388</td>\n",
       "      <td>1059132</td>\n",
       "      <td>1552527608238767</td>\n",
       "      <td>14819213</td>\n",
       "      <td>4</td>\n",
       "      <td>300680</td>\n",
       "      <td>SZ</td>\n",
       "      <td>93948000</td>\n",
       "      <td>108200</td>\n",
       "      <td>2044703.00</td>\n",
       "      <td>18.95</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395389</td>\n",
       "      <td>1059133</td>\n",
       "      <td>1552527608238773</td>\n",
       "      <td>14819214</td>\n",
       "      <td>4</td>\n",
       "      <td>300683</td>\n",
       "      <td>SZ</td>\n",
       "      <td>93948000</td>\n",
       "      <td>129000</td>\n",
       "      <td>4082509.00</td>\n",
       "      <td>31.69</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395390</td>\n",
       "      <td>1059134</td>\n",
       "      <td>1552527608238795</td>\n",
       "      <td>14819215</td>\n",
       "      <td>4</td>\n",
       "      <td>300684</td>\n",
       "      <td>SZ</td>\n",
       "      <td>93948000</td>\n",
       "      <td>343900</td>\n",
       "      <td>13478452.60</td>\n",
       "      <td>39.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472400</td>\n",
       "      <td>1216176</td>\n",
       "      <td>1552527728275987</td>\n",
       "      <td>16615602</td>\n",
       "      <td>4</td>\n",
       "      <td>300747</td>\n",
       "      <td>SZ</td>\n",
       "      <td>94148000</td>\n",
       "      <td>302034</td>\n",
       "      <td>51923472.72</td>\n",
       "      <td>171.80</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472401</td>\n",
       "      <td>1216177</td>\n",
       "      <td>1552527728275995</td>\n",
       "      <td>16615603</td>\n",
       "      <td>4</td>\n",
       "      <td>300750</td>\n",
       "      <td>SZ</td>\n",
       "      <td>94148000</td>\n",
       "      <td>657737</td>\n",
       "      <td>57985464.62</td>\n",
       "      <td>88.35</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472402</td>\n",
       "      <td>1216178</td>\n",
       "      <td>1552527728276000</td>\n",
       "      <td>16615604</td>\n",
       "      <td>4</td>\n",
       "      <td>300751</td>\n",
       "      <td>SZ</td>\n",
       "      <td>94148000</td>\n",
       "      <td>109500</td>\n",
       "      <td>18225430.00</td>\n",
       "      <td>167.92</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472403</td>\n",
       "      <td>1216180</td>\n",
       "      <td>1552527728276017</td>\n",
       "      <td>16615606</td>\n",
       "      <td>4</td>\n",
       "      <td>300758</td>\n",
       "      <td>SZ</td>\n",
       "      <td>94148000</td>\n",
       "      <td>731200</td>\n",
       "      <td>37034994.72</td>\n",
       "      <td>50.50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472404</td>\n",
       "      <td>1216181</td>\n",
       "      <td>1552527728276022</td>\n",
       "      <td>16615607</td>\n",
       "      <td>4</td>\n",
       "      <td>300760</td>\n",
       "      <td>SZ</td>\n",
       "      <td>94148000</td>\n",
       "      <td>340117</td>\n",
       "      <td>43662997.00</td>\n",
       "      <td>128.80</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76919 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index_x    clockAtArrival  sequenceNo  source  StockID exchange  \\\n",
       "395386  1059130  1552527608238742    14819211       4   300662       SZ   \n",
       "395387  1059131  1552527608238754    14819212       4   300667       SZ   \n",
       "395388  1059132  1552527608238767    14819213       4   300680       SZ   \n",
       "395389  1059133  1552527608238773    14819214       4   300683       SZ   \n",
       "395390  1059134  1552527608238795    14819215       4   300684       SZ   \n",
       "...         ...               ...         ...     ...      ...      ...   \n",
       "472400  1216176  1552527728275987    16615602       4   300747       SZ   \n",
       "472401  1216177  1552527728275995    16615603       4   300750       SZ   \n",
       "472402  1216178  1552527728276000    16615604       4   300751       SZ   \n",
       "472403  1216180  1552527728276017    16615606       4   300758       SZ   \n",
       "472404  1216181  1552527728276022    16615607       4   300760       SZ   \n",
       "\n",
       "          time_x  cum_volume   cum_amount   close  ...  wa_bidPrice  PreNAV  \\\n",
       "395386  93948000      247312   9414215.72   38.03  ...          NaN     NaN   \n",
       "395387  93948000     2513900  86681920.50   33.67  ...          NaN     NaN   \n",
       "395388  93948000      108200   2044703.00   18.95  ...          NaN     NaN   \n",
       "395389  93948000      129000   4082509.00   31.69  ...          NaN     NaN   \n",
       "395390  93948000      343900  13478452.60   39.00  ...          NaN     NaN   \n",
       "...          ...         ...          ...     ...  ...          ...     ...   \n",
       "472400  94148000      302034  51923472.72  171.80  ...          NaN     NaN   \n",
       "472401  94148000      657737  57985464.62   88.35  ...          NaN     NaN   \n",
       "472402  94148000      109500  18225430.00  167.92  ...          NaN     NaN   \n",
       "472403  94148000      731200  37034994.72   50.50  ...          NaN     NaN   \n",
       "472404  94148000      340117  43662997.00  128.80  ...          NaN     NaN   \n",
       "\n",
       "        RealTimeNAV  WarrantPremiumRate  UpLimitPx  DownLimitPx  \\\n",
       "395386          NaN                 NaN        NaN          NaN   \n",
       "395387          NaN                 NaN        NaN          NaN   \n",
       "395388          NaN                 NaN        NaN          NaN   \n",
       "395389          NaN                 NaN        NaN          NaN   \n",
       "395390          NaN                 NaN        NaN          NaN   \n",
       "...             ...                 ...        ...          ...   \n",
       "472400          NaN                 NaN        NaN          NaN   \n",
       "472401          NaN                 NaN        NaN          NaN   \n",
       "472402          NaN                 NaN        NaN          NaN   \n",
       "472403          NaN                 NaN        NaN          NaN   \n",
       "472404          NaN                 NaN        NaN          NaN   \n",
       "\n",
       "        TotalLongPosition  unknown1  unknown2  unknown3  \n",
       "395386                NaN       NaN       NaN       NaN  \n",
       "395387                NaN       NaN       NaN       NaN  \n",
       "395388                NaN       NaN       NaN       NaN  \n",
       "395389                NaN       NaN       NaN       NaN  \n",
       "395390                NaN       NaN       NaN       NaN  \n",
       "...                   ...       ...       ...       ...  \n",
       "472400                NaN       NaN       NaN       NaN  \n",
       "472401                NaN       NaN       NaN       NaN  \n",
       "472402                NaN       NaN       NaN       NaN  \n",
       "472403                NaN       NaN       NaN       NaN  \n",
       "472404                NaN       NaN       NaN       NaN  \n",
       "\n",
       "[76919 rows x 92 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009891171269040142\n",
      "[93948000 93951000 93954000 93957000 94000000 94003000 94006000 94009000\n",
      " 94012000 94015000 94018000 94021000 94024000 94027000 94030000 94033000\n",
      " 94036000 94039000 94042000 94045000 94048000 94051000 94054000 94057000\n",
      " 94100000 94103000 94106000 94109000 94112000 94115000 94118000 94121000\n",
      " 94124000 94127000 94130000 94133000 94136000 94139000 94142000 94145000\n",
      " 94148000]\n",
      "[300662 300667 300680 ...    428 300013   2855]\n",
      "*************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20190314(æ·±äº¤æ‰€æ•°æ®) SZ lv2 check:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2133\n",
      "2133\n",
      "7776531\n",
      "7776531\n",
      "7776531\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SZE lv2 test is complete'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date      Data                     Condition        Prob     Time\n",
      "0         0314  lv2 data  SZE lv2 test is not complete  0.00989117  0.99971\n",
      "1  0314(æ·±äº¤æ‰€æ•°æ®)  lv2 data      SZE lv2 test is complete           C  0.99983\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "\n",
    "year = \"2019\"\n",
    "startDate = \"0314\"\n",
    "endDate = \"0315\"\n",
    "\n",
    "readPath = 'E:\\\\SZ\\\\' + year + '\\\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs < endDate)]\n",
    "\n",
    "\n",
    "diff = {}\n",
    "for col in ['Date', 'Data', 'Condition', 'Prob', 'Time']:\n",
    "    diff[col] = []\n",
    "    \n",
    "    \n",
    "for p in dataPathLs:\n",
    "    print(\"*************************************************************************************************\")\n",
    "    list1 = np.array(glob.glob(p + '\\\\***'))\n",
    "#     if len(list1) < 5:\n",
    "#         continue\n",
    "    \n",
    "    F1 = open(p+\"\\\\Snapshot.pkl\", 'rb')\n",
    "    logSZ1 = pickle.load(F1)\n",
    "    \n",
    "    \n",
    "    if len(os.path.basename(p).split('.')[0]) == 4:\n",
    "        path = \"H:\\\\recordData\\\\logs_\" + year + os.path.basename(p).split('.')[0] + \"_zs_92_01_day_data\\\\mdLog_SZ_***\"  \n",
    "    else:\n",
    "        path = \"H:\\\\recordData\\\\logs_\" + year + os.path.basename(p).split('.')[0].split('(')[0] + \"_zs_92_01_day_data\\\\mdLog_SZ_***\"  \n",
    "    if len(np.array(glob.glob(path))) == 0:\n",
    "        print(os.path.basename(p).split('.')[0])\n",
    "        print(\"92 SZE snapshot data is missing\")\n",
    "        continue\n",
    "    if len(np.array(glob.glob(path))) == 2:\n",
    "        logSZ11 = pd.read_csv(np.array(glob.glob(path))[0], encoding=\"utf-8\").loc[:, [\"clockAtArrival\", \"sequenceNo\", \"source\", \"StockID\",\n",
    "                                              \"exchange\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                                              \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\",\n",
    "                                              \"bid2q\", \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\",\n",
    "                                              \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "                                              \"ask4q\", \"ask5q\", \"openPrice\"]]\n",
    "        logSZ22 = pd.read_csv(np.array(glob.glob(path))[1], encoding=\"utf-8\").loc[:, [\"clockAtArrival\", \"sequenceNo\", \"source\", \"StockID\",\n",
    "                                              \"exchange\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                                              \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\",\n",
    "                                              \"bid2q\", \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\",\n",
    "                                              \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "                                              \"ask4q\", \"ask5q\", \"openPrice\"]]\n",
    "        logSZ = pd.concat([logSZ11, logSZ22])\n",
    "        del logSZ11\n",
    "        del logSZ22\n",
    "    else:\n",
    "        logSZ = pd.read_csv(np.array(glob.glob(path))[0], encoding=\"utf-8\").loc[:, [\"clockAtArrival\", \"sequenceNo\", \"source\", \"StockID\",\n",
    "                                              \"exchange\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                                              \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\",\n",
    "                                              \"bid2q\", \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\",\n",
    "                                              \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "                                              \"ask4q\", \"ask5q\", \"openPrice\"]]\n",
    "    \n",
    "    \n",
    "    logSZ[\"time\"] = logSZ[\"time\"].apply(lambda x: int((x.replace(':', \"\")).replace(\".\", \"\")))\n",
    "    sl = logSZ[\"StockID\"].unique()\n",
    "    logSZ1 = logSZ1[logSZ1[\"StockID\"].isin(sl)]\n",
    "    dd = int(logSZ1[\"OrigTime\"].iloc[0]//1000000000 * 1000000000)\n",
    "    logSZ1['time'] = (logSZ1['OrigTime'] - dd).astype(int)\n",
    "    \n",
    "    # lv2 data comparison\n",
    "    display(year + os.path.basename(p).split('.')[0] + \" SZ lv2 check:\")\n",
    "    data1 = logSZ[(logSZ[\"time\"] > 92500000) & (logSZ[\"time\"] < 145700000) & (logSZ[\"source\"] == 4)]\n",
    "    data2 = logSZ1[(logSZ1[\"time\"] > 92500000) & (logSZ1[\"time\"] < 145700000)]\n",
    "    columns = [\"StockID\", \"cum_volume\", \"cum_amount\", \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "           \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "           \"ask4q\", \"ask5q\", \"openPrice\"]\n",
    "    data1_1 = data1.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    del data1\n",
    "    data2_1 = data2.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    del data2\n",
    "    n1 = len(data1_1[\"StockID\"].unique())\n",
    "    n2 = len(data2_1[\"StockID\"].unique())\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    if n1 != n2:\n",
    "        sl = list(set(data1_1[\"StockID\"].unique()) & set(data2_1[\"StockID\"].unique()))\n",
    "        data1_1 = data1_1[data1_1[\"StockID\"].isin(sl)]\n",
    "        data2_1 = data2_1[data2_1[\"StockID\"].isin(sl)]\n",
    "    \n",
    "    data1_1[\"cum_amount\"] = data1_1[\"cum_amount\"].round(2)\n",
    "    data2_1[\"cum_amount\"] = data2_1[\"cum_amount\"].round(2)\n",
    "    test = pd.merge(data1_1, data2_1, left_on=columns, right_on=columns, how=\"outer\")\n",
    "    n1 = test[\"time_x\"].count()\n",
    "    n2 = test[\"time_y\"].count()\n",
    "    len1 = len(test)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    diff[\"Date\"].append(os.path.basename(p).split('.')[0])\n",
    "    diff[\"Data\"].append(\"lv2 data\")\n",
    "    re = test[(~np.isnan(test[\"time_y\"]))&(~np.isnan(test[\"time_x\"]))]\n",
    "    diff[\"Time\"].append(re[re[\"time_x\"] == re[\"time_y\"]].shape[0]/re.shape[0])\n",
    "    if n2 < len1:\n",
    "        display(\"SZE lv2 test is not complete:\")\n",
    "        display(test[np.isnan(test[\"time_y\"])])\n",
    "        print(len(test[np.isnan(test[\"time_y\"])])/n1)\n",
    "        print(test[np.isnan(test[\"time_y\"])][\"time_x\"].unique())\n",
    "        print(test[np.isnan(test[\"time_y\"])][\"StockID\"].unique())\n",
    "        diff[\"Condition\"].append(\"SZE lv2 test is not complete\")\n",
    "        diff[\"Prob\"].append(len(test[np.isnan(test[\"time_y\"])])/n1)\n",
    "    if len1 == n2:\n",
    "        display(\"SZE lv2 test is complete\")\n",
    "        diff[\"Condition\"].append(\"SZE lv2 test is complete\")\n",
    "        diff[\"Prob\"].append('C')\n",
    "\n",
    "diff = pd.DataFrame(diff)\n",
    "# diff.to_csv(\"F:\\\\SZ_check_result_2.csv\")\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "\n",
    "year = \"2019\"\n",
    "startDate = \"0314\"\n",
    "endDate = \"0315\"\n",
    "\n",
    "readPath = 'E:\\\\SZ\\\\' + year + '\\\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs < endDate)]\n",
    "\n",
    "\n",
    "diff = {}\n",
    "for col in ['Date', 'Data', 'Condition', 'Prob', 'Time']:\n",
    "    diff[col] = []\n",
    "    \n",
    "    \n",
    "for p in dataPathLs[1:]:\n",
    "    print(\"*************************************************************************************************\")\n",
    "    list1 = np.array(glob.glob(p + '\\\\***'))\n",
    "#     if len(list1) < 5:\n",
    "#         continue\n",
    "    \n",
    "    F1 = open(p+\"\\\\Snapshot.pkl\", 'rb')\n",
    "    logSZ1 = pickle.load(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logSZ1[\"ID\"] = logSZ1[\"StockID\"].astype(str).apply(lambda x: 'SZ' + x.rjust(6, '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "readPath = r'\\\\192.168.10.30\\Kevin_zhenyu\\day_stock_20200416\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dataPathLs = dataPathLs[[np.array([os.path.basename(i).split('.')[0][:2] == 'SZ' for i in dataPathLs])]]\n",
    "db = pd.DataFrame()\n",
    "for p in dataPathLs:\n",
    "    dayData = pd.read_csv(p, compression='gzip')\n",
    "    db = pd.concat([db, dayData])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SZ001914'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(db[db[\"date\"] == \"2019-03-14\"][\"ID\"].unique()) - set(logSZ1[\"ID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4295120713.15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4295120713.15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data1_1[(data1_1[\"StockID\"] == 300059) & (data1_1[\"cum_volume\"] == 221972507)][\"cum_amount\"].values[0].round(2))\n",
    "display(data2_1[(data2_1[\"StockID\"] == 300059) & (data2_1[\"cum_volume\"] == 221972507)][\"cum_amount\"].values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
